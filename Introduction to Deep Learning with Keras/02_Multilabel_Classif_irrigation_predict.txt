# -*- coding: utf-8 -*-
"""
Created on Sat Sep 14 22:46:15 2019

@author: jacqueline.cortez

Chapter 2. Going Deeper
Introduction:
    By the end of this chapter, you will know how to solve binary, multi-class, and multi-label problems with neural networks. 
    All of this by solving problems like detecting fake dollar bills, deciding who threw which dart at a board, and building an 
    intelligent system to water your farm. You will also be able to plot model training metrics and to stop training and save your 
    models when they no longer improve.
    MULTILABEL CLASSIFICATION EXAMPLE CODE
"""
print("****************************************************")
print("** BEGIN                                          **")
print("****************************************************")
print("** Importing libraries \n")

import numpy             as np                                                #For making operations in lists
import pandas            as pd                                                #For loading tabular data
import matplotlib.pyplot as plt                                               #For creating charts
import tensorflow as tf                                                       #For DeapLearning

#from pandas.api.types                import CategoricalDtype                  #For categorical data

from keras.callbacks                 import EarlyStopping                     #For DeapLearning
from keras.callbacks                 import ModelCheckpoint                   #For DeapLearning
from keras.layers                    import Dense                             #For DeapLearning
from keras.models                    import Sequential                        #For DeapLearning
from keras.utils                     import plot_model                        #For DeapLearning

from sklearn.model_selection         import train_test_split                  #For learning machine

print("****************************************************")
print("** Preparing the environment \n")

pd.set_option("display.max_columns", 30)

SEED=42
np.random.seed(SEED)
tf.set_random_seed(SEED)

print("****************************************************")
print("** User functions \n")

def model_display(model, sup_title, file_name):
    print(model.summary()) # Summarize your model
    
    plot_model(model, to_file=file_name, show_shapes=False, show_layer_names=True, rankdir='TB') # rankdir='TB' makes vertical plot and rankdir='LR' creates a horizontal plot
    
    # Plotting the model
    plt.figure()
    data = plt.imread(file_name) # Display the image
    plt.imshow(data)
    plt.axis('off');
    plt.title('Defined Model')
    plt.suptitle(sup_title)
    #plt.subplots_adjust(left=0.2, bottom=None, right=None, top=0.88, wspace=0.3, hspace=None)
    plt.show()

def learning_curve_display(training, loss_name):
    plt.figure()
    plt.plot(training.history['loss']) # Plot the training loss 
    plt.ylabel(loss_name)
    plt.xlabel('epochs')
    plt.title('Evaluation results in each epoch')
    plt.suptitle(tema)
    #plt.subplots_adjust(left=0.2, bottom=None, right=None, top=0.88, wspace=0.3, hspace=None)
    plt.show()

def learning_curve_compare(train, validation, metrics):
    plt.figure()
    plt.plot(train)
    plt.plot(validation)
    plt.title('Model {}'.format(metrics))
    plt.ylabel(metrics)
    plt.xlabel('Epoch')
    plt.legend(['Train', 'Test'])
    plt.show()

print("****************************************************")
tema = "Reading the data"; print("** %s\n" % tema)

file = 'irrigation_machine.csv'
irrigation_df = pd.read_csv(file, 
                            usecols=['sensor_0', 'sensor_1', 'sensor_2', 'sensor_3', 'sensor_4', 
                                     'sensor_5', 'sensor_6', 'sensor_7', 'sensor_8', 'sensor_9', 
                                     'sensor_10', 'sensor_11', 'sensor_12', 'sensor_13', 'sensor_14',
                                     'sensor_15', 'sensor_16', 'sensor_17', 'sensor_18', 'sensor_19',
                                     'parcel_0', 'parcel_1', 'parcel_2'])

print('Dataset info: \n',  irrigation_df.info()) # Describe the data
print('Dataset stats: \n', irrigation_df.describe(include='all')) # Describe the data

sensors = irrigation_df.drop(['parcel_0', 'parcel_1', 'parcel_2'], axis=1)
parcels = irrigation_df[['parcel_0', 'parcel_1', 'parcel_2']]

print("****************************************************")
tema = "11. An irrigation machine"; print("** %s\n" % tema)

model = Sequential() # Instantiate a Sequential model
model.add(Dense(64, input_shape=(20,), activation='relu', name='Dense_1')) # Add a hidden layer of 64 neurons and a 20 neuron's input
model.add(Dense(3, activation='sigmoid', name='Output')) # Add an output layer of 3 neurons with sigmoid activation
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']) # Compile your model with adam and binary crossentropy loss

model_display(model, tema, file_name='02_11_model.png')

print("****************************************************")
tema = "12. Training with multiple labels"; print("** %s\n" % tema)
tema = "14. The history callback"; print("** %s\n" % tema)
tema = "15. Early stopping your model"; print("** %s\n" % tema)
tema = "16. A combination of callbacks"; print("** %s\n" % tema)

sensors_train, sensors_test, parcels_train, parcels_test = train_test_split(sensors,  parcels, stratify=parcels, # Create training and test sets
                                                                            test_size=0.3, random_state=SEED)

monitor_val_loss = EarlyStopping(monitor='val_loss', patience=5) # Define a callback to monitor val_acc
modelCheckpoint = ModelCheckpoint('02_16_model_irrigation_predict.hdf5', save_best_only=True) # Save the best model as best_banknote_model.hdf5

training = model.fit(sensors_train, parcels_train, # Train for 100 epochs using a validation split of 0.2 
                     epochs = 100, validation_split = 0.2,  callbacks=[monitor_val_loss, modelCheckpoint]) 
print("Trackin metrics: ", training.history.keys())
#learning_curve_display(training, loss_name='categorical_crossentropy')

learning_curve_compare(training.history['loss'], training.history['val_loss'], metrics='Loss') # Plot train vs test loss during training
learning_curve_compare(training.history['acc'], training.history['val_acc'], metrics='Accuracy') # Plot train vs test accuracy during training

preds = model.predict(sensors_test) # Predict on sensors_test and round up the predictions
preds_rounded = np.round(preds)
print('\nRounded Predictions: \n', preds_rounded) # Print rounded preds

print("\nThe 5 first predictions\n{} | {}\n".format('Raw Model Predictions','True labels')) # Print preds vs true values
for i, pred in enumerate(preds_rounded[:5]):
    print("{:>21} | {}".format(str(pred), parcels_test.values[i]))

accuracy = model.evaluate(sensors_test, parcels_test)
accuracy_df = pd.DataFrame(data=[accuracy], columns=model.metrics_names) # Evaluate your model's accuracy on the test data
print('\nAccuracy: \n{}'.format(accuracy_df)) # Print accuracy

print("****************************************************")
print("** END                                            **")
print("****************************************************")