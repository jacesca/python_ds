# -*- coding: utf-8 -*-
"""
Created on Sat Aug 24 13:21:34 2019

@author: jacqueline.cortez

Chapter 2. Optimizing a neural network with backward propagation
Introduction:
    Learn how to optimize the predictions generated by your neural networks. You'll use a method called backward 
    propagation, which is one of the most important techniques in deep learning. Understanding how it works will 
    give you a strong foundation to build on in the second half of the course.
"""

# Import packages
#import pandas as pd                                                                 #For loading tabular data
import numpy as np                                                                  #For making operations in lists
#import matplotlib as mpl                                                            #To format numbers with ax.yaxis.set_major_formatter(mpl.ticker.StrMethodFormatter('{x:,.0f}')) or ax.get_xaxis().set_major_formatter(matplotlib.ticker.FuncFormatter(lambda x, p: format(int(x), ',')))
import matplotlib.pyplot as plt                                                     #For creating charts
import seaborn as sns                                                               #For visualizing data
#import scipy.stats as stats                                                         #For accesign to a vary of statistics functiosn
#import statsmodels as sm                                                            #For stimations in differents statistical models
#import scykit-learn                                                                 #For performing machine learning  
#import tabula                                                                       #For extracting tables from pdf
#import nltk                                                                         #For working with text data
#import math                                                                         #For accesing to a complex math operations
#import random                                                                       #For generating random numbers
#import calendar                                                                     #For accesing to a vary of calendar operations
#import re                                                                           #For regular expressions
#import timeit                                                                       #For Measure execution time of small code snippets
#import time                                                                         #To measure the elapsed wall-clock time between two points
#import warnings
#import wikipedia

#from pandas.plotting import register_matplotlib_converters                          #For conversion as datetime index in x-axis
#from math import radian                                                             #For accessing a specific math operations
#from functools import reduce                                                        #For accessing to a high order functions (functions or operators that return functions)
#from pandas.api.types import CategoricalDtype                                       #For categorical data
#from glob import glob                                                               #For using with pathnames matching
#from datetime import datetime                                                       #For obteining today function
#from string import Template                                                         #For working with string, regular expressions
#from itertools import cycle                                                         #Used in the function plot_labeled_decision_regions()
#from math import floor                                                              #Used in the function plot_labeled_decision_regions()
#from math import ceil                                                               #Used in the function plot_labeled_decision_regions()

#from scipy.cluster.hierarchy import fcluster                                        #For learning machine - unsurpervised
#from scipy.cluster.hierarchy import dendrogram                                      #For learning machine - unsurpervised
#from scipy.cluster.hierarchy import linkage                                         #For learning machine - unsurpervised
#from scipy.sparse import csr_matrix                                                 #For learning machine 
#from scipy.stats import pearsonr                                                    #For learning machine 
#from scipy.stats import randint                                                     #For learning machine 

#from sklearn.cluster import KMeans                                                  #For learning machine - unsurpervised
#from sklearn.decomposition import NMF                                               #For learning machine - unsurpervised
#from sklearn.decomposition import PCA                                               #For learning machine - unsurpervised
#from sklearn.decomposition import TruncatedSVD                                      #For learning machine - unsurpervised

#from sklearn.ensemble import AdaBoostClassifier                                     #For learning machine - surpervised
#from sklearn.ensemble import BaggingClassifier                                      #For learning machine - surpervised
#from sklearn.ensemble import GradientBoostingRegressor                              #For learning machine - surpervised
#from sklearn.ensemble import RandomForestClassifier                                 #For learning machine
#from sklearn.ensemble import RandomForestRegressor                                  #For learning machine - unsurpervised
#from sklearn.ensemble import VotingClassifier                                       #For learning machine - unsurpervised
#from sklearn.feature_extraction.text import TfidfVectorizer                         #For learning machine - unsurpervised
#from sklearn.feature_selection import chi2                                          #For learning machine
#from sklearn.feature_selection import SelectKBest                                   #For learning machine
#from sklearn.feature_extraction.text import CountVectorizer                         #For learning machine
#from sklearn.feature_extraction.text import HashingVectorizer                       #For learning machine
#from sklearn import datasets                                                        #For learning machine
#from sklearn.impute import SimpleImputer                                            #For learning machine
#from sklearn.linear_model import ElasticNet                                         #For learning machine
#from sklearn.linear_model import Lasso                                              #For learning machine
#from sklearn.linear_model import LinearRegression                                   #For learning machine
#from sklearn.linear_model import LogisticRegression                                 #For learning machine
#from sklearn.linear_model import Ridge                                              #For learning machine
#from sklearn.manifold import TSNE                                                   #For learning machine - unsurpervised
#from sklearn.metrics import accuracy_score                                          #For learning machine
#from sklearn.metrics import classification_report                                   #For learning machine
#from sklearn.metrics import confusion_matrix                                        #For learning machine
from sklearn.metrics import mean_squared_error as MSE                               #For learning machine
#from sklearn.metrics import roc_auc_score                                           #For learning machine
#from sklearn.metrics import roc_curve                                               #For learning machine
#from sklearn.model_selection import cross_val_score                                 #For learning machine
#from sklearn.model_selection import GridSearchCV                                    #For learning machine
#from sklearn.model_selection import RandomizedSearchCV                              #For learning machine
#from sklearn.model_selection import train_test_split                                #For learning machine
#from sklearn.multiclass import OneVsRestClassifier                                   #For learning machine
#from sklearn.neighbors import KNeighborsClassifier as KNN                            #For learning machine
#from sklearn.pipeline import FeatureUnion                                           #For learning machine
#from sklearn.pipeline import make_pipeline                                          #For learning machine - unsurpervised
#from sklearn.pipeline import Pipeline                                               #For learning machine
#from sklearn.preprocessing import FunctionTransformer                               #For learning machine
#from sklearn.preprocessing import Imputer                                           #For learning machine
#from sklearn.preprocessing import MaxAbsScaler                                      #For learning machine (transforms the data so that all users have the same influence on the model)
#from sklearn.preprocessing import Normalizer                                        #For learning machine - unsurpervised (for pipeline)
#from sklearn.preprocessing import normalize                                         #For learning machine - unsurpervised
#from sklearn.preprocessing import scale                                             #For learning machine
#from sklearn.preprocessing import StandardScaler                                    #For learning machine
#from sklearn.svm import SVC                                                         #For learning machine
#from sklearn.tree import DecisionTreeClassifier                                     #For learning machine - supervised
#from sklearn.tree import DecisionTreeRegressor                                      #For learning machine - supervised

#from bokeh.io import curdoc, output_file, show                                      #For interacting visualizations
#from bokeh.plotting import figure, ColumnDataSource                                 #For interacting visualizations
#from bokeh.layouts import row, widgetbox, column, gridplot                          #For interacting visualizations
#from bokeh.models import HoverTool, ColumnDataSource, CategoricalColorMapper        #For interacting visualizations
#from bokeh.models import Slider, Select, Button, CheckboxGroup, RadioGroup, Toggle  #For interacting visualizations
#from bokeh.models.widgets import Tabs, Panel                                        #For interacting visualizations
#from bokeh.palettes import Spectral6                                                #For interacting visualizations


# Setting the pandas options
#pd.set_option("display.max_columns",20)
#pd.options.display.float_format = '{:,.4f}'.format 
#pd.reset_option("all")
#register_matplotlib_converters() #Require to explicitly register matplotlib converters.

#plt.rcParams = plt.rcParamsDefault
#plt.rcParams['figure.constrained_layout.use'] = True
#plt.rcParams['figure.constrained_layout.h_pad'] = 0.09

#Setting the numpy options
#np.set_printoptions(precision=3) #precision set the precision of the output:
#np.set_printoptions(suppress=True) #suppress suppresses the use of scientific notation for small numbers
#np.set_printoptions(threshold=np.inf) #Show all the columns and rows from an array.
#np.set_printoptions(threshold=8) #Return to default value.

#Setting images params
#plt.rcParams.update({'figure.max_open_warning': 0}) #To solve the max images open

print("****************************************************")
print("** BEGIN                                          **")
print("****************************************************")
print("** User defined functions \n")

def relu(input):
    '''Define your relu activation function here'''
    output = max(0, input) # Calculate the value for the output of the relu function: output
    return(output) # Return the value just calculated


def onelayer_predict_with_network(input_data_row, weights): # Define predict_with_network()
    """Function to make prediction with one hidden layer"""
    node_0_input = (input_data_row * weights['node_0']).sum() # Calculate node 0 value
    node_0_output = relu(node_0_input)
    
    node_1_input = (input_data_row * weights['node_1']).sum() # Calculate node 1 value
    node_1_output = relu(node_1_input)
    
    hidden_layer_outputs = np.array([node_0_output, node_1_output]) # Put node values into array: hidden_layer_outputs
    
    input_to_final_layer = (hidden_layer_outputs * weights['output']).sum() # Calculate model output
    model_output = relu(input_to_final_layer)
    return(model_output)# Return model output


def pred(input_data, weights):
    """Make predictions base on input and weights"""
    return ((input_data * weights).sum())


def get_slope(input_data, target, weights):
    """Get slope base on input_data, weights and error get from difference between target and predictions"""
    preds = pred(input_data, weights)
    error = preds - target
    slope = 2 * input_data * error
    return slope


def get_mse(input_data, target, weights):
    """Get the mean square error from the getted predictions"""
    preds = pred(input_data, weights)
    return MSE([preds], [target])


print("****************************************************")
print("** Getting the data for this program\n")

print("****************************************************")
tema = "4. Coding how weight changes affect accuracy"; print("** %s\n" % tema)

input_data = np.array([0, 3]) # The data point you will make a prediction for
target_actual = 3 # The actual target value, used to calculate the error

weights_0 = {'node_0': [2, 1], 'node_1': [1, 2], 'output': [1, 1]} # Sample weights
model_output_0 = onelayer_predict_with_network(input_data, weights_0) # Make prediction using original weights
error_0 = model_output_0 - target_actual # Calculate error: error_0

weights_1 = {'node_0': [2, 1], 'node_1': [1, 2], 'output': [-1, 1]} # Create weights that cause the network to make perfect prediction (3): weights_1
model_output_1 = onelayer_predict_with_network(input_data, weights_1) # Make prediction using new weights: model_output_1
error_1 = model_output_1 - target_actual # Calculate error: error_1

print(error_0) # Print error_0 and error_1
print(error_1)

print("****************************************************")
tema = "5. Scaling up to multiple data points"; print("** %s\n" % tema)

input_data = [np.array([0, 3]), np.array([1, 2]), np.array([-1, -2]), np.array([4, 0])]
target_actuals = [1, 3, 5, 7]
weights_0 = {'node_0': np.array([2, 1]), 'node_1': np.array([1, 2]), 'output': np.array([1, 1])}
weights_1 = {'node_0': np.array([2, 1]), 'node_1': np.array([1. , 1.5]), 'output': np.array([1. , 1.5])}

model_output_0 = [] # Create model_output_0 
model_output_1 = [] # Create model_output_1

for row in input_data: # Loop over input_data
    model_output_0.append(onelayer_predict_with_network(row, weights_0)) # Append prediction to model_output_0
    model_output_1.append(onelayer_predict_with_network(row, weights_1)) # Append prediction to model_output_1
    
mse_0 = MSE(target_actuals, model_output_0) # Calculate the mean squared error for model_output_0: mse_0
mse_1 = MSE(target_actuals, model_output_1) # Calculate the mean squared error for model_output_1: mse_1

print("Mean squared error with weights_0: %f" %mse_0) # Print mse_0 and mse_1
print("Mean squared error with weights_1: %f" %mse_1)

print("Root mean squared error with weights_0: %f" %(mse_0**(1/2))) # Print rmse_0 and mse_1
print("Root mean squared error with weights_1: %f" %(mse_1**(1/2)))

print("****************************************************")
tema = "7. Calculating slopes"; print("** %s\n" % tema)

input_data = np.array([1, 2, 3])
weights = np.array([0, 2, 1])
target = 0

preds = (input_data * weights).sum() # Calculate the predictions: preds
error = preds - target# Calculate the error: error
slope = 2 * input_data * error # Calculate the slope: slope

print('inout data: ', input_data)
print('weights: ', weights)
print('target: ', target)
print('predictions: ', preds)
print('slope: ', slope) # Print the slope

print("****************************************************")
tema = "8. Improving model weights"; print("** %s\n" % tema)

learning_rate = 0.01 # Set the learning rate: learning_rate

weights_updated = weights - (slope * learning_rate) # Update the weights: weights_updated
print('updated weights: ', weights_updated)

preds_updated = (input_data * weights_updated).sum() # Get updated predictions: preds_updated
error_updated = preds_updated - target # Calculate updated error: error_updated

print("Initial error: ", error) # Print the original error
print("Error after first rectification: ", error_updated) # Print the updated error

print("****************************************************")
tema = "9. Making multiple updates to weights"; print("** %s\n" % tema)

learning_rate = 0.01
input_data = np.array([1, 2, 3])
weights = np.array([0, 2, 1])
target = 0

n_updates = 20
mse_hist = []

for i in range(n_updates): # Iterate over the number of updates
    slope = get_slope(input_data, target, weights) # Calculate the slope: slope
    weights = weights - (slope * learning_rate) # Update the weights: weights
    mse = get_mse(input_data, target, weights) # Calculate mse with new weights: mse
    mse_hist.append(mse) # Append the mse to mse_hist

sns.set() # Set default Seaborn style
#plt.figure()
plt.plot(mse_hist) # Plot the mse history
plt.xlabel('Iterations')
plt.ylabel('Mean Squared Error')
plt.title('Features Importances')
plt.suptitle(tema)
#plt.subplots_adjust(left=0.35, bottom=None, right=None, top=0.88, wspace=None, hspace=None)
plt.show()
plt.style.use('default')

print("****************************************************")
print("** END                                            **")
print("****************************************************")