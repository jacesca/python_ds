{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import expectexception  #%%expect_exception TypeError\n",
    "import pytest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Unit testing basics\n",
    "\n",
    "In this chapter, you will get introduced to the pytest package and use it to write simple unit tests. You'll run the tests, interpret the test result reports and fix bugs. Throughout the chapter, we will use examples exclusively from the data preprocessing module of a linear regression project, making sure you learn unit testing in the context of data science."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=darkred>1.1 Why unit test?</font>\n",
    "\n",
    "1. Why unit test?\n",
    ">Hello and welcome to Unit Testing for Data Science in Python! My name is Dibya. I am a Test Automation Engineer and I will be your instructor for this course.\n",
    "\n",
    "2. How can we test an implementation?\n",
    ">Consider this question. Suppose we have just implemented a Python function. How can we test whether our implementation is correct? The easiest way is to open an interpreter, test the function on a few arguments and check whether the return value is correct. If correct, we can accept the implementation and move on. Right? While testing on the interpreter is easy, it is actually very inefficient. This will become clear if we think about the big picture of a function's life cycle in a data science project.\n",
    "\n",
    "3. Life cycle of a function\n",
    ">The life cycle of a function typically looks like this. We implement the function\n",
    "\n",
    "4. Life cycle of a function\n",
    ">and then test it.\n",
    "\n",
    "5. Life cycle of a function\n",
    ">If the tests pass, we accept the implementation.\n",
    "\n",
    "6. Life cycle of a function\n",
    ">If the tests fail, we fix any bugs that we found and test again.\n",
    "\n",
    "7. Life cycle of a function\n",
    ">Later, we might get a new feature request or we may be asked to refactor the function.\n",
    "\n",
    "8. Life cycle of a function\n",
    ">So we implement the new feature or refactor the code, and then test it again.\n",
    "\n",
    "9. Life cycle of a function\n",
    ">Alternatively, someone might discover a previously unseen bug.\n",
    "\n",
    "10. Life cycle of a function\n",
    ">In that case, we fix that bug and test again. Notice how many times a function needs to be tested during the life cycle. Every time we modify the function, either to fix bugs or to implement new features, we have to test it.\n",
    "\n",
    "11. Life cycle of a function\n",
    ">If the project continues for a few years, we might be testing the function about a hundred times, maybe more.\n",
    "\n",
    "12. Example\n",
    ">Let's look at an example function. It's called row_to_list(). It takes a single argument, which is a Python string. The string is a single row in a data file which contains data on housing area and market price of the house.\n",
    "\n",
    "13. Data format\n",
    ">The string contains the housing area in square feet, followed by a single tab, followed by the housing price in dollars and ending with a newline character. If the string follows this format, the function returns a list of length 2, containing the housing area and the housing price.\n",
    "\n",
    "14. Data isn't clean\n",
    ">But this data file is not clean, and some rows in this data file do not follow this format. The third row has missing area,\n",
    "\n",
    "15. Data isn't clean\n",
    ">while the penultimate row is missing the tab between the area and price. For these invalid rows, the function should return None.\n",
    "\n",
    "16. Time spent in testing this function\n",
    ">To test this function, we will have to try all the arguments that we listed and check if the function returns the correct value.\n",
    "\n",
    "17. Time spent in testing this function\n",
    ">Remembering that a function needs to be tested about 100 times in its life cycle,\n",
    "\n",
    "18. Time spent in testing this function\n",
    ">and assuming it takes 5 minutes to test each time, we will spend 8 hours just testing this function on the interpreter.\n",
    "\n",
    "19. Manual testing vs. unit tests\n",
    ">Unit tests automate this repetitive and tedious testing process. Unit tests will reduce the testing time over the life cycle of a single function to 1 hour instead of 8. Now imagine how much time we would save when we unit test all the functions in a project! This makes unit testing a must-have skill for productive data scientists.\n",
    "\n",
    "20. Learn unit testing - with a data science spin\n",
    ">This course will teach you how to write unit tests. We have created an example data science project which predicts prices from the housing area using linear regression, as we can see in the plot.\n",
    "\n",
    "21. GitHub repository of the course\n",
    ">The complete code for this project, including actual implementations for functions like row_to_list(), is available in a public GitHub repository. We will share the link to the repository at the end of the course.\n",
    "\n",
    "22. Develop a complete unit test suite\n",
    ">Here is the folder structure of this project.\n",
    "\n",
    "23. Develop a complete unit test suite\n",
    ">During this course, we are going to write a complete unit test suite for this example project. It's going to be fun and exciting. This will prepare you to write unit tests for your own projects.\n",
    "\n",
    "24. Let's practice these concepts!\n",
    ">Sounds good? Then let's get started by practicing the concepts covered in this lesson."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=darkred>1.2 How frequently is a function tested?</font>\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "Many data scientists do not think much about testing, and just do it in the manual way when necessary. But once you see the big picture i.e. the life cycle of a function over the entire project, you appreciate how important testing really is and how frequently you need to test things.\n",
    "\n",
    "Which of the following is true about testing?\n",
    "\n",
    "**Possible Answers**\n",
    "- A function is tested just once during its life cycle, which is right after the first implementation.\n",
    "- A function is tested after the first implementation and then any time the function is modified, and this happens mainly when new bugs are found.\n",
    "- <font color=red>A function is tested after the first implementation and then any time the function is modified, which happens mainly when new bugs are found, new features are implemented or the code is refactored.</font>\n",
    "- A function is tested every time the function is executed.\n",
    "\n",
    "**Results**\n",
    "\n",
    "<font color=darkgreen>Exactly! If the project goes on for a few years, you may end up testing the same function over a hundred times because of new bugs, new feature requests and refactoring!</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=darkred>1.3 Manual testing</font> \n",
    "\n",
    "The function row_to_list(), which you met in the video lesson, has the following expected return values for the arguments listed below.\n",
    "\n",
    "|Argument|Expected return value|Explanation|\n",
    "|-|-|-|\n",
    "|\"2,081\\t314,942\\n\"|[\"2,081\", \"314,942\"]|Correct row format|\n",
    "|\"\\t293,410\\n\"|None|Missing area|\n",
    "|\"1,463238,765\\n\"|None|Missing tab separator|\n",
    "\n",
    "row_to_list() has been defined and imported for you. Your job is to test the function manually in the IPython console.\n",
    "\n",
    "While testing manually, notice how many times you have to repeat the same steps! The point is to experience the inefficiency of manual testing.\n",
    "\n",
    "**Instructions**\n",
    "- Call row_to_list() in the IPython console on the three arguments listed in the table. Do the actual return values match the expected return values listed in the table?\n",
    "    - Yes, the implementation returns the expected value in each case.\n",
    "    - No, the function returns None for the argument \"2,081\\t314,942\\n\" instead of the expected return value [\"2,081\", \"314,942\"].\n",
    "    - <font color=red>No. the function returns [\"\", \"293,410\"] for the argument \"\\t293,410\\n\" instead of the expected return value None.</font>\n",
    "    - No, the function returns False for the argument \"1,463238,765\\n\" instead of the expected return value None.\n",
    "\n",
    "<font color=darkgreen>In the last step, you discovered a bug in our implementation of row_to_list(). Good job!</font>\n",
    "\n",
    "- We have implemented a corresponding bug fix in a new function row_to_list_bugfix(). Call row_to_list_bugfix() in the IPython console on the three arguments listed in the table. Do the actual return values now match the expected return values listed in the table?\n",
    "    - <font color=red>Yes, the implementation returns the expected value in each case.</font>\n",
    "    - No, the function returns None for the argument \"2,081\\t314,942\\n\" instead of the expected return value [\"2,081\", \"314,942\"].\n",
    "    - No. the function returns [\"\", \"293,410\"] for the argument \"\\t293,410\\n\" instead of the expected return value None.\n",
    "    - No, the function returns False for the argument \"1,463238,765\\n\" instead of the expected return value None..\n",
    "\n",
    "**Results**\n",
    "\n",
    "<font color=darkgreen>Well done! Did you notice how manual testing involves repeating the same steps over and over in the IPython console? In this exercise, you just went through a single bug discovery and fixing phase. Just imagine doing this a hundred times over the entire life cycle of row_to_list(), including new feature implementation and refactoring phases! Unit testing can automate these repetitive steps, so that testing becomes easier, and you will learn it in the next lesson ;-)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2,081', '314,942']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['', '293,410']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def row_to_list(row):\n",
    "    row = row.rstrip()\n",
    "    separated_entries = row.split(\"\\t\")\n",
    "    if len(separated_entries) == 2:\n",
    "        return separated_entries\n",
    "    return None\n",
    "\n",
    "display(row_to_list(\"2,081\\t314,942\\n\"))\n",
    "display(row_to_list(\"\\t293,410\\n\"))\n",
    "display(row_to_list(\"1,463238,765\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2,081', '314,942']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['', '293,410']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#import sys\n",
    "\n",
    "#sys.path.append(\"univariate-linear-regression/src/data\")\n",
    "#from preprocessing_helpers import row_to_list\n",
    "\n",
    "def row_to_list_bugfix(row):\n",
    "    row = row.rstrip()\n",
    "    separated_entries = row.split(\"\\t\")\n",
    "    if len(separated_entries) == 2 and \"\" not in separated_entries:\n",
    "        return separated_entries\n",
    "    return None\n",
    "\n",
    "\n",
    "display(row_to_list(\"2,081\\t314,942\\n\"))\n",
    "display(row_to_list(\"\\t293,410\\n\"))\n",
    "display(row_to_list(\"1,463238,765\\n\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=darkred>1.4 Write a simple unit test using pytest</font>\n",
    "\n",
    "1. Write a simple unit test using pytest\n",
    ">In the last exercise, you went through a function's life cycle.\n",
    "\n",
    "2. Testing on the console\n",
    ">At every step, you tested it by calling row_to_list() on different arguments and checked if the return values are correct. This was repetitive, tedious and time consuming. In this lesson, we will learn to write unit tests and improve this process.\n",
    "\n",
    "3. Python unit testing libraries\n",
    ">There are many Python libraries for writing unit tests such as pytest, unittest, nosetests, and doctest. We will use pytest for this course, because pytest has all essential features, is easiest to use, and is the most popular testing library in Python.\n",
    "\n",
    "4. Step 1: Create a file\n",
    ">To start unit testing with pytest, we will first create a file called test_row_to_list.py. When pytest sees a filename starting with \"test_\", it understands that this is not an usual Python file, but a special one containing unit tests. We must make sure to follow this naming convention. Files holding unit tests are also called test modules, and we just created our first test module.\n",
    "\n",
    "5. Step 2: Imports\n",
    ">In the test module, we first import pytest. Then we import the function under test.\n",
    "\n",
    "6. Step 3: Unit tests are Python functions\n",
    ">A unit test is written as a Python function, whose name starts with a \"test_\", just like the test module. This way, pytest can tell that it is a unit test and not an ordinary function.\n",
    "\n",
    "7. Step 3: Unit tests are Python functions\n",
    ">The unit test usually corresponds to exactly one entry in the argument and return value table for row_to_list(). The unit test checks whether row_to_list() has the expected return value when called on this particular argument. This particular argument is a clean row, so we call the unit test test_for_clean_row().\n",
    "\n",
    "8. Step 4: Assertion\n",
    ">The actual check is done via an assert statement, and every test must contain one.\n",
    "\n",
    "9. Theoretical structure of an assertion\n",
    ">The assert statement has a required first argument, which can be any boolean expression. If the expression is True, the assert statement passes, giving us a blank output. If the expression is False, it raises an AssertionError.\n",
    "\n",
    "10. Step 4: Assertion\n",
    ">In this case, we want to check if row_to_list() returns the correct list when called on the clean row. The expression we use is row_to_list() called on the argument equal equals the correct list. If the function works, this will evaluate to True and the assert statement will pass. This will make the test pass. If the function has a bug, it will evaluate to False, the assert statement will raise an AssertionError, and the test will fail.\n",
    "\n",
    "11. A second unit test\n",
    ">For the second row in the table, we create a unit test called test_on_missing_area() because the argument has missing area data. Then we assert that the return value for this argument is None.\n",
    "\n",
    "12. Checking for None values\n",
    ">Note that the correct way to check if a variable's value is None is to use the boolean expression var is None and not var equal equals None.\n",
    "\n",
    "13. A third unit test\n",
    ">For the third row in the table, we create a unit test called test_for_missing_tab(), because the argument is missing the tab separating area and price. The assert statement is similar to the second test.\n",
    "\n",
    "14. Step 5: Running unit tests\n",
    ">To test whether row_to_list() is working at any time in its life cycle, we simply run the test module. The standard way to run tests is to open a command line and type pytest followed by the test module name.\n",
    "\n",
    "15. Running unit tests in DataCamp exercises\n",
    ">In the DataCamp exercises, we can't create files directly. So you will define the unit tests in the script.py area, which is highlighted here.\n",
    "\n",
    "16. Running unit tests in DataCamp exercises\n",
    ">In the next step or next exercise, we will write the tests to a test module in the background and tell you its file path. This is highlighted in this slide.\n",
    "\n",
    "17. Running unit tests in DataCamp exercises\n",
    ">Once you know the test module's file path, you can run the tests in the IPython console at the bottom, which is highlighted here.\n",
    "\n",
    "18. Running unit tests in DataCamp exercises\n",
    ">You can run any command line expression in the IPython console by adding an exclamation mark before the expression. For example, to run the pytest command, you have to use exclamation pytest, as shown in the picture.\n",
    "\n",
    "19. Next lesson: test result report\n",
    ">Running this command will output the test result report, which contains information about bugs in the function, if any. We will cover the test result report in the next video lesson.\n",
    "\n",
    "20. Let's write some unit tests!\n",
    ">But now, let's practice writing some simple unit tests using pytest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jaces\\Documents\\Data Science\\Python\\Cursos\\___Unit Testing for Data Science in Python\\test_practices\n",
      "============================= test session starts =============================\n",
      "platform win32 -- Python 3.8.8, pytest-6.2.4, py-1.10.0, pluggy-0.13.1\n",
      "Matplotlib: 3.3.4\n",
      "Freetype: 2.10.4\n",
      "rootdir: C:\\Users\\jaces\\Documents\\Data Science\\Python\\Cursos\\___Unit Testing for Data Science in Python\\test_practices\n",
      "plugins: cov-2.12.1, mock-3.6.1, mpl-0.13\n",
      "collected 3 items\n",
      "\n",
      "test_row_to_list.py ...                                                  [100%]\n",
      "\n",
      "============================== 3 passed in 0.36s ==============================\n",
      "C:\\Users\\jaces\\Documents\\Data Science\\Python\\Cursos\\___Unit Testing for Data Science in Python\n"
     ]
    }
   ],
   "source": [
    "%cd test_practices\n",
    "with open(\"test_row_to_list.py\", \"w\") as text_file:\n",
    "    text_file.write(\"\"\"\n",
    "import sys\n",
    "sys.path.append(\"../univariate-linear-regression/src/data\")\n",
    "\n",
    "import pytest\n",
    "from preprocessing_helpers import row_to_list\n",
    "\n",
    "def test_for_clean_row():\n",
    "    assert row_to_list('2,081\\\\t314,942\\\\n') == ['2,081', '314,942']\n",
    "\n",
    "def test_for_missing_area():\n",
    "    assert row_to_list('\\\\t293,410\\\\n') is None\n",
    "\n",
    "def test_for_missing_tab():\n",
    "    assert row_to_list('1,463238,765\\\\n') is None\n",
    "    \"\"\")\n",
    "    \n",
    "!pytest test_row_to_list.py\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=darkred>1.5 Your first unit test using pytest</font> \n",
    "\n",
    "The data file containing housing area and prices uses commas as thousands separators, e.g. \"2,081\" or \"314,942\", as you can see in the IPython Shell.\n",
    "\n",
    "The convert_to_int() function takes a comma separated integer string as argument, and returns the integer. Therefore, the expected return value of convert_to_int(\"2,081\") is the integer 2081.\n",
    "\n",
    "This function is defined in the module preprocessing_helpers.py. But it is not known if the function is working properly.\n",
    "\n",
    "**Instructions**\n",
    "- Import the pytest package.\n",
    "- Import the function convert_to_int().\n",
    "- Complete the name of the unit test by adding the prefix which pytest uses to distinguish unit tests from ordinary functions.\n",
    "- Complete the assert statement to check if convert_to_int() returns the expected value for the argument \"2,081\".\n",
    "\n",
    "**Results**\n",
    "\n",
    "<font color=darkgreen>You just wrote your first unit test using pytest. Congratulations! A unit test takes 5 minutes to write, but saves you many hours in the future.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the pytest package\n",
    "import pytest\n",
    "\n",
    "# Import the function convert_to_int()\n",
    "import sys\n",
    "sys.path.append(\"univariate-linear-regression/src/data\")\n",
    "from preprocessing_helpers import convert_to_int\n",
    "\n",
    "# Complete the unit test name by adding a prefix\n",
    "def test_on_string_with_one_comma():\n",
    "  # Complete the assert statement\n",
    "  assert convert_to_int(\"2,081\") == 2081"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jaces\\Documents\\Data Science\\Python\\Cursos\\___Unit Testing for Data Science in Python\\test_practices\n",
      "============================= test session starts =============================\n",
      "platform win32 -- Python 3.8.8, pytest-6.2.4, py-1.10.0, pluggy-0.13.1\n",
      "Matplotlib: 3.3.4\n",
      "Freetype: 2.10.4\n",
      "rootdir: C:\\Users\\jaces\\Documents\\Data Science\\Python\\Cursos\\___Unit Testing for Data Science in Python\\test_practices\n",
      "plugins: cov-2.12.1, mock-3.6.1, mpl-0.13\n",
      "collected 1 item\n",
      "\n",
      "test_convert_to_int.py .                                                 [100%]\n",
      "\n",
      "============================== 1 passed in 0.21s ==============================\n",
      "C:\\Users\\jaces\\Documents\\Data Science\\Python\\Cursos\\___Unit Testing for Data Science in Python\n"
     ]
    }
   ],
   "source": [
    "%cd test_practices\n",
    "with open(\"test_convert_to_int.py\", \"w\") as text_file:\n",
    "    text_file.write(\"\"\"\n",
    "# Import the pytest package\n",
    "import pytest\n",
    "\n",
    "# Import the function convert_to_int()\n",
    "import sys\n",
    "sys.path.append(\"../univariate-linear-regression/src/data\")\n",
    "from preprocessing_helpers import convert_to_int\n",
    "\n",
    "# Complete the unit test name by adding a prefix\n",
    "def test_on_string_with_one_comma():\n",
    "  # Complete the assert statement\n",
    "  assert convert_to_int(\"2,081\") == 2081\n",
    "    \"\"\")\n",
    "    \n",
    "!pytest test_convert_to_int.py\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=darkred>1.6 Running unit tests</font>\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "The tests that you wrote in the previous exercise have been written to a test module test_convert_to_int.py. Try running the tests in the IPython console.\n",
    "\n",
    "What is the correct IPython console command to run the tests in this test module?\n",
    "\n",
    "**Possible Answers**\n",
    "- pytest test_convert_to_int.py\n",
    "- pytest\n",
    "- !pytest\n",
    "- <font color=Red>!pytest test_convert_to_int.py</font>\n",
    "\n",
    "**Results**\n",
    "\n",
    "<font color=darkgreen>Congratulations! You just wrote and ran your first unit test. You probably saw that running the test produced a lot of output. This output contains information about a bug in convert_to_int(). You should be able to read and understand this output in order to bug fix efficiently. This will be covered in the next video lesson. Jump right in!</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jaces\\Documents\\Data Science\\Python\\Cursos\\___Unit Testing for Data Science in Python\\test_practices\n",
      "============================= test session starts =============================\n",
      "platform win32 -- Python 3.8.8, pytest-6.2.4, py-1.10.0, pluggy-0.13.1\n",
      "Matplotlib: 3.3.4\n",
      "Freetype: 2.10.4\n",
      "rootdir: C:\\Users\\jaces\\Documents\\Data Science\\Python\\Cursos\\___Unit Testing for Data Science in Python\\test_practices\n",
      "plugins: cov-2.12.1, mock-3.6.1, mpl-0.13\n",
      "collected 1 item\n",
      "\n",
      "test_convert_to_int.py .                                                 [100%]\n",
      "\n",
      "============================== 1 passed in 0.18s ==============================\n",
      "C:\\Users\\jaces\\Documents\\Data Science\\Python\\Cursos\\___Unit Testing for Data Science in Python\n"
     ]
    }
   ],
   "source": [
    "%cd test_practices\n",
    "!pytest test_convert_to_int.py\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=darkred>1.7 Understanding test result report</font>\n",
    "\n",
    "1. Understanding test result report\n",
    ">In this lesson, we will take a deeper look at the output generated when we run tests. This output is called the test result report and contains information that will help us fix bugs.\n",
    "\n",
    "2. Unit tests for row_to_list()\n",
    ">As an example, we will use the test module test_row_to_list.py, which we saw in the previous video lesson. It contains three unit tests for the row_to_list() function. The unit tests check if row_to_list() returns the correct return values for clean rows, rows missing area data and rows missing the tab separator respectively.\n",
    "\n",
    "3. Test result report\n",
    ">Running the tests in the IPython console produces lot of output. So much output that we had to truncate it in this slide. This is called the test result report. We will break this down into smaller pieces and understand them individually.\n",
    "\n",
    "4. Section 1: general information\n",
    ">The first section provides information about the operating system, Python version, pytest package versions, the working directory and pytest plugins. There is not much to say about this section, so let's move ahead.\n",
    "\n",
    "5. Section 2: Test result\n",
    ">The next bit is important. The output says \"collected 3 items\", which means that pytest found three tests to run. This is accurate as the test module test_row_to_list.py contains three unit tests. The next line contains the test module name, which is test_row_to_list.py, followed by the characters dot, capital F and dot. Each character represents the result of a unit test.\n",
    "\n",
    "6. Section 2: Test result\n",
    ">The character capital F stands for failure. A unit test fails if an exception is raised when running the unit test code.\n",
    "\n",
    "7. Section 2: Test result\n",
    ">This happens most often when the assert statement raises an AssertionError. This means that the function has a bug and we should fix it.\n",
    "\n",
    "8. Section 2: Test result\n",
    ">A unit test may also fail if a different exception is raised while running the unit test code. In this case, execution will stop before the assert statement is run. For example, if we wrote None with a small n, this would raise a NameError. Since the assert statement did not run, we cannot conclude anything about the function under test from the capital F result. In this case, we should fix the unit test so that it can actually run the assert statement.\n",
    "\n",
    "9. Section 2: Test result\n",
    ">Dot means that the unit test passed. This means no exceptions were raised by the assert statement or any other part of the unit test. For the test module test_row_to_list.py, the first test passed, the second failed and the third passed.\n",
    "\n",
    "10. Section 3: Information on failed tests\n",
    ">The next section contains detailed information about failed tests. We can see that the unit test test_on_missing_area() failed. The line raising the exception is marked by a greater than sign on the left. In this case, it is the assert statement.\n",
    "\n",
    "11. Section 3: Information on failed tests\n",
    ">The following lines marked with capital E on the left contains details of the exception. In this case, the assert statement raised an AssertionError.\n",
    "\n",
    "12. Section 3: Information about failed tests\n",
    ">The lines which contain the word \"where\" displays any return values that were calculated when running the assert statement. In this case, it shows that the actual return value of row_to_list() is a list containing an empty string and the string \"293,410\". The expected return value is, of course, None. The mismatch between the expected and actual value will be our starting point for debugging. We would have to figure out why row_to_list() returns a list instead of None in this case.\n",
    "\n",
    "13. Section 4: Test result summary\n",
    ">The final line is a test result summary, saying that \"1 test failed, and 2 passed\". Additionally, we also find out that the test took 0.03 seconds to run. That's really fast compared to the time we would need to test using the interpreter.\n",
    "\n",
    "14. Let's practice reading test result reports\n",
    ">Now, let's practice reading test result reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jaces\\Documents\\Data Science\\Python\\Cursos\\___Unit Testing for Data Science in Python\\test_practices\n",
      "============================= test session starts =============================\n",
      "platform win32 -- Python 3.8.8, pytest-6.2.4, py-1.10.0, pluggy-0.13.1\n",
      "Matplotlib: 3.3.4\n",
      "Freetype: 2.10.4\n",
      "rootdir: C:\\Users\\jaces\\Documents\\Data Science\\Python\\Cursos\\___Unit Testing for Data Science in Python\\test_practices\n",
      "plugins: cov-2.12.1, mock-3.6.1, mpl-0.13\n",
      "collected 3 items\n",
      "\n",
      "test_row_to_list_fail.py .F.                                             [100%]\n",
      "\n",
      "================================== FAILURES ===================================\n",
      "____________________________ test_for_missing_area ____________________________\n",
      "\n",
      "    def test_for_missing_area():\n",
      ">       assert row_to_list('\\t293,410\\n') is none\n",
      "E       NameError: name 'none' is not defined\n",
      "\n",
      "test_row_to_list_fail.py:12: NameError\n",
      "=========================== short test summary info ===========================\n",
      "FAILED test_row_to_list_fail.py::test_for_missing_area - NameError: name 'non...\n",
      "========================= 1 failed, 2 passed in 0.40s =========================\n",
      "C:\\Users\\jaces\\Documents\\Data Science\\Python\\Cursos\\___Unit Testing for Data Science in Python\n"
     ]
    }
   ],
   "source": [
    "%cd test_practices\n",
    "with open(\"test_row_to_list_fail.py\", \"w\") as text_file:\n",
    "    text_file.write(\"\"\"\n",
    "import sys\n",
    "sys.path.append(\"../univariate-linear-regression/src/data\")\n",
    "\n",
    "import pytest\n",
    "from preprocessing_helpers import row_to_list\n",
    "\n",
    "def test_for_clean_row():\n",
    "    assert row_to_list('2,081\\\\t314,942\\\\n') == ['2,081', '314,942']\n",
    "\n",
    "def test_for_missing_area():\n",
    "    assert row_to_list('\\\\t293,410\\\\n') is none\n",
    "\n",
    "def test_for_missing_tab():\n",
    "    assert row_to_list('1,463238,765\\\\n') is None\n",
    "    \"\"\")\n",
    "\n",
    "!pytest test_row_to_list_fail.py\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=darkred>1.8 What causes a unit test to fail?</font>\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "In the test result report, the character ., as shown below, stands for a passing test. A passing test is good news as it means that your function works as expected. The character F stands for a failing test. A failing test is bad news as this means that something is broken.\n",
    "\n",
    "<code>test_row_to_list.py .F.                                                  [100%]</code>\n",
    "\n",
    "Which of the following describes best why a unit test fails?\n",
    "\n",
    "**Possible Answers**\n",
    "- The assert statement passes.\n",
    "- The assert statement cannot be run because an exception is raised while running the unit test code.\n",
    "- The assert statement raises an AssertionError.\n",
    "- An exception is raised when running the unit test. This could be an AssertionError raised by the assert statement or another exception, e.g. NameError, which is raised before the assert statement can run.\n",
    "\n",
    "**Results**\n",
    "\n",
    "<font color=darkgreen>Exactly! If you get an AssertionError, this means the function has a bug and you should fix it. If you get another exception, e.g. NameError, this means that something else is wrong with the unit test code and you should fix it so that the assert statement can actually run.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=darkred>1.9 Spotting and fixing bugs</font>\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "To find bugs in functions, you need to follow a four step procedure.\n",
    "\n",
    "1. Write unit tests.\n",
    "2. Run them.\n",
    "3. Read the test result report and spot the bugs.\n",
    "4. Fix the bugs.\n",
    "\n",
    "In a previous exercise, you wrote a unit test for the function convert_to_int(), which is supposed to convert a comma separated integer string like \"2,081\" to the integer 2081. You also ran the unit test and discovered that it is failing.\n",
    "\n",
    "In this exercise, you will read the test result report from that exercise in detail, and then spot and fix the bug. This would equip you with all basic skills to start using unit tests for your projects.\n",
    "\n",
    "The convert_to_int() function is defined in the file preprocessing_helpers.py. The unit test is available in the test module test_convert_to_int.py.\n",
    "\n",
    "**Results**\n",
    "- Run the unit test in the test module test_convert_to_int.py in the IPython console. Read the test result report and spot the bug.<br>\n",
    "Which of the following describes the bug in the function convert_to_int(), if any?\n",
    "    - convert_to_int(\"2,081\") is expected to return the string \"2081\", but it is actually returning the integer 2081.\n",
    "    - <font color=red>convert_to_int(\"2,081\") is expected to return the integer 2081, but it is actually returning the string \"2081\".</font>\n",
    "    - convert_to_int(\"2,081\") is expected to return the integer 2081, but it is actually returning the string \"2,081\".\n",
    "    - The function convert_to_int() does not have a bug.\n",
    "- Fix the convert_to_int() function so that it returns the integer 2081 instead of the string \"2081\" for the argument \"2,081\".\n",
    "\n",
    "<font color=darkgreen>Good work! Your boss and colleagues are going to really appreciate your new skill of reading test result reports, and then spotting and fixing the bugs, because this would mean fewer bugs in the code base in the long term.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jaces\\Documents\\Data Science\\Python\\Cursos\\___Unit Testing for Data Science in Python\\test_practices\n",
      "============================= test session starts =============================\n",
      "platform win32 -- Python 3.8.8, pytest-6.2.4, py-1.10.0, pluggy-0.13.1\n",
      "Matplotlib: 3.3.4\n",
      "Freetype: 2.10.4\n",
      "rootdir: C:\\Users\\jaces\\Documents\\Data Science\\Python\\Cursos\\___Unit Testing for Data Science in Python\\test_practices\n",
      "plugins: cov-2.12.1, mock-3.6.1, mpl-0.13\n",
      "collected 1 item\n",
      "\n",
      "test_convert_to_int_fail.py F                                            [100%]\n",
      "\n",
      "================================== FAILURES ===================================\n",
      "________________________ test_on_string_with_one_comma ________________________\n",
      "\n",
      "    def test_on_string_with_one_comma():\n",
      ">       assert convert_to_int(\"2,081\") == 2081\n",
      "E       AssertionError: assert '2081' == 2081\n",
      "E        +  where '2081' = convert_to_int('2,081')\n",
      "\n",
      "test_convert_to_int_fail.py:9: AssertionError\n",
      "=========================== short test summary info ===========================\n",
      "FAILED test_convert_to_int_fail.py::test_on_string_with_one_comma - Assertion...\n",
      "============================== 1 failed in 0.41s ==============================\n",
      "C:\\Users\\jaces\\Documents\\Data Science\\Python\\Cursos\\___Unit Testing for Data Science in Python\n"
     ]
    }
   ],
   "source": [
    "%cd test_practices\n",
    "with open(\"test_convert_to_int_fail.py\", \"w\") as text_file:\n",
    "    text_file.write(\"\"\"\n",
    "import pytest\n",
    "\n",
    "def convert_to_int(string_with_comma):\n",
    "    # emulating a wrong function\n",
    "    return string_with_comma.replace(',', '')\n",
    "    \n",
    "def test_on_string_with_one_comma():\n",
    "    assert convert_to_int(\"2,081\") == 2081\n",
    "    \"\"\")\n",
    "\n",
    "!pytest test_convert_to_int_fail.py\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jaces\\Documents\\Data Science\\Python\\Cursos\\___Unit Testing for Data Science in Python\\test_practices\n",
      "============================= test session starts =============================\n",
      "platform win32 -- Python 3.8.8, pytest-6.2.4, py-1.10.0, pluggy-0.13.1\n",
      "Matplotlib: 3.3.4\n",
      "Freetype: 2.10.4\n",
      "rootdir: C:\\Users\\jaces\\Documents\\Data Science\\Python\\Cursos\\___Unit Testing for Data Science in Python\\test_practices\n",
      "plugins: cov-2.12.1, mock-3.6.1, mpl-0.13\n",
      "collected 1 item\n",
      "\n",
      "test_convert_to_int.py .                                                 [100%]\n",
      "\n",
      "============================== 1 passed in 0.29s ==============================\n",
      "C:\\Users\\jaces\\Documents\\Data Science\\Python\\Cursos\\___Unit Testing for Data Science in Python\n"
     ]
    }
   ],
   "source": [
    "%cd test_practices\n",
    "with open(\"test_convert_to_int.py\", \"w\") as text_file:\n",
    "    text_file.write(\"\"\"\n",
    "import pytest\n",
    "\n",
    "def convert_to_int(string_with_comma):\n",
    "    # emulating a wrong function\n",
    "    return int(string_with_comma.replace(',', ''))\n",
    "    \n",
    "def test_on_string_with_one_comma():\n",
    "    assert convert_to_int(\"2,081\") == 2081\n",
    "    \"\"\")\n",
    "\n",
    "!pytest test_convert_to_int.py\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=darkred>1.10 More benefits and test types</font>\n",
    "\n",
    "1. More benefits and test types\n",
    ">In a previous lesson, we learned that unit tests save a lot of time. But the benefits of unit testing goes beyond time savings.\n",
    "\n",
    "2. Unit tests serve as documentation\n",
    ">The unit tests that we wrote for row_to_list() also serve as documentation. If a collaborator didn't know this function's purpose,\n",
    "\n",
    "3. Unit tests serve as documentation\n",
    ">they could recreate the argument and return value table on the right by looking at the boolean expressions used in the assert statements. The table would give them a good hint about what row_to_list() does, helping them understand the function's code faster.\n",
    "\n",
    "4. Guess function's purpose by reading unit tests\n",
    ">To mimic this real life situation, some exercises may ask you to guess a function's job by looking at a test module. In this case, just type exclamation cat followed by the test module name in the IPython console\n",
    "\n",
    "5. Guess function's purpose by reading unit tests\n",
    ">to see the unit tests.\n",
    "\n",
    "6. More trust\n",
    ">Unit tests also increase trust in a package, as users can run the unit tests and verify that the functions work. In the picture, we see NumPy's Github page.\n",
    "\n",
    "7. More trust\n",
    ">This highlighted badge shows how much of the code base is unit tested\n",
    "\n",
    "8. More trust\n",
    ">and this other badge shows whether the tests are passing. Users trust NumPy more because of these badges. We should implement these badges for our projects too, because user trust is important, and we will learn how to do that later in the course.\n",
    "\n",
    "9. Reduced downtime\n",
    ">Unit tests can also reduce downtime for a productive system.\n",
    "\n",
    "10. Reduced downtime\n",
    ">Suppose we make a mistake\n",
    "\n",
    "11. Reduced downtime\n",
    ">and push bad code to a productive system.\n",
    "\n",
    "12. Reduced downtime\n",
    ">This will bring the system down and annoy users.\n",
    "\n",
    "13. Reduced downtime\n",
    ">We can cure this by setting up Continuous Integration or CI. CI runs all unit tests when any code is pushed,\n",
    "\n",
    "14. Reduced downtime\n",
    ">and if any unit test fails, it rejects the change, preventing downtime.\n",
    "\n",
    "15. Reduced downtime\n",
    ">It also informs us that the code needs to be fixed. If we run productive systems that many people depend upon, we must write unit tests and setup CI. We will see an example of this later in the course.\n",
    "\n",
    "16. All benefits\n",
    ">All of these benefits make the case stronger for writing unit tests! In this course, we will write unit tests for all functions in the example linear regression project.\n",
    "\n",
    "17. Tests we already wrote\n",
    ">We already wrote tests for row_to_list()\n",
    "\n",
    "18. Tests we already wrote\n",
    ">and convert_to_int().\n",
    "\n",
    "19. Data module\n",
    ">They are part of the data module, which creates a clean data file from raw data on housing area and price.\n",
    "\n",
    "20. Feature module\n",
    ">Very soon, we will see functions from the feature module, which compute features from the clean data.\n",
    "\n",
    "21. Models module\n",
    ">Later in the course, we will meet the models module, which will output a model for predicting housing price from the features.\n",
    "\n",
    "22. Unit test\n",
    ">The tests that we wrote are called unit tests because they test a unit, such as row_to_list().\n",
    "\n",
    "23. What is a unit?\n",
    ">A unit is any small independent piece of code, and could be a Python function or class.\n",
    "\n",
    "24. Integration test\n",
    ">In contrast, integration tests check if multiple units work well together when they are connected, and not just independently. For example, we could check if the data and the feature module work well when connected. Here, the argument will be the raw data, and the return values to check would be the features.\n",
    "\n",
    "25. End to end test\n",
    ">End to end tests check the whole software at once.. They start from one end, which is the unprocessed data file, goes through all the units till the other end, and checks whether we get the correct model.\n",
    "\n",
    "26. This course focuses on unit tests\n",
    ">This course is focused on unit tests as this is really the best way to learn about pytest.\n",
    "\n",
    "27. In Chapter 2...\n",
    ">In Chapter 2, we will dig much deeper into pytest and write more advanced unit tests for the features and models module. Exciting!\n",
    "\n",
    "28. Let's practice these concepts!\n",
    ">But for now, let's practice the concepts in this lesson."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=darkred>1.11 Benefits of unit testing</font>\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "You have been invited to a meeting where company executives are discussing whether developers should write unit tests. The CEO is unsure, and asks you about the benefits that unit testing might bring. In your response, which of the following benefits should you include?\n",
    "\n",
    "1. Time savings, leading to faster development of new features.\n",
    "2. Better user experience due to faster code execution.\n",
    "3. Improved documentation, which will help new colleagues understand the code base better.\n",
    "4. More user trust in the software product.\n",
    "5. Better user experience due to improved visualizations.\n",
    "6. Better user experience due to reduced downtime.\n",
    "\n",
    "\n",
    "**Possible Answers**\n",
    "\n",
    "- 1, 2, 4 and 6.\n",
    "- 1, 2, 3, 4 and 5.\n",
    "- 1, 3, 4 and 6.\n",
    "- All of them i.e. 1-6.\n",
    "\n",
    "**Results**\n",
    "\n",
    "<font color=darkgreen>You steered the CEO in the right direction! Time savings and reduced downtime are the major benefits of unit testing, while improved documentation and more user trust are great side effects.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=darkred>1.12 Unit tests as documentation</font>\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "You guessed it right and you didn't even take a look at the function definition! This is why - when onboarding new colleagues - it is a good idea to tell them to look at the unit tests if they are not sure about a function's purpose. In Chapter 2, you will see more functions from the feature and models module, and write more advanced unit tests using new pytest features.\n",
    "\n",
    "**Possible Answers**\n",
    "\n",
    "- <font color=red>It converts data in a data file into a NumPy array.</font>\n",
    "- It slices a NumPy array and returns the first two rows.\n",
    "- It checks if data in a data file is clean. If clean, it returns True. If dirty, it returns False.\n",
    "\n",
    "**Results**\n",
    "\n",
    "<font color=darkgreen>You guessed it right and you didn't even take a look at the function definition! This is why - when onboarding new colleagues - it is a good idea to tell them to look at the unit tests if they are not sure about a function's purpose. In Chapter 2, you will see more functions from the feature and models module, and write more advanced unit tests using new pytest features.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=blue>**USING SYS AND RELATIVE PATHS**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jaces\\Documents\\Data Science\\Python\\Cursos\\___Unit Testing for Data Science in Python\\test_practices\n",
      "============================= test session starts =============================\n",
      "platform win32 -- Python 3.8.8, pytest-6.2.4, py-1.10.0, pluggy-0.13.1\n",
      "Matplotlib: 3.3.4\n",
      "Freetype: 2.10.4\n",
      "rootdir: C:\\Users\\jaces\\Documents\\Data Science\\Python\\Cursos\\___Unit Testing for Data Science in Python\\test_practices\n",
      "plugins: cov-2.12.1, mock-3.6.1, mpl-0.13\n",
      "collected 1 item\n",
      "\n",
      "test_mystery_function.py .                                               [100%]\n",
      "\n",
      "============================== 1 passed in 0.50s ==============================\n",
      "C:\\Users\\jaces\\Documents\\Data Science\\Python\\Cursos\\___Unit Testing for Data Science in Python\n"
     ]
    }
   ],
   "source": [
    "%cd test_practices\n",
    "with open(\"datasets/example_clean_data.txt\", \"w\") as text_file:\n",
    "    text_file.write(\"\"\"2081\\t314942\\n1059\\t186606\"\"\")\n",
    "\n",
    "\n",
    "with open(\"pythoncode/mystery_function.py\", \"w\") as text_file:\n",
    "    text_file.write(\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "def mystery_function(clean_data_file_path, num_columns):\n",
    "    result = np.empty((0, num_columns))\n",
    "    with open(clean_data_file_path, \"r\") as f:\n",
    "        rows = f.readlines()\n",
    "        for row_num in range(len(rows)):\n",
    "            try:\n",
    "                row = np.array([rows[row_num].rstrip('\\\\n').split('\\\\t')], dtype=float)\n",
    "            except ValueError:\n",
    "                raise ValueError('Line {0} of {1} is badly formatted'.format(\n",
    "                                     row_num + 1, clean_data_file_path\n",
    "                                     )\n",
    "                                 )\n",
    "            else:\n",
    "                if row.shape != (1, num_columns):\n",
    "                    raise ValueError('Line {0} of {1} does not have {2} columns'.format(\n",
    "                                         row_num + 1, clean_data_file_path, num_columns\n",
    "                                         )\n",
    "                                     )\n",
    "            result = np.append(result, row, axis=0)\n",
    "    return result\n",
    "    \"\"\")\n",
    "\n",
    "\n",
    "with open(\"test_mystery_function.py\", \"w\") as text_file:\n",
    "    text_file.write(\"\"\"\n",
    "import numpy as np\n",
    "import pytest\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"pythoncode\") #Need for python shell execution\n",
    "from mystery_function import mystery_function\n",
    "\n",
    "def test_on_clean_data():\n",
    "    assert np.array_equal(mystery_function('datasets/example_clean_data.txt', num_columns=2), \n",
    "                          np.array([[2081.0, 314942.0], [1059.0, 186606.0]]))\n",
    "    \"\"\")\n",
    "\n",
    "\n",
    "!pytest test_mystery_function.py\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=blue>**IN MORE NATURAL PYTHON STYLE**</blue>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jaces\\Documents\\Data Science\\Python\\Cursos\\___Unit Testing for Data Science in Python\\test_practices\n",
      "============================= test session starts =============================\n",
      "platform win32 -- Python 3.8.8, pytest-6.2.4, py-1.10.0, pluggy-0.13.1\n",
      "Matplotlib: 3.3.4\n",
      "Freetype: 2.10.4\n",
      "rootdir: C:\\Users\\jaces\\Documents\\Data Science\\Python\\Cursos\\___Unit Testing for Data Science in Python\\test_practices\n",
      "plugins: cov-2.12.1, mock-3.6.1, mpl-0.13\n",
      "collected 1 item\n",
      "\n",
      "test_mystery_function.py .                                               [100%]\n",
      "\n",
      "============================== 1 passed in 0.59s ==============================\n",
      "C:\\Users\\jaces\\Documents\\Data Science\\Python\\Cursos\\___Unit Testing for Data Science in Python\n"
     ]
    }
   ],
   "source": [
    "%cd test_practices\n",
    "with open(\"datasets/example_clean_data.txt\", \"w\") as text_file:\n",
    "    text_file.write(\"\"\"2081\\t314942\\n1059\\t186606\"\"\")\n",
    "\n",
    "\n",
    "with open(\"pythoncode/mystery_function.py\", \"w\") as text_file:\n",
    "    text_file.write(\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "def mystery_function(clean_data_file_path, num_columns):\n",
    "    result = np.empty((0, num_columns))\n",
    "    with open(clean_data_file_path, \"r\") as f:\n",
    "        rows = f.readlines()\n",
    "        for row_num in range(len(rows)):\n",
    "            try:\n",
    "                row = np.array([rows[row_num].rstrip('\\\\n').split('\\\\t')], dtype=float)\n",
    "            except ValueError:\n",
    "                raise ValueError('Line {0} of {1} is badly formatted'.format(\n",
    "                                     row_num + 1, clean_data_file_path\n",
    "                                     )\n",
    "                                 )\n",
    "            else:\n",
    "                if row.shape != (1, num_columns):\n",
    "                    raise ValueError('Line {0} of {1} does not have {2} columns'.format(\n",
    "                                         row_num + 1, clean_data_file_path, num_columns\n",
    "                                         )\n",
    "                                     )\n",
    "            result = np.append(result, row, axis=0)\n",
    "    return result\n",
    "    \"\"\")\n",
    "\n",
    "\n",
    "with open(\"test_mystery_function.py\", \"w\") as text_file:\n",
    "    text_file.write(\"\"\"\n",
    "import numpy as np\n",
    "import pytest\n",
    "\n",
    "from pythoncode.mystery_function import mystery_function\n",
    "\n",
    "def test_on_clean_data():\n",
    "    assert np.array_equal(mystery_function('datasets/example_clean_data.txt', num_columns=2), \n",
    "                          np.array([[2081.0, 314942.0], [1059.0, 186606.0]]))\n",
    "    \"\"\")\n",
    "\n",
    "\n",
    "!pytest test_mystery_function.py\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aditional material\n",
    "\n",
    "- Datacamp course: https://learn.datacamp.com/courses/unit-testing-for-data-science-in-python\n",
    "- Project https://github.com/gutfeeling/univariate-linear-regression"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
