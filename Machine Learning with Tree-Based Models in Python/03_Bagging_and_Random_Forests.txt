# -*- coding: utf-8 -*-
"""
Created on Mon Aug 19 19:30:01 2019

@author: jacqueline.cortez

Cap√≠tulo 3. Bagging and Random Forests
Introduction:
    Bagging is an ensemble method involving training the same algorithm many times using different subsets sampled 
    from the training data. 
    In this chapter, you'll understand how bagging can be used to create a tree ensemble. 
    You'll also learn how the random forests algorithm can lead to further ensemble diversity through randomization 
    at the level of each split in the trees forming the ensemble.
"""
import pandas as pd                                                                 #For loading tabular data
import matplotlib.pyplot as plt                                                     #For creating charts
import seaborn as sns                                                               #For visualizing data


from sklearn.ensemble import BaggingClassifier                                      #For learning machine - unsurpervised
from sklearn.ensemble import RandomForestRegressor                                  #For learning machine - unsurpervised
from sklearn.metrics import accuracy_score                                          #For learning machine
from sklearn.metrics import mean_squared_error as MSE                               #For learning machine
from sklearn.model_selection import train_test_split                                #For learning machine
from sklearn.tree import DecisionTreeClassifier                                     #For learning machine - supervised


print("****************************************************")
print("** BEGIN                                          **")
print("****************************************************")
print("** User defined functions \n")

SEED = 1


print("****************************************************")
print("** Getting the data for this program\n")

file = 'indian_liver_patient.csv'
liver_df = pd.read_csv(file)
liver_df.dropna(inplace=True)
liver_df['Dataset'] = liver_df.Dataset.map({1: 1, 2: 0})
liver_df['Is_male'] = liver_df.Gender.map({'Female':0,'Male':1})
liver_X = liver_df.drop(['Dataset', 'Gender'], axis=1)
liver_y = liver_df.Dataset


file = 'bikes.csv'
bikes_df = pd.read_csv(file)
bikes_X = bikes_df.drop(['cnt'], axis=1)
bikes_y = bikes_df.cnt

print("****************************************************")
tema = "2. Define the bagging classifier"; print("** %s\n" % tema)

dt = DecisionTreeClassifier(random_state=SEED) # Instantiate dt
bc = BaggingClassifier(base_estimator=dt, n_estimators=50, random_state=SEED) # Instantiate bc




print("****************************************************")
tema = "3. Evaluate Bagging performance"; print("** %s\n" % tema)

liver_X_train, liver_X_test, liver_y_train, liver_y_test = train_test_split(liver_X, liver_y, stratify=liver_y, test_size=0.2, random_state=SEED)

dt.fit(liver_X_train, liver_y_train)                  # Fit bc to the training set
liver_y_pred = dt.predict(liver_X_test)               # Predict test set labels
acc_test = accuracy_score(liver_y_test, liver_y_pred) # Evaluate acc_test
print('Test set accuracy of dt: {:.6f}'.format(acc_test))


bc.fit(liver_X_train, liver_y_train)                  # Fit bc to the training set
liver_y_pred = bc.predict(liver_X_test)               # Predict test set labels
acc_test = accuracy_score(liver_y_test, liver_y_pred) # Evaluate acc_test
print('Test set accuracy of bc: {:.6f}'.format(acc_test))




print("****************************************************")
tema = "5. Prepare the ground"; print("** %s\n" % tema)

dt = DecisionTreeClassifier(min_samples_leaf=8, random_state=SEED) # Instantiate dt
bc = BaggingClassifier(base_estimator=dt, n_estimators=50, oob_score=True, random_state=SEED) # Instantiate bc



print("****************************************************")
tema = "6. OOB Score vs Test Set Score"; print("** %s\n" % tema)

bc.fit(liver_X_train, liver_y_train)                  # Fit bc to the training set 
liver_y_pred = bc.predict(liver_X_test)               # Predict test set labels
acc_test = accuracy_score(liver_y_test, liver_y_pred) # Evaluate test set accuracy
acc_oob = bc.oob_score_                   # Evaluate OOB accuracy

print('Test set accuracy: {:.6f}, OOB accuracy: {:.6f}'.format(acc_test, acc_oob)) # Print acc_test and acc_oob



print("****************************************************")
tema = "8. Train an RF regressor"; print("** %s\n" % tema)

SEED = 2

bikes_X_train, bikes_X_test, bikes_y_train, bikes_y_test = train_test_split(bikes_X, bikes_y, test_size=0.2, random_state=SEED)
rf = RandomForestRegressor(n_jobs=1, n_estimators=25, random_state=SEED) # Instantiate rf
rf.fit(bikes_X_train, bikes_y_train) # Fit rf to the training set    




print("****************************************************")
tema = "9. Evaluate the RF regressor"; print("** %s\n" % tema)

bikes_y_pred = rf.predict(bikes_X_test) # Predict the test set labels
rmse_test = MSE(bikes_y_test, bikes_y_pred) ** (1/2) # Evaluate the test set RMSE

print('Test set RMSE of rf: {:.6f}'.format(rmse_test)) # Print rmse_test



print("****************************************************")
tema = "10. Visualizing features importances"; print("** %s\n" % tema)

importances = pd.Series(data=rf.feature_importances_, index= bikes_X_train.columns) # Create a pd.Series of features importances
importances_sorted = importances.sort_values() # Sort importances

# Draw a horizontal barplot of importances_sorted
sns.set() # Set default Seaborn style
#plt.figure()
importances_sorted.plot(kind='barh', color='lightgreen')
plt.xlabel('Porcentage')
plt.ylabel('Bike Features')
plt.title('Features Importances')
plt.suptitle(tema)
plt.subplots_adjust(left=0.35, bottom=None, right=None, top=0.88, wspace=None, hspace=None)
plt.show()
plt.style.use('default')


print("****************************************************")
print("** END                                            **")
print("****************************************************")