{\rtf1\ansi\ansicpg1252\deff0\nouicompat\deflang2058{\fonttbl{\f0\fnil\fcharset0 Calibri;}{\f1\fnil\fcharset0 Courier New;}{\f2\fnil Calibri;}{\f3\fnil Courier New;}{\f4\fnil\fcharset2 Symbol;}}
{\colortbl ;\red255\green0\blue0;\red0\green77\blue187;\red0\green176\blue80;\red0\green0\blue255;}
{\*\generator Riched20 10.0.18362}\viewkind4\uc1 
\pard\sl240\slmult1\tx568\cf1\f0\fs22\lang10 __________________________________________________________________________________\par

\pard\sl240\slmult1\qj\b\fs32 02. Large-scale data analysis with spaCy\par
\cf0\b0\fs22 In this chapter, you'll use your new skills to extract specific information from large volumes of text. You'll learn how to make the most of spaCy's data structures, and how to effectively combine statistical and rule-based approaches for text analysis.\cf1\b\fs20\par

\pard\sl240\slmult1\tx568\b0\fs22 __________________________________________________________________________________\par

\pard\sl240\slmult1\qj\cf2\b 02.01 Data Structures (1)\par

\pard\li720\sl240\slmult1\qj\cf0\b0\fs20 See the video.\fs22\par

\pard\sl240\slmult1\tx568\cf1 __________________________________________________________________________________\par

\pard\sl240\slmult1\qj\cf2\b 02.02 Strings to hashes\par

\pard\li720\sl240\slmult1\qj\cf0\b0\fs20 The nlp object has already been created for you.\fs22\par
___________________________________________________________________________\par

\pard\li720\sl240\slmult1\b INSTRUCTIONS:\par

\pard{\pntext\f4\'B7\tab}{\*\pn\pnlvlblt\pnf4\pnindent0{\pntxtb\'B7}}\fi-360\li1080\sl240\slmult1\qj\b0\fs20 Look up the string "cat" in nlp.vocab.strings to get the hash.\par
{\pntext\f4\'B7\tab}Look up the hash to get back the string.\par

\pard\sl240\slmult1\qj\par

\pard{\pntext\f4\'B7\tab}{\*\pn\pnlvlblt\pnf4\pnindent0{\pntxtb\'B7}}\fi-360\li1080\sl240\slmult1\qj Look up the string label "PERSON" in nlp.vocab.strings to get the hash.\par
{\pntext\f4\'B7\tab}Look up the hash to get back the string.\par

\pard\li720\sl240\slmult1\qj\fs22 ___________________________________________________________________________\par

\pard\li720\sl240\slmult1\b ANSWER:\par
\b0\f1\fs16 # Look up the hash for the word "cat"\par
word = 'cat'\par
cat_hash = nlp.vocab.strings[word]\par
print(cat_hash)\par
\par
# Look up the cat_hash to get the string\par
cat_string = nlp.vocab.strings[cat_hash]\par
print(cat_string)\par
\par
\par
\par
# Look up the hash for the string label "PERSON"\par
word = 'PERSON'\par
person_hash = nlp.vocab.strings[word]\par
print(person_hash)\par
\par
# Look up the person_hash to get the string\par
person_string = nlp.vocab.strings[person_hash]\par
print(person_string)\par

\pard\li720\sl240\slmult1\qj\f0\fs22 ___________________________________________________________________________\par

\pard\li720\sl240\slmult1\b RESULT:\par
\b0\f1\fs16 5439657043933447811\par
cat\par
\par
\par
380\par
PERSON\b\par

\pard\li720\sl240\slmult1\qj\b0\f0\fs22 ___________________________________________________________________________\par
\cf3\i\fs20 Good job!\cf0\i0\f1\fs16\par

\pard\sl240\slmult1\tx568\cf1\f0\fs22 __________________________________________________________________________________\par

\pard\sl240\slmult1\qj\cf2\b 02.03 Vocab, hashes and lexemes\par

\pard\li720\sl240\slmult1\cf0 INSTRUCTIONS:\par

\pard\li720\sl240\slmult1\qj\b0\fs20 Why does this code throw an error?\par
\par
\f1\fs16 from spacy.lang.en import English\par
from spacy.lang.de import German\par
\par
# Create an English and German nlp object\par
nlp = English()\par
nlp_de = German()\par
# Get the ID for the string 'Bowie'\par
bowie_id = nlp.vocab.strings['Bowie']\par
print(bowie_id)\par
\par
# Look up the ID for 'Bowie' in the vocab\par
print(nlp_de.vocab.strings[bowie_id])\par
\f0\fs20\par
The English language class is already available as the nlp object.\par
\fs22 ___________________________________________________________________________\par

\pard\li720\sl240\slmult1\b ANSWER:\par

\pard\li1440\sl240\slmult1\f1\fs20 POSIBLLE ANSWERS\par

\pard{\pntext\f4\'B7\tab}{\*\pn\pnlvlblt\pnf4\pnindent0{\pntxtb\'B7}}\fi-360\li2160\sl240\slmult1\qj\cf1\b0\f0 The string 'Bowie' isn't present in the German vocab, so the hash can't be resolved in the string store.\par
{\pntext\f4\'B7\tab}\cf0 'Bowie' is not a regular word in the English or German dictionary, so it can't be hashed.\par
{\pntext\f4\'B7\tab}nlp_de is not a valid name. The vocab can only be shared if the nlp objects have the same name.\par

\pard\li1440\sl240\slmult1\b\f1 CORRECT ANSWER\par

\pard{\pntext\f4\'B7\tab}{\*\pn\pnlvlblt\pnf4\pnindent0{\pntxtb\'B7}}\fi-360\li2160\sl240\slmult1\qj\cf1\b0\f0 The string 'Bowie' isn't present in the German vocab, so the hash can't be resolved in the string store.\cf0\f1\fs16\par

\pard\li720\sl240\slmult1\qj\f0\fs22 ___________________________________________________________________________\par

\pard\li720\sl240\slmult1\b RESULT:\par
\cf1\b0\f1\fs16 Traceback (most recent call last):\par
  File "<stdin>", line 12, in <module>\par
    print(nlp_de.vocab.strings[bowie_id])\par
  File "<stdin>", line 138, in spacy.strings.StringStore.__getitem__\par
KeyError: "[E018] Can't retrieve string for hash '2644858412616767388'."\b\par

\pard\li720\sl240\slmult1\qj\cf0\b0\f0\fs22 ___________________________________________________________________________\par
\cf3\i\fs20 That's correct! Hashes can't be reversed. To prevent this problem, add the word to the new vocab by processing a text or looking up the string, or use the same vocab to resolve the hash back to a string.\cf0\i0\f1\fs16\par

\pard\sl240\slmult1\tx568\cf1\f0\fs22 __________________________________________________________________________________\par

\pard\sl240\slmult1\qj\cf2\b 02.04 Data Structures (2)\par

\pard\li720\sl240\slmult1\qj\cf0\b0\fs20 See the video.\fs22\par

\pard\sl240\slmult1\tx568\cf1 __________________________________________________________________________________\par

\pard\sl240\slmult1\qj\cf2\b 02.05 Creating a Doc\par

\pard\li720\sl240\slmult1\qj\cf0\b0\fs20 Let's create some Doc objects from scratch! The nlp object has already been created for you.\par
By the way, if you haven't downloaded it already, check out the spaCy Cheat Sheet ({{\field{\*\fldinst{HYPERLINK http://datacamp-community-prod.s3.amazonaws.com/29aa28bf-570a-4965-8f54-d6a541ae4e06 }}{\fldrslt{http://datacamp-community-prod.s3.amazonaws.com/29aa28bf-570a-4965-8f54-d6a541ae4e06\ul0\cf0}}}}\f0\fs20 ). It includes an overview of the most important concepts and methods and might come in handy if you ever need a quick refresher!\fs22\par
___________________________________________________________________________\par

\pard\li720\sl240\slmult1\b INSTRUCTIONS:\par

\pard{\pntext\f4\'B7\tab}{\*\pn\pnlvlblt\pnf4\pnindent0{\pntxtb\'B7}}\fi-360\li1080\sl240\slmult1\qj\b0\fs20 Import the Doc from spacy.tokens.\par
{\pntext\f4\'B7\tab}Create a Doc from the words and spaces. Don't forget to pass in the vocab!\par

\pard\sl240\slmult1\qj\par

\pard{\pntext\f4\'B7\tab}{\*\pn\pnlvlblt\pnf4\pnindent0{\pntxtb\'B7}}\fi-360\li1080\sl240\slmult1\qj Import the Doc from spacy.tokens.\par
{\pntext\f4\'B7\tab}Create a Doc from the words and spaces. Don't forget to pass in the vocab!\par

\pard\sl240\slmult1\qj\par

\pard{\pntext\f4\'B7\tab}{\*\pn\pnlvlblt\pnf4\pnindent0{\pntxtb\'B7}}\fi-360\li1080\sl240\slmult1\qj Import the Doc from spacy.tokens.\par
{\pntext\f4\'B7\tab}Complete the words and spaces to match the desired text and create a doc.\par

\pard\li720\sl240\slmult1\qj\fs22 ___________________________________________________________________________\par

\pard\li720\sl240\slmult1\b ANSWER:\par
\b0\f1\fs16 # Import the Doc class\par
from spacy.tokens import Doc\par
\par
# Desired text: "spaCy is cool!"\par
words = ['spaCy', 'is', 'cool', '!']\par
spaces = [True, True, False, False]\par
\par
# Create a Doc from the words and spaces\par
doc = Doc(nlp.vocab, words=words, spaces=spaces)\par
print(doc.text)\par
\par
\par
\par
# Import the Doc class\par
from spacy.tokens import Doc\par
\par
# Desired text: "Go, get started!"\par
words = ['Go', ',', 'get', 'started', '!']\par
spaces = [False, True, True, False, False]\par
\par
# Create a Doc from the words and spaces\par
doc = Doc(nlp.vocab, words=words, spaces=spaces)\par
print(doc.text)\par
\par
\par
\par
# Import the Doc class\par
from spacy.tokens import Doc\par
\par
# Desired text: "Oh, really?!"\par
words = ['Oh', ',', 'really', '?', '!']\par
spaces = [False, True, False, False, False]\par
\par
# Create a Doc from the words and spaces\par
doc = Doc(nlp.vocab, words=words, spaces=spaces)\par
print(doc.text)\par

\pard\li720\sl240\slmult1\qj\f0\fs22 ___________________________________________________________________________\par

\pard\li720\sl240\slmult1\b RESULT:\par
\b0\f1\fs16 spaCy is cool!\par
\par
Go, get started!\par
\par
Oh, really?!\b\par

\pard\li720\sl240\slmult1\qj\b0\f0\fs22 ___________________________________________________________________________\par
\cf3\i\fs20 Nice work! Next, let's create some entities.\cf0\i0\f1\fs16\par

\pard\sl240\slmult1\tx568\cf1\f0\fs22 __________________________________________________________________________________\par

\pard\sl240\slmult1\qj\cf2\b 02.06 Docs, spans and entities from scratch\par

\pard\li720\sl240\slmult1\qj\cf0\b0\fs20 In this exercise, you'll create the Doc and Span objects manually, and update the named entities \f2\endash  just like spaCy does behind the scenes. A shared nlp object has already been created.\f0\fs22\par
___________________________________________________________________________\par

\pard\li720\sl240\slmult1\b INSTRUCTIONS:\par

\pard{\pntext\f4\'B7\tab}{\*\pn\pnlvlblt\pnf4\pnindent0{\pntxtb\'B7}}\fi-360\li1080\sl240\slmult1\qj\b0\fs20 Import the Doc and Span classes from spacy.tokens.\par
{\pntext\f4\'B7\tab}Use the Doc class directly to create a doc from the words and spaces.\par

\pard\sl240\slmult1\qj\par

\pard{\pntext\f4\'B7\tab}{\*\pn\pnlvlblt\pnf4\pnindent0{\pntxtb\'B7}}\fi-360\li1080\sl240\slmult1\qj Create a Span for "David Bowie" from the doc and assign it the label "PERSON".\par

\pard\sl240\slmult1\qj\par

\pard{\pntext\f4\'B7\tab}{\*\pn\pnlvlblt\pnf4\pnindent0{\pntxtb\'B7}}\fi-360\li1080\sl240\slmult1\qj Overwrite the doc.ents with a list of one entity, the "David Bowie" span.\par

\pard\li720\sl240\slmult1\qj\fs22 ___________________________________________________________________________\par

\pard\li720\sl240\slmult1\b ANSWER:\par
\b0\f1\fs16 # Import the Doc and Span classes\par
from spacy.tokens import Doc, Span\par
\par
words = ['I', 'like', 'David', 'Bowie']\par
spaces = [True, True, True, False]\par
\par
# Create a doc from the words and spaces\par
doc = Doc(nlp.vocab, words=words, spaces=spaces)\par
print(doc.text)\par
\par
\par
# Create a span for "David Bowie" from the doc and assign it the label "PERSON"\par
span = Span(doc, 2, 4, label='PERSON')\par
print(span.text, span.label_)\par
\par
\par
# Add the span to the doc's entities\par
doc.ents = [span]\par
\par
# Print entities' text and labels\par
print([(ent.text, ent.label_) for ent in doc.ents])\par

\pard\li720\sl240\slmult1\qj\f0\fs22 ___________________________________________________________________________\par

\pard\li720\sl240\slmult1\b RESULT:\par
\b0\f1\fs16 I like David Bowie\par
\par
David Bowie PERSON\par
\par
[('David Bowie', 'PERSON')]\b\par

\pard\li720\sl240\slmult1\qj\b0\f0\fs22 ___________________________________________________________________________\par
\cf3\i\fs20 Perfect! Creating spaCy's objects manually and modifying the entities will come in handy later when you're writing your own information extraction pipelines.\cf0\i0\f1\fs16\par

\pard\sl240\slmult1\tx568\cf1\f0\fs22 __________________________________________________________________________________\par

\pard\sl240\slmult1\qj\cf2\b 02.07 Data structures best practices\par

\pard\li720\sl240\slmult1\qj\cf0\b0\fs20 The code in this example is trying to analyze a text and collect all proper nouns. If the token following the proper noun is a verb, it should also be extracted. A doc object has already been created.\fs22\par

\pard\li1440\sl240\slmult1\f1\fs16 doc = nlp('Berlin is a nice city')\par
\par
# Get all tokens and part-of-speech tags\par
pos_tags = [token.pos_ for token in doc]\par
\par
for index, pos in enumerate(pos_tags):\par
    # Check if the current token is a proper noun\par
    if pos == 'PROPN':\par
        # Check if the next token is a verb\par
        if pos_tags[index + 1] == 'VERB':\par
            print('Found a verb after a proper noun!')\par

\pard\li720\sl240\slmult1\qj\f0\fs22 ___________________________________________________________________________\par

\pard\li720\sl240\slmult1\b INSTRUCTIONS:\par

\pard{\pntext\f4\'B7\tab}{\*\pn\pnlvlblt\pnf4\pnindent0{\pntxtb\'B7}}\fi-360\li1080\sl240\slmult1\qj\b0\fs20 Why is the code bad?\par

\pard\li1440\sl240\slmult1\b\f1 POSIBLLE ANSWERS\par

\pard{\pntext\f4\'B7\tab}{\*\pn\pnlvlblt\pnf4\pnindent0{\pntxtb\'B7}}\fi-360\li2160\sl240\slmult1\qj\b0\f0 The tokens in the result should be converted back to Token objects. This will let you reuse them in spaCy.\par
{\pntext\f4\'B7\tab}\cf1 It only uses lists of strings instead of native token attributes. This is often less efficient, and can't express complex relationships.\par
{\pntext\f4\'B7\tab}\cf0 pos_ is the wrong attribute to use for extracting proper nouns. You should use tag_ and the 'NNP' and 'NNS' labels instead.\par

\pard\li1440\sl240\slmult1\b\f1 CORRECT ANSWER\par

\pard{\pntext\f4\'B7\tab}{\*\pn\pnlvlblt\pnf4\pnindent0{\pntxtb\'B7}}\fi-360\li2160\sl240\slmult1\qj\cf1\b0\f0 It only uses lists of strings instead of native token attributes. This is often less efficient, and can't express complex relationships.\par

\pard\sl240\slmult1\qj\cf0\par

\pard{\pntext\f4\'B7\tab}{\*\pn\pnlvlblt\pnf4\pnindent0{\pntxtb\'B7}}\fi-360\li1080\sl240\slmult1\qj Rewrite the code to use the native token attributes instead of a list of pos_tags.\par
{\pntext\f4\'B7\tab}Loop over each token in the doc and check the token.pos_ attribute.\par
{\pntext\f4\'B7\tab}Use doc[token.i + 1] to check for the next token and its .pos_ attribute.\par

\pard\li720\sl240\slmult1\qj\fs22 ___________________________________________________________________________\par

\pard\li720\sl240\slmult1\b ANSWER:\par
\b0\f1\fs16 print(doc.text)\par
\par
# Get all tokens and part-of-speech tags\par
pos_tags = [token.pos_ for token in doc]\par
print(pos_tags)\par
\par
for index, pos in enumerate(pos_tags):\par
    # Check if the current token is a proper noun\par
    if pos == 'PROPN':\par
        # Check if the next token is a verb\par
        if pos_tags[index + 1] == 'VERB':\par
            print('Found a verb after a proper noun!')\par
\par
print(doc.text)\par
\par
for token in doc:\par
    # Check if the current token is a proper noun\par
    if token.pos_ == 'PROPN':\par
        # Check if the next token is a verb\par
        if doc[token.i + 1].pos_ == 'VERB':\par
            print('Found a verb after a proper noun!')\par

\pard\li720\sl240\slmult1\qj\f0\fs22 ___________________________________________________________________________\par

\pard\li720\sl240\slmult1\b RESULT:\par
\b0\f1\fs16 Berlin is a nice city\par
['PROPN', 'VERB', 'DET', 'ADJ', 'NOUN']\par
Found a verb after a proper noun!\par
\par
Berlin is a nice city\par
Found a verb after a proper noun!\b\par

\pard\li720\sl240\slmult1\qj\b0\f0\fs22 ___________________________________________________________________________\par
\cf3\i\fs20 Great work!\cf0\i0\f1\fs16\par

\pard\sl240\slmult1\tx568\cf1\f0\fs22 __________________________________________________________________________________\par

\pard\sl240\slmult1\qj\cf2\b 02.08 Word vectors and similarity\par

\pard\li720\sl240\slmult1\qj\cf0\b0\fs20 See the video.\fs22\par

\pard\sl240\slmult1\tx568\cf1 __________________________________________________________________________________\par

\pard\sl240\slmult1\qj\cf2\b 02.09 Inspecting word vectors\par

\pard\li720\sl240\slmult1\qj\cf0\b0\fs20 In this exercise, you'll use a larger English model, which includes around 20.000 word vectors. Because vectors take a little longer to load, we're using a slightly compressed version of it than the one you can download with spaCy. The model is already pre-installed, and spacy has already been imported for you.\fs22\par
___________________________________________________________________________\par

\pard\li720\sl240\slmult1\b INSTRUCTIONS:\par

\pard{\pntext\f4\'B7\tab}{\*\pn\pnlvlblt\pnf4\pnindent0{\pntxtb\'B7}}\fi-360\li1080\sl240\slmult1\qj\b0\fs20 Load the medium 'en_core_web_md' model with word vectors.\par
{\pntext\f4\'B7\tab}Print the vector for "bananas" using the token.vector attribute.\par

\pard\li720\sl240\slmult1\qj\fs22 ___________________________________________________________________________\par

\pard\li720\sl240\slmult1\b ANSWER:\par
\b0\f1\fs16 # Load the en_core_web_md model\par
nlp = spacy.load('en_core_web_md')\par
\par
# Process a text\par
doc = nlp("Two bananas in pyjamas")\par
\par
# Get the vector for the token "bananas"\par
bananas_vector = doc[1].vector\par
print(bananas_vector)\par

\pard\li720\sl240\slmult1\qj\f0\fs22 ___________________________________________________________________________\par

\pard\li720\sl240\slmult1\b RESULT:\par
\b0\f1\fs16 [-2.2009e-01 -3.0322e-02 -7.9859e-02 -4.6279e-01 -3.8600e-01  3.6962e-01\par
 -7.7178e-01 -1.1529e-01  3.3601e-02  5.6573e-01 -2.4001e-01  4.1833e-01\par
...\par
4.6106e-02 -1.2361e-01  1.4516e-01 -2.7947e-02  2.6231e-02 -5.9591e-01\par
 -4.4183e-01  7.8440e-01 -3.4375e-02 -1.3928e+00  3.5248e-01  6.5220e-01]\b\par

\pard\li720\sl240\slmult1\qj\b0\f0\fs22 ___________________________________________________________________________\par
\cf3\i\fs20 Well done! In the next exercise, you'll be using spaCy to predict similarities between documents, spans and tokens via the word vectors under the hood.\cf0\i0\f1\fs16\par

\pard\sl240\slmult1\tx568\cf1\f0\fs22 __________________________________________________________________________________\par

\pard\sl240\slmult1\qj\cf2\b 02.10 Comparing similarities\par

\pard\li720\sl240\slmult1\qj\cf0\b0\fs20 In this exercise, you'll be using spaCy's similarity methods to compare Doc, Token and Span objects and get similarity scores. The medium English model is already available as the nlp object.\fs22\par
___________________________________________________________________________\par

\pard\li720\sl240\slmult1\b INSTRUCTIONS:\par

\pard{\pntext\f4\'B7\tab}{\*\pn\pnlvlblt\pnf4\pnindent0{\pntxtb\'B7}}\fi-360\li1080\sl240\slmult1\qj\b0\fs20 Use the doc.similarity method to compare doc1 to doc2 and print the result.\par

\pard\sl240\slmult1\qj\par

\pard{\pntext\f4\'B7\tab}{\*\pn\pnlvlblt\pnf4\pnindent0{\pntxtb\'B7}}\fi-360\li1080\sl240\slmult1\qj Use the token.similarity method to compare token1 to token2 and print the result.\par

\pard\sl240\slmult1\qj\par

\pard{\pntext\f4\'B7\tab}{\*\pn\pnlvlblt\pnf4\pnindent0{\pntxtb\'B7}}\fi-360\li1080\sl240\slmult1\qj Create spans for "great restaurant"/"really nice bar".\par
{\pntext\f4\'B7\tab}Use span.similarity to compare them and print the result.\par

\pard\li720\sl240\slmult1\qj\fs22 ___________________________________________________________________________\par

\pard\li720\sl240\slmult1\b ANSWER:\par
\b0\f1\fs16 doc1 = nlp("It's a warm summer day")\par
doc2 = nlp("It's sunny outside")\par
\par
# Get the similarity of doc1 and doc2\par
similarity = doc1.similarity(doc2)\par
print(similarity)\par
\par
\par
doc = nlp("TV and books")\par
token1, token2 = doc[0], doc[2]\par
\par
# Get the similarity of the tokens "TV" and "books" \par
similarity = token1.similarity(token2)\par
print(similarity)\par
\par
\par
doc = nlp("This was a great restaurant. Afterwards, we went to a really nice bar.")\par
\par
# Create spans for "great restaurant" and "really nice bar"\par
span1 = doc[3:5]\par
span2 = doc[12:15]\par
\par
# Get the similarity of the spans\par
similarity = span1.similarity(span2)\par
print(similarity)\par

\pard\li720\sl240\slmult1\qj\f0\fs22 ___________________________________________________________________________\par

\pard\li720\sl240\slmult1\b RESULT:\par
\b0\f1\fs16 0.8789265574516525\par
0.22325331\par
0.7517393180536583\b\par

\pard\li720\sl240\slmult1\qj\b0\f0\fs22 ___________________________________________________________________________\par
\cf3\i\fs20 Well done! Feel free to experiment with comparing more objects, if you like. The similarities are not always this conclusive. Once you're getting serious about developing NLP applications that leverage semantic similarity, you might want to train vectors on your own data, or tweak the similarity algorithm.\cf0\i0\f1\fs16\par

\pard\sl240\slmult1\tx568\cf1\f0\fs22 __________________________________________________________________________________\par

\pard\sl240\slmult1\qj\cf2\b 02.11 Combining models and rules\par

\pard\li720\sl240\slmult1\qj\cf0\b0\fs20 See the video.\b\f1\fs16\par

\pard\sl240\slmult1\tx568\cf1\b0\f0\fs22 __________________________________________________________________________________\par

\pard\sl240\slmult1\qj\cf2\b 02.12 Debugging patterns (1)\par

\pard\li720\sl240\slmult1\cf0 INSTRUCTIONS:\par
\b0\fs20 Why does this pattern not match the tokens "Silicon Valley" in the doc?\par
\par

\pard\li1440\sl240\slmult1\f1\fs15 pattern = [\{'LOWER': 'silicon'\}, \{'TEXT': ' '\}, \{'LOWER': 'valley'\}]\par
doc = nlp("Can Silicon Valley workers rein in big tech from within?")\par

\pard\li720\sl240\slmult1\f0\fs20\par
You can try it out in your IPython shell. The matcher with the added pattern and the doc are already created.\par

\pard\li720\sl240\slmult1\qj\fs22 ___________________________________________________________________________\par

\pard\li720\sl240\slmult1\b ANSWER:\par

\pard\li1440\sl240\slmult1\f1\fs20 POSIBLLE ANSWERS\par

\pard{\pntext\f4\'B7\tab}{\*\pn\pnlvlblt\pnf4\pnindent0{\pntxtb\'B7}}\fi-360\li2160\sl240\slmult1\qj\b0\f0 The tokens "Silicon" and "Valley" are not lowercase, so the 'LOWER' attribute won't match.\par
{\pntext\f4\'B7\tab}\cf1 The tokenizer doesn't create tokens for single spaces, so there's no token with the value ' ' in between.\par
{\pntext\f4\'B7\tab}\cf0 The tokens are missing an operator 'OP' to indicate that they should be matched exactly once.\par

\pard\li1440\sl240\slmult1\b\f1 CORRECT ANSWER\par

\pard{\pntext\f4\'B7\tab}{\*\pn\pnlvlblt\pnf4\pnindent0{\pntxtb\'B7}}\fi-360\li2160\sl240\slmult1\qj\cf1\b0\f0 The tokenizer doesn't create tokens for single spaces, so there's no token with the value ' ' in between.\cf0\f1\fs16\par

\pard\li720\sl240\slmult1\qj\f0\fs22 ___________________________________________________________________________\par
\cf3\i\fs20 Correct! The tokenizer already takes care of splitting off whitespace and each dictionary in the pattern describes one token.\cf0\i0\f1\fs16\par

\pard\sl240\slmult1\tx568\cf1\f0\fs22 __________________________________________________________________________________\par

\pard\sl240\slmult1\qj\cf2\b 02.13 Debugging patterns (2)\par

\pard\li720\sl240\slmult1\qj\cf0\b0\fs20 Both patterns in this exercise contain mistakes and won't match as expected. Can you fix them?\par
The nlp and a doc have already been created for you. If you get stuck, try printing the tokens in the doc to see how the text will be split and adjust the pattern so that each dictionary represents one token.\par

\pard\li1440\sl240\slmult1\qj\f1 In [1]: doc\par
Out[1]: Twitch Prime, the perks program for Amazon Prime members offering free loot, games and other benefits, is ditching one of its best features: ad-free viewing. According to an email sent out to Amazon Prime members today, ad-free viewing will no longer be included as a part of Twitch Prime for new members, beginning on September 14. However, members with existing annual subscriptions will be able to continue to enjoy ad-free viewing until their subscription comes up for renewal. Those with monthly subscriptions will have access to ad-free viewing until October 15.\par
\f0\fs22\par

\pard\li720\sl240\slmult1\qj ___________________________________________________________________________\par

\pard\li720\sl240\slmult1\b INSTRUCTIONS:\par

\pard{\pntext\f4\'B7\tab}{\*\pn\pnlvlblt\pnf4\pnindent0{\pntxtb\'B7}}\fi-360\li1080\sl240\slmult1\qj\b0\fs20 Edit pattern1 so that it correctly matches all case-insensitive mentions of "Amazon" plus a title-cased proper noun.\par
{\pntext\f4\'B7\tab}Edit pattern2 so that it correctly matches all case-insensitive mentions of "ad-free", plus the following noun.\par

\pard\li720\sl240\slmult1\qj\fs22 ___________________________________________________________________________\par

\pard\li720\sl240\slmult1\b ANSWER:\par
\b0\f1\fs16 # Create the match patterns\par
pattern1 = [\{'LOWER': 'amazon'\}, \{'IS_TITLE': True, 'POS': 'PROPN'\}]\par
pattern2 = [\{'LOWER': 'ad'\}, \{'ORTH': '-'\}, \{'LOWER': 'free'\}, \{'POS': 'NOUN'\}]\par
\par
# Initialize the Matcher and add the patterns\par
matcher = Matcher(nlp.vocab)\par
matcher.add('PATTERN1', None, pattern1)\par
matcher.add('PATTERN2', None, pattern2)\par
\par
# Iterate over the matches\par
for match_id, start, end in matcher(doc):\par
    # Print pattern string name and text of matched span\par
    print(doc.vocab.strings[match_id], doc[start:end].text)\par

\pard\li720\sl240\slmult1\qj\f0\fs22 ___________________________________________________________________________\par

\pard\li720\sl240\slmult1\b RESULT:\par
\b0\f1\fs16 PATTERN1 Amazon Prime\par
PATTERN2 ad-free viewing\par
PATTERN1 Amazon Prime\par
PATTERN2 ad-free viewing\par
PATTERN2 ad-free viewing\par
PATTERN2 ad-free viewing\b\par

\pard\li720\sl240\slmult1\qj\b0\f0\fs22 ___________________________________________________________________________\par
\cf3\i\fs20 Well done! For the token '_', you can match on the attribute TEXT, LOWER or even SHAPE. All of those are correct. As you can see, paying close attention to the tokenization is very important when working with the token-based Matcher. Sometimes it's much easier to just match exact strings instead and use the PhraseMatcher, which we'll get to in the next exercise.\cf0\i0\f1\fs16\par

\pard\sl240\slmult1\tx568\cf1\f0\fs22 __________________________________________________________________________________\par

\pard\sl240\slmult1\qj\cf2\b 02.14 Efficient phrase matching\par

\pard\li720\sl240\slmult1\qj\cf0\b0\fs20 Sometimes it's more efficient to match exact strings instead of writing patterns describing the individual tokens. This is especially true for finite categories of things \f2\endash  like all countries of the world.\par
We already have a list of countries, so let's use this as the basis of our information extraction script. A list of string names is available as the variable COUNTRIES. The nlp object and a test doc have already been created and the doc.text has been printed to the shell.\par

\pard\li720\sl240\slmult1\f1\fs15 In [1]: COUNTRIES\par
Out[1]: ['Afghanistan', '\'c5land Islands', 'Albania', 'Algeria', 'American Samoa',\par
         'Andorra', 'Angola', 'Anguilla', 'Antarctica', 'Antigua and Barbuda',\par
         'Argentina', 'Armenia', 'Aruba', 'Australia', 'Austria', 'Azerbaijan',\par
         'Bahamas', 'Bahrain', 'Bangladesh', 'Barbados', 'Belarus', 'Belgium', 'Belize',\par
         'Benin', 'Bermuda', 'Bhutan', 'Bolivia (Plurinational State of)',\par
         'Bonaire, Sint Eustatius and Saba', 'Bosnia and Herzegovina', 'Botswana',\par
         'Bouvet Island', 'Brazil', 'British Indian Ocean Territory',\par
         'United States Minor Outlying Islands', 'Virgin Islands (British)',\par
         'Virgin Islands (U.S.)', 'Brunei Darussalam', 'Bulgaria', 'Burkina Faso',\par
         'Burundi', 'Cambodia', 'Cameroon', 'Canada', 'Cabo Verde', 'Cayman Islands',\par
         'Central African Republic', 'Chad', 'Chile', 'China', 'Christmas Island',\par
         'Cocos (Keeling) Islands', 'Colombia', 'Comoros', 'Congo',\par
         'Congo (Democratic Republic of the)', 'Cook Islands', 'Costa Rica', 'Croatia',\par
         'Cuba', 'Cura\'e7ao', 'Cyprus', 'Czech Republic', 'Denmark', 'Djibouti',\par
         'Dominica', 'Dominican Republic', 'Ecuador', 'Egypt', 'El Salvador',\par
         'Equatorial Guinea', 'Eritrea', 'Estonia', 'Ethiopia',\par
         'Falkland Islands (Malvinas)', 'Faroe Islands', 'Fiji', 'Finland', 'France',\par
         'French Guiana', 'French Polynesia', 'French Southern Territories', 'Gabon',\par
         'Gambia', 'Georgia', 'Germany', 'Ghana', 'Gibraltar', 'Greece', 'Greenland',\par
         'Grenada', 'Guadeloupe', 'Guam', 'Guatemala', 'Guernsey', 'Guinea',\par
         'Guinea-Bissau', 'Guyana', 'Haiti', 'Heard Island and McDonald Islands',\par
         'Holy See', 'Honduras', 'Hong Kong', 'Hungary', 'Iceland', 'India',\par
         'Indonesia', "C\'f4te d'Ivoire", 'Iran (Islamic Republic of)', 'Iraq', 'Ireland',\par
         'Isle of Man', 'Israel', 'Italy', 'Jamaica', 'Japan', 'Jersey', 'Jordan',\par
         'Kazakhstan', 'Kenya', 'Kiribati', 'Kuwait', 'Kyrgyzstan',\par
         "Lao People's Democratic Republic", 'Latvia', 'Lebanon', 'Lesotho', 'Liberia',\par
         'Libya', 'Liechtenstein', 'Lithuania', 'Luxembourg', 'Macao',\par
         'Macedonia (the former Yugoslav Republic of)', 'Madagascar', 'Malawi',\par
         'Malaysia', 'Maldives', 'Mali', 'Malta', 'Marshall Islands', 'Martinique',\par
         'Mauritania', 'Mauritius', 'Mayotte', 'Mexico',\par
         'Micronesia (Federated States of)', 'Moldova (Republic of)', 'Monaco',\par
         'Mongolia', 'Montenegro', 'Montserrat', 'Morocco', 'Mozambique', 'Myanmar',\par
         'Namibia', 'Nauru', 'Nepal', 'Netherlands', 'New Caledonia', 'New Zealand',\par
         'Nicaragua', 'Niger', 'Nigeria', 'Niue', 'Norfolk Island',\par
         "Korea (Democratic People's Republic of)", 'Northern Mariana Islands',\par
         'Norway', 'Oman', 'Pakistan', 'Palau', 'Palestine, State of', 'Panama',\par
         'Papua New Guinea', 'Paraguay', 'Peru', 'Philippines', 'Pitcairn', 'Poland',\par
         'Portugal', 'Puerto Rico', 'Qatar', 'Republic of Kosovo', R\'e9union', 'Romania',\par
         'Russian Federation', 'Rwanda', 'Saint Barth\'e9lemy',\par
         'Saint Helena, Ascension and Tristan da Cunha', 'Saint Kitts and Nevis',\par
         'Saint Lucia', 'Saint Martin (French part)', 'Saint Pierre and Miquelon',\par
         'Saint Vincent and the Grenadines',  'Samoa', 'San Marino',\par
         'Sao Tome and Principe', 'Saudi Arabia', 'Senegal', 'Serbia', eychelles',\par
         'Sierra Leone', 'Singapore', 'Sint Maarten (Dutch part)', 'Slovakia',\par
         'Slovenia', 'Solomon Islands', 'Somalia', 'South Africa',\par
         'South Georgia and the South Sandwich Islands', 'Korea (Republic of)',\par
         'South Sudan', 'Spain', 'Sri Lanka', 'Sudan', 'Suriname',\par
         'Svalbard and Jan Mayen', 'Swaziland', 'Sweden', 'Switzerland',\par
         'Syrian Arab Republic', 'Taiwan', 'Tajikistan', 'Tanzania, United Republic of',\par
         'Thailand', 'Timor-Leste', 'Togo', 'Tokelau', 'Tonga', 'Trinidad and Tobago',\par
         'Tunisia', 'Turkey', 'Turkmenistan', 'Turks and Caicos Islands', 'Tuvalu',\par
         'Uganda', 'Ukraine', 'United Arab Emirates',\par
         'United Kingdom of Great Britain and Northern Ireland',\par
         'United States of America', 'Uruguay', 'Uzbekistan', 'Vanuatu',\par
         'Venezuela (Bolivarian Republic of)', 'Viet Nam', 'Wallis and Futuna',\par
         'Western Sahara', 'Yemen', 'Zambia', 'Zimbabwe']\par
\par
In [2]: doc\par
Out[2]: Czech Republic may help Slovakia protect its airspace\f0\fs22\par

\pard\li720\sl240\slmult1\qj ___________________________________________________________________________\par

\pard\li720\sl240\slmult1\b INSTRUCTIONS:\par

\pard{\pntext\f4\'B7\tab}{\*\pn\pnlvlblt\pnf4\pnindent0{\pntxtb\'B7}}\fi-360\li1080\sl240\slmult1\qj\b0\fs20 Import the PhraseMatcher and initialize it with the shared vocab as the variable matcher.\par
{\pntext\f4\'B7\tab}Add the phrase patterns and call the matcher on the doc.\par

\pard\li720\sl240\slmult1\qj\fs22 ___________________________________________________________________________\par

\pard\li720\sl240\slmult1\b ANSWER:\par
\b0\f1\fs16 # Import the PhraseMatcher and initialize it\par
from spacy.matcher import PhraseMatcher\par
matcher = PhraseMatcher(nlp.vocab)\par
\par
# Create pattern Doc objects and add them to the matcher\par
# This is the faster version of: [nlp(country) for country in COUNTRIES]\par
patterns = list(nlp.pipe(COUNTRIES))\par
matcher.add('COUNTRY', None, *patterns)\par
\par
# Call the matcher on the test document and print the result\par
matches = matcher(doc)\par
print([doc[start:end] for match_id, start, end in matches])\par

\pard\li720\sl240\slmult1\qj\f0\fs22 ___________________________________________________________________________\par

\pard\li720\sl240\slmult1\b RESULT:\par
\b0\f1\fs16 [Czech Republic, Slovakia]\b\par

\pard\li720\sl240\slmult1\qj\b0\f0\fs22 ___________________________________________________________________________\par
\cf3\i\fs20 Great work!\cf0\i0\f1\fs16\par

\pard\sl240\slmult1\tx568\cf1\f0\fs22 __________________________________________________________________________________\par

\pard\sl240\slmult1\qj\cf2\b 02.15 Extracting countries and relationships\par

\pard\li720\sl240\slmult1\qj\cf0\b0\fs20 In the previous exercise, you wrote a script using spaCy's PhraseMatcher to find country names in text. Let's use that country matcher on a longer text, analyze the syntax and update the document's entities with the matched countries. The nlp object has already been created.\par
The text is available as the variable text, the PhraseMatcher with the country patterns as the variable matcher. The Span class has already been imported.\par
\par

\pard\li1440\sl240\slmult1\f1\fs15 In [1]: text\par
Out[1]: 'After the Cold War, the UN saw a radical expansion in its peacekeeping duties, taking on more missions in ten years than it had in the previous four decades.Between 1988 and 2000, the number of adopted Security Council resolutions more than doubled, and the peacekeeping budget increased more than tenfold. The UN negotiated an end to the Salvadoran Civil War, launched a successful peacekeeping mission in Namibia, and oversaw democratic elections in post-apartheid South Africa and post-Khmer Rouge Cambodia. In 1991, the UN authorized a US-led coalition that repulsed the Iraqi invasion of Kuwait. Brian Urquhart, Under-Secretary-General from 1971 to 1985, later described the hopes raised by these successes as a "false renaissance" for the organization, given the more troubled missions that followed. Though the UN Charter had been written primarily to prevent aggression by one nation against another, in the early 1990s the UN faced a number of simultaneous, serious crises within nations such as Somalia, Haiti, Mozambique, and the former Yugoslavia. The UN mission in Somalia was widely viewed as a failure after the US withdrawal following casualties in the Battle of Mogadishu, and the UN mission to Bosnia faced "worldwide ridicule" for its indecisive and confused mission in the face of ethnic cleansing. In 1994, the UN Assistance Mission for Rwanda failed to intervene in the Rwandan genocide amid indecision in the Security Council. Beginning in the last decades of the Cold War, American and European critics of the UN condemned the organization for perceived mismanagement and corruption. In 1984, the US President, Ronald Reagan, withdrew his nation\\'s funding from UNESCO (the United Nations Educational, Scientific and Cultural Organization, founded 1946) over allegations of mismanagement, followed by Britain and Singapore. Boutros Boutros-Ghali, Secretary-General from 1992 to 1996, initiated a reform of the Secretariat, reducing the size of the organization somewhat. His successor, Kofi Annan (1997\f3\endash 2006), initiated further management reforms in the face of threats from the United States to withhold its UN dues. In the late 1990s and 2000s, international interventions authorized by the UN took a wider variety of forms. The UN mission in the Sierra Leone Civil War of 1991\endash 2002 was supplemented by British Royal Marines, and the invasion of Afghanistan in 2001 was overseen by NATO. In 2003, the United States invaded Iraq despite failing to pass a UN Security Council resolution for authorization, prompting a new round of questioning of the organization\\'s effectiveness. Under the eighth Secretary-General, Ban Ki-moon, the UN has intervened with peacekeepers in crises including the War in Darfur in Sudan and the Kivu conflict in the Democratic Republic of Congo and sent observers and chemical weapons inspectors to the Syrian Civil War. In 2013, an internal review of UN actions in the final battles of the Sri Lankan Civil War in 2009 concluded that the organization had suffered "systemic failure". One hundred and one UN personnel died in the 2010 Haiti earthquake, the worst loss of life in the organization\\'s history. The Millennium Summit was held in 2000 to discuss the UN\\'s role in the 21st century. The three day meeting was the largest gathering of world leaders in history, and culminated in the adoption by all member states of the Millennium Development Goals (MDGs), a commitment to achieve international development in areas such as poverty reduction, gender equality, and public health. Progress towards these goals, which were to be met by 2015, was ultimately uneven. The 2005 World Summit reaffirmed the UN\\'s focus on promoting development, peacekeeping, human rights, and global security. The Sustainable Development Goals were launched in 2015 to succeed the Millennium Development Goals. In addition to addressing global challenges, the UN has sought to improve its accountability and democratic legitimacy by engaging more with civil society and fostering a global constituency. In an effort to enhance transparency, in 2016 the organization held its first public debate between candidates for Secretary-General. On 1 January 2017, Portuguese diplomat Ant\f1\'f3nio Guterres, who previously served as UN High Commissioner for Refugees, became the ninth Secretary-General. Guterres has highlighted several key goals for his administration, including an emphasis on diplomacy for preventing conflicts, more effective peacekeeping efforts, and streamlining the organization to be more responsive and versatile to global needs.'\f0\fs22\par

\pard\li720\sl240\slmult1\qj ___________________________________________________________________________\par

\pard\li720\sl240\slmult1\b INSTRUCTIONS:\par

\pard{\pntext\f4\'B7\tab}{\*\pn\pnlvlblt\pnf4\pnindent0{\pntxtb\'B7}}\fi-360\li1080\sl240\slmult1\qj\b0\fs20 Iterate over the matches and create a Span with the label "GPE" (geopolitical entity).\par
{\pntext\f4\'B7\tab}Overwrite the entities in doc.ents and add the matched span.\par

\pard\sl240\slmult1\qj\par

\pard{\pntext\f4\'B7\tab}{\*\pn\pnlvlblt\pnf4\pnindent0{\pntxtb\'B7}}\fi-360\li1080\sl240\slmult1\qj Update the script and get the matched span's root head token.\par
{\pntext\f4\'B7\tab}Print the text of the head token and the span.\par

\pard\li720\sl240\slmult1\qj\fs22 ___________________________________________________________________________\par

\pard\li720\sl240\slmult1\b ANSWER:\par
\b0\f1\fs16 # Create a doc and find matches in it\par
doc = nlp(text)\par
\par
# Iterate over the matches\par
for match_id, start, end in matcher(doc):\par
    # Create a Span with the label for "GPE"\par
    span = Span(doc, start, end, label='GPE')\par
\par
    # Overwrite the doc.ents and add the span\par
    doc.ents = list(doc.ents) + [span]\par
\par
# Print the entities in the document\par
print([(ent.text, ent.label_) for ent in doc.ents if ent.label_ == 'GPE'])\par
\par
\par
\par
# Create a doc and find matches in it\par
doc = nlp(text)\par
\par
# Iterate over the matches\par
for match_id, start, end in matcher(doc):\par
    # Create a Span with the label for "GPE" and overwrite the doc.ents\par
    span = Span(doc, start, end, label='GPE')\par
    doc.ents = list(doc.ents) + [span]\par
    \par
    # Get the span's root head token\par
    span_root_head = span.root.head\par
    # Print the text of the span root's head token and the span text\par
    print(span_root_head.text, '-->', span.text)\par

\pard\li720\sl240\slmult1\qj\f0\fs22 ___________________________________________________________________________\par

\pard\li720\sl240\slmult1\b RESULT:\par
\b0\f1\fs16 [('Namibia', 'GPE'), ('South Africa', 'GPE'), ('Cambodia', 'GPE'), ('Kuwait', 'GPE'), ('Somalia', 'GPE'), ('Haiti', 'GPE'), ('Mozambique', 'GPE'), ('Somalia', 'GPE'), ('Rwanda', 'GPE'), ('Singapore', 'GPE'), ('Sierra Leone', 'GPE'), ('Afghanistan', 'GPE'), ('Iraq', 'GPE'), ('Sudan', 'GPE'), ('Congo', 'GPE'), ('Haiti', 'GPE')]\par
\par
\par
Namibia --> Namibia\par
South --> South Africa\par
Cambodia --> Cambodia\par
Kuwait --> Kuwait\par
Somalia --> Somalia\par
Haiti --> Haiti\par
Mozambique --> Mozambique\par
Somalia --> Somalia\par
Rwanda --> Rwanda\par
Singapore --> Singapore\par
Sierra --> Sierra Leone\par
Afghanistan --> Afghanistan\par
Iraq --> Iraq\par
Sudan --> Sudan\par
Congo --> Congo\par
Haiti --> Haiti\b\par

\pard\li720\sl240\slmult1\qj\b0\f0\fs22 ___________________________________________________________________________\par
\cf3\i\fs20 Well done! Now that you've practiced combining predictions with rule-based information extraction, you're ready for chapter 3, which will teach you everything about spaCy's processing pipelines.\cf0\i0\f1\fs16\par

\pard\sl240\slmult1\tx568\cf1\f0\fs22 __________________________________________________________________________________\par

\pard\sl240\slmult1\qj\b Source:\par

\pard\sl240\slmult1 {\cf0\b0{\field{\*\fldinst{HYPERLINK https://learn.datacamp.com/courses/advanced-nlp-with-spacy }}{\fldrslt{https://learn.datacamp.com/courses/advanced-nlp-with-spacy\ul0\cf0}}}}\cf0\b0\f0\fs22\lang2058\par

\pard\sl240\slmult1\tx568\cf1\lang10 __________________________________________________________________________________\par
\cf0\b\par
}
 