{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Importing the requires libraries\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import speech_recognition as sr\n",
    "\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "from pydub.effects import normalize\n",
    "from pydub.silence import split_on_silence\n",
    "\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "from punctuator import Punctuator\n",
    "\n",
    "import spacy\n",
    "from spacy.pipeline import EntityRuler\n",
    "\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "# Import text classification packages\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Global variables\n",
    "PUNCTUATOR_MODULE = r'C:\\Anaconda3\\PUNCTUATOR_DATA_DIR\\INTERSPEECH-T-BRNN.pcl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 Processing text transcribed from spoken language\n",
    "\n",
    "In this chapter, you'll put everything you've learned together by building a speech processing proof of concept project for a technology company, Acme Studios. You'll start by transcribing customer support call phone call audio snippets to text. Then you'll perform sentiment analysis using NLTK, named entity recognition using spaCy and text classification using scikit-learn on the transcribed text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04.01 Creating transcription helper functions\n",
    "\n",
    "See the video.\n",
    "\n",
    "**Examples from the video - Exploring audio**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " '00 Spoken Language Processing in Python.rtf',\n",
       " '01 Introduction to Spoken Language Processing with Python.pdf',\n",
       " '01 Introduction to Spoken Language Processing with Python.rtf',\n",
       " '01. Introduction to Spoken Language Processing with Python.ipynb',\n",
       " '01.01 Introduction to audio data in Python.mp4',\n",
       " '01.03 Converting sound wave bytes to integers.mp4',\n",
       " '01.08 Visualizing sound waves.mp4',\n",
       " '01_Introduction_to_Spoken_Language_Processing_with_Python.py',\n",
       " '02 Using the Python SpeechRecognition library.pdf',\n",
       " '02. Using the Python SpeechRecognition library.ipynb',\n",
       " '02. Using the Python SpeechRecognition library.rtf',\n",
       " '02.01 SpeechRecognition Python library.mp4',\n",
       " '02.05 Reading audio files with SpeechRecognition.mp4',\n",
       " '02.08 Dealing with different kinds of audio.mp4',\n",
       " '02_Using_the_Python_SpeechRecognition_library.py',\n",
       " '03 Manipulating Audio Files with PyDub.pdf',\n",
       " '03. Manipulating Audio Files with PyDub.ipynb',\n",
       " '03. Manipulating Audio Files with PyDub.rtf',\n",
       " '03.01 Introduction to PyDub.mp4',\n",
       " '03.06 Manipulating audio files with PyDub.mp4',\n",
       " '03.11 Converting and saving audio files with PyDub.mp4',\n",
       " '03_Manipulating_Audio_Files_with_PyDub.py',\n",
       " '04 Processing text transcribed from spoken language.ipynb',\n",
       " '04 Processing text transcribed from spoken language.pdf',\n",
       " '04. Processing text transcribed from spoken language.rtf',\n",
       " '04.01 Creating transcription helper functions.mp4',\n",
       " '04_Processing_text_transcribed_from_spoken_language.py',\n",
       " '2-noisy-support-call.wav',\n",
       " '30-seconds-of-nothing-16k.wav',\n",
       " '7601-291468-0006.txt',\n",
       " '7601-291468-0006.wav',\n",
       " 'acme_studios_audio',\n",
       " 'AUD-20180918-WA0000.mp3',\n",
       " 'AUD-20180918-WA0000.txt',\n",
       " 'AUD-20190504-WA0000.m4a',\n",
       " 'audio-chunks-temp',\n",
       " 'audio.wav',\n",
       " 'audio_mp3_to_wav',\n",
       " 'buenos_dias.wav',\n",
       " 'charlie-bit-me-5.wav',\n",
       " 'clean-support-call.wav',\n",
       " 'CocaCola.mp3',\n",
       " 'CocaCola.txt',\n",
       " 'customer_call_transcriptions.csv',\n",
       " 'ex3-static-help-with-account.mp3',\n",
       " 'ex3_datacamp_loud_then_quiet.wav',\n",
       " 'ex3_slicing_part_1.wav',\n",
       " 'ex3_slicing_part_2.wav',\n",
       " 'ex3_stereo_call.wav',\n",
       " 'ex3_stereo_call_c0.wav',\n",
       " 'ex3_stereo_call_c1.wav',\n",
       " 'From audio to text (example).ipynb',\n",
       " 'fr_example.wav',\n",
       " 'good-morning-japanense.wav',\n",
       " 'good_afternoon.wav',\n",
       " 'good_morning.wav',\n",
       " 'good_morning_jacesca.wav',\n",
       " 'it_example.wav',\n",
       " 'leopard.wav',\n",
       " 'louder_speaker_0_original.wav',\n",
       " 'louder_wav_file.wav',\n",
       " 'mp3_file.mp3',\n",
       " 'multiple-speakers-16k.txt',\n",
       " 'multiple-speakers-16k.wav',\n",
       " 'portuguese-example.wav',\n",
       " 'quiet_wav_file.wav',\n",
       " 'speaker_0.wav',\n",
       " 'speaker_0_original.wav',\n",
       " 'speaker_1.wav',\n",
       " 'speaker_2.wav',\n",
       " 'static-out-of-warranty.wav',\n",
       " 'temp.wav',\n",
       " 'Transcribe_speech_to_text.py',\n",
       " 'transcript.py',\n",
       " 'volume_adjusted.wav',\n",
       " 'wav_file.wav',\n",
       " '__pycache__']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the folder of audio files\n",
    "folder = \"./\"\n",
    "os.listdir(folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For the following examples, we use <code>ex4_call_1_stereo_mp3.mp3</code> audio file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"acme_studios_audio/ex4_call_1_stereo_mp3.mp3\"\n",
    "wav_file = \"acme_studios_audio/ex4_call_1_stereo_mp3.wav\"\n",
    "\n",
    "# Import audio file\n",
    "audio = AudioSegment.from_file(file)\n",
    "play(audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating a format conversion function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting acme_studios_audio/ex4_call_1_stereo_mp3.mp3 to acme_studios_audio/ex4_call_1_stereo_mp3.wav...\n"
     ]
    }
   ],
   "source": [
    "# Create function to convert audio file to wav\n",
    "def convert_to_wav(filename):\n",
    "    \"Takes an audio file of non .wav format and converts to .wav\"\n",
    "    \n",
    "    # Import audio file\n",
    "    audio = AudioSegment.from_file(filename)\n",
    "    \n",
    "    # Increase the volume by 10 dB\n",
    "    audio = audio + 10\n",
    "    \n",
    "    # Improving the quality\n",
    "    audio = normalize(audio)\n",
    "    \n",
    "    # Create new filename\n",
    "    new_filename = filename.split(\".\")[0] + \".wav\"\n",
    "    \n",
    "    # Export file as .wav\n",
    "    audio.export(new_filename, format=\"wav\")\n",
    "    \n",
    "    print(f\"Converting {filename} to {new_filename}...\")\n",
    "    return new_filename\n",
    "\n",
    "# Using the file format conversion function\n",
    "_ = convert_to_wav(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating an attribute showing function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels: 1\n",
      "Sample width: 2\n",
      "Frame rate (sample rate): 32000\n",
      "Frame width: 2\n",
      "Length (ms): 54888\n",
      "Frame count: 1756416.0\n"
     ]
    }
   ],
   "source": [
    "def show_pydub_stats(filename):\n",
    "    \"Returns different audio attributes related to an audio file.\"\n",
    "    \n",
    "    # Create AudioSegment instance\n",
    "    audio_segment = AudioSegment.from_file(filename)\n",
    "    \n",
    "    # Print attributes\n",
    "    print(f\"Channels: {audio_segment.channels}\")\n",
    "    print(f\"Sample width: {audio_segment.sample_width}\")\n",
    "    print(f\"Frame rate (sample rate): {audio_segment.frame_rate}\")\n",
    "    print(f\"Frame width: {audio_segment.frame_width}\")\n",
    "    print(f\"Length (ms): {len(audio_segment)}\")\n",
    "    print(f\"Frame count: {audio_segment.frame_count()}\")\n",
    "    \n",
    "    return audio_segment\n",
    "    \n",
    "# Using the attribute showing function\n",
    "_ = show_pydub_stats(wav_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating a transcribe function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello welcome to Acme Studio support lawn my name is Daniel how can I best help you hi Daniel this is John'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a function to transcribe audio\n",
    "def transcribe_audio(filename, language, energy_threshold=300, duration=None, offset=None, show_all=None, noise=0):\n",
    "    \"Takes a .wav format audio file and transcribes it to text.\"\n",
    "    \n",
    "    # Setup a recognizer instance\n",
    "    recognizer = sr.Recognizer()\n",
    "    \n",
    "    # Import the audio file and convert to audio data\n",
    "    audio_file = sr.AudioFile(filename)\n",
    "    with audio_file as source:\n",
    "         # Adjust for ambient noise and record\n",
    "        if noise>0:\n",
    "            recognizer.adjust_for_ambient_noise(source, duration=noise)\n",
    "            \n",
    "        # Record the audio\n",
    "        audio_data = recognizer.record(source,\n",
    "                                       duration=duration, #Listen from the begining to duration value.\n",
    "                                       offset=offset) #used to skip over a specific seconds at the start.\n",
    "    # Set the energy threshold\n",
    "    recognizer.energy_threshold = energy_threshold\n",
    "    \n",
    "    # Return the transcribed text\n",
    "    return recognizer.recognize_google(audio_data, language=language, show_all=show_all)\n",
    "\n",
    "# Using the transcribe function\n",
    "transcribe_audio(wav_file, language='en-GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PayPal just looking to place an order but before I receive I'm just wondering if this offer still stands \n"
     ]
    }
   ],
   "source": [
    "# a function that splits the audio file into chunks and applies speech recognition\n",
    "def transcribe_long_audio(file, language, \n",
    "                          energy_threshold=300, duration=None, offset=None, show_all=None, noise=0,\n",
    "                          chunk_folder=r'acme_studios_audio\\temp'):\n",
    "    \"\"\"\n",
    "    Splitting the large audio file into chunks and apply speech recognition on each of these chunks\n",
    "    \"\"\"\n",
    "    \n",
    "    # create a speech recognition object\n",
    "    recognizer = sr.Recognizer()\n",
    "\n",
    "    # open the audio file using pydub\n",
    "    audio_file = AudioSegment.from_file(file)  \n",
    "    \n",
    "    # split audio_file where silence is 700 miliseconds or more and get chunks\n",
    "    chunks = split_on_silence(audio_file,\n",
    "                              min_silence_len = 500, # experiment with this value for your target audio file\n",
    "                              silence_thresh = audio_file.dBFS-14, # adjust this per requirement\n",
    "                              keep_silence=500, # keep the silence for 1 second, adjustable as well\n",
    "                             )\n",
    "    \n",
    "    # create a directory to store the audio chunks\n",
    "    if os.path.isdir(chunk_folder):\n",
    "        shutil.rmtree(chunk_folder)\n",
    "    os.mkdir(chunk_folder)\n",
    "    \n",
    "    whole_text = \"\"\n",
    "    for i, audio_chunk in enumerate(chunks, start=1):\n",
    "        # export audio chunk and save it in the `folder_name` directory.\n",
    "        chunk_filename = os.path.join(chunk_folder, f\"chunk{i}.wav\")\n",
    "            \n",
    "        audio_chunk.export(chunk_filename, format=\"wav\")\n",
    "            \n",
    "        # recognize the chunk\n",
    "        with sr.AudioFile(chunk_filename) as source:\n",
    "            # Adjust for ambient noise and record\n",
    "            if noise>0:\n",
    "                recognizer.adjust_for_ambient_noise(source, duration=noise)\n",
    "                \n",
    "            # Record the audio\n",
    "            audio_listened = recognizer.record(source,\n",
    "                                               duration=duration, #Listen from the begining to duration value.\n",
    "                                               offset=offset) #used to skip over a specific seconds at the start.\n",
    "                \n",
    "            # Set the energy threshold\n",
    "            recognizer.energy_threshold = energy_threshold\n",
    "    \n",
    "            # try converting it to text\n",
    "            try:\n",
    "                text = recognizer.recognize_google(audio_listened, language=language)\n",
    "            except sr.UnknownValueError as e:\n",
    "                print(f\"Error: {str(e)}\")\n",
    "            else:\n",
    "                whole_text += f'{text} '\n",
    "                \n",
    "    # return the text for all chunks detected\n",
    "    return whole_text\n",
    "\n",
    "# Using the transcribe function\n",
    "print(transcribe_long_audio(wav_file, language='en-US'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04.02 Converting audio to the right format\n",
    "\n",
    "Acme Studios have asked you to do a proof of concept to find out more about their audio files.\n",
    "\n",
    "After exploring them briefly, you find there's a few calls but they're in the wrong file format for transcription.\n",
    "\n",
    "As you'll be interacting with many audio files, you decide to begin by creating some helper functions.\n",
    "\n",
    "The first one, __convert_to_wav(filename)__ takes a file path and uses __PyDub__ to convert it from a __non-wav__ format to __.wav__ format.\n",
    "\n",
    "Once it's built, we'll use the function to convert Acme's first call (https://assets.datacamp.com/production/repositories/4637/datasets/83ef1650407e911a0f52f491068e3082661db743/ex4_call_1_stereo_mp3.mp3), __call_1.mp3__, from __.mp3__ format to __.wav__.\n",
    "\n",
    "__PyDub__'s __AudioSegment__ class has already been imported. Remember, to work with non-wav files, you'll need __ffmpeg__.\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "1. Import the filename parameter using AudioSegment's from_file().\n",
    "2. Set the export format to \"wav\".\n",
    "3. Pass the target audio file, call_1.mp3, to the function.\n",
    "\n",
    "**Results:**<br>\n",
    "<font color=darkgreen>The first function down! Beautiful. Now to convert any audio file to .wav format, you can pass the filename to convert_to_wav(). Creating functions like this at the start of your projects saves plenty of coding later on.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting acme_studios_audio/ex4_call_1_stereo_formatted_mp3.mp3 to acme_studios_audio/ex4_call_1_stereo_formatted_mp3.wav...\n"
     ]
    }
   ],
   "source": [
    "file = \"acme_studios_audio/ex4_call_1_stereo_formatted_mp3.mp3\"\n",
    "\n",
    "# Using the file format conversion function\n",
    "_ = convert_to_wav(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04.03 Finding PyDub stats\n",
    "\n",
    "You decide it'll be helpful to know the audio attributes of any given file easily. This will be especially helpful for finding out how many channels an audio file has or if the frame rate is adequate for transcription.\n",
    "\n",
    "In this exercise, we'll create __show_pydub_stats()__ which takes a filename of an audio file as input. It then imports the audio as a __PyDub__ __AudioSegment__ instance and prints attributes such as number of channels, length and more.\n",
    "\n",
    "It then returns the __AudioSegment__ instance so it can be used later on.\n",
    "\n",
    "We'll use our function on the newly converted __.wav__ file (https://assets.datacamp.com/production/repositories/4637/datasets/43c5aff8c419d07f8cef70fdf40e4657b78b70be/ex4_call_1_stereo_formatted.wav), __call_1.wav__\n",
    "\n",
    "__AudioSegment__ has already imported from __PyDub__.\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "1. Create an AudioSegment instance called audio_segment by importing the filename parameter.\n",
    "2. Print the number of channels using the channels attribute.\n",
    "3. Return the audio_segment variable.\n",
    "4. Test the function on \"call_1.wav\".\n",
    "\n",
    "**Results:**<br>\n",
    "<font color=darkgreen>Nice! Now you'll be able to find the PyDub attribute parameters of any audio file in one line! It seems call_1.wav has two channels, potentially they could be split using PyDubs's split_to_mono() and transcribed separately.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels: 2\n",
      "Sample width: 2\n",
      "Frame rate (sample rate): 32000\n",
      "Frame width: 4\n",
      "Length (ms): 54888\n",
      "Frame count: 1756416.0\n"
     ]
    }
   ],
   "source": [
    "wav_file = \"acme_studios_audio/ex4_call_1_stereo_formatted_mp3.wav\"\n",
    "\n",
    "# Using the attribute showing function\n",
    "_ = show_pydub_stats(wav_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04.04 Transcribing audio with one line\n",
    "\n",
    "Alright, now you've got functions to convert audio files and find out their attributes, it's time to build one to transcribe them.\n",
    "\n",
    "In this exercise, you'll build __transcribe_audio()__ which takes a __filename__ as input, imports the __filename__ using __speech_recognition__'s __AudioFile__ class and then transcribes it using __recognize_google()__.\n",
    "\n",
    "You've seen these functions before but now we'll put them together so they're accessible in a function.\n",
    "\n",
    "To test it out, we'll transcribe Acme's first call (https://assets.datacamp.com/production/repositories/4637/datasets/43c5aff8c419d07f8cef70fdf40e4657b78b70be/ex4_call_1_stereo_formatted.wav), \"__call_1.wav__\".\n",
    "\n",
    "__speech_recognition__ has been imported as __sr__.\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "1. Define a function called transcribe_audio which takes filename as an input parameter.\n",
    "2. Setup a Recognizer() instance as recognizer.\n",
    "3. Use recognize_google() to transcribe the audio data.\n",
    "4. Pass the target call to the function.\n",
    "\n",
    "**Results:**<br>\n",
    "<font color=darkgreen>Massive! You'll notice the recognizer didn't transcribe the words 'fast as' adequately on the last line, starring them out as a potential expletive, this is a reminder speech recognition still isn't perfect. But now you've now got a function which can transcribe the audio of a .wav file with one line of code. They're a bit of effort to setup but once you've got them, helper functions like transcribe_audio() save time and prevent errors later on.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello welcome to Acme Studio support lawn my name is Daniel how can I best help you hey Daniel this is John I've recently bought a small fire from you last 3 weeks ago and I'm already having issues with it oh no that's not good to hear John let's let's get your serial number and then we can we can set up a way to fix it for you just one second and grab my serial number it is full 175 7 I'm very displeased how long do you reckon this is going to take Abby on hold for about an hour now well John we're going to try out back there I will get the steel number will start up a support case we're just really really really really just ways of this talk. I've been trying to contact support pause three four days now and has been coronavirus in the morning and then Erin Haas I'm not really happy I kinda want to get this issue fix this possible \n"
     ]
    }
   ],
   "source": [
    "wav_file = \"acme_studios_audio/ex4_call_1_stereo_formatted_mp3.wav\"\n",
    "\n",
    "# Using the transcribe function\n",
    "print(transcribe_long_audio(wav_file, language='en-US'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Result of the ex. in Datacamp platform**\n",
    ">hello welcome to Acme studio support line my name is Daniel how can I best help you hey Daniel this is John I've recently bought a smart from you guys 3 weeks ago and I'm already having issues with it I know that's not good to hear John let's let's get your cell number and then we can we can set up a way to fix it for you one number for 17 varies how long do you reckon this is going to try our best to get the steel number will start up this support case I'm just really really really really I've been trying to contact past three 4 days now and I've been put on hold more than an hour and a half so I'm not really happy I kind of wanna get this issue 6 is f***** possible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04.05 Using the helper functions you've built\n",
    "\n",
    "Okay, now we've got some helper functions ready to go, it's time to put them to use!\n",
    "\n",
    "You'll first use __convert_to_wav()__ to convert Acme's __call_1.mp3__ to __.wav__ format and save it as __call_1.wav__\n",
    "\n",
    "Using __show_pydub_stats()__ you find __call_1.wav__ has 2 channels so you decide to split them using PyDub's __split_to_mono()__. Acme tells you the customer channel is likely channel 2. So you export channel 2 using __PyDub__'s __.export()__.\n",
    "\n",
    "Finally, you'll use __transcribe_audio()__ to transcribe channel 2 only.\n",
    "\n",
    "**Instructions**\n",
    "1. Convert the .mp3 version of call_1 to .wav and then check the stats of the .wav version.\n",
    "2. Split call_1 to mono and then export the second channel in .wav format.\n",
    "3. Transcribe the audio of call 1's channel 2.\n",
    "\n",
    "**Results:**<br>\n",
    "<font color=darkgreen>Look at that! Thanks to the helper functions we implemented earlier, you converted an audio file, check its stats, split it into separate channels and transcribed it all within a few lines of code! Well done. Now we've got some ways to turn our audio files into text, let's use some natural language processing to find out more.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting to wav format...\n",
      "Converting acme_studios_audio/ex4_call_1_stereo_formatted_mp3.mp3 to acme_studios_audio/ex4_call_1_stereo_formatted_mp3.wav...\n",
      "\n",
      "Checking its stats...\n",
      "Channels: 2\n",
      "Sample width: 2\n",
      "Frame rate (sample rate): 32000\n",
      "Frame width: 4\n",
      "Length (ms): 54888\n",
      "Frame count: 1756416.0\n",
      "\n",
      "Getting the client audio (channnel 2)...\n",
      "\n",
      "Transcribing the client audio...\n",
      "hey Daniel this is John I've recently bought a small fire from you last 3 weeks ago and I'm already having issues with it just one second and grab my serial number it is full 175 7 I'm very displeased how long do you reckon this is going to take Abby on hold for about an hour now we're just really really really really just ways of this talk time I've been trying to contact the pool at Cintas pause three four days now and I've been coronavirus in the morning and then Aaron Haas I'm not really happy I kind of want to get this issue fix this possible \n"
     ]
    }
   ],
   "source": [
    "file = \"acme_studios_audio/ex4_call_1_stereo_formatted_mp3.mp3\"\n",
    "\n",
    "# Convert mp3 file to wav\n",
    "print('Converting to wav format...')\n",
    "wav_file = convert_to_wav(file)\n",
    "\n",
    "# Check the stats of new file\n",
    "print('\\nChecking its stats...')\n",
    "call_1 = show_pydub_stats(wav_file)\n",
    "\n",
    "\n",
    "\n",
    "# Split call_1 to mono\n",
    "print('\\nGetting the client audio (channnel 2)...')\n",
    "call_1_split = call_1.split_to_mono()\n",
    "\n",
    "# Export channel 2 (the customer channel)\n",
    "file_channel2 = file.split('.')[0] + '_channel_2.wav'\n",
    "call_1_split[1].export(file_channel2, format='wav')\n",
    "\n",
    "\n",
    "\n",
    "# Transcribe the single channel\n",
    "print('\\nTranscribing the client audio...')\n",
    "print(transcribe_long_audio(file_channel2, language='en-US'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04.06 Sentiment analysis on spoken language text\n",
    "\n",
    "See the video.\n",
    "\n",
    "**Installing sentiment analysis libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\jaces\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\jaces\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"vader_lexicon\") #Sentimental analysis in English only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">[nltk_data] Downloading package punkt to <br>\n",
    ">[nltk_data]     C:\\Users\\jaces\\AppData\\Roaming\\nltk_data...<br>\n",
    ">[nltk_data]   Package punkt is already up-to-date!<br>\n",
    ">[nltk_data] Downloading package vader_lexicon to<br>\n",
    ">[nltk_data]     C:\\Users\\jaces\\AppData\\Roaming\\nltk_data..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sentiment analysis with VADER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.437, 'neu': 0.563, 'pos': 0.0, 'compound': -0.4767}\n"
     ]
    }
   ],
   "source": [
    "# Create sentiment analysis instance\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Test sentiment analysis on negative text\n",
    "print(sid.polarity_scores(\"This customer service is terrible.\"))\n",
    "#the compound value can be thought of as the overall score with -1 being most negative and positive 1 being most positive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sentiment analysis on transcribed text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey Daniel this is John I've recently bought a small fire from you last 3 weeks ago and I'm already having issues with it just one second and grab my serial number it is full 175 7 I'm very displeased how long do you reckon this is going to take Abby on hold for about an hour now we're just really really really really just ways of this talk time I've been trying to contact the pool at Cintas pause three four days now and I've been coronavirus in the morning and then Aaron Haas I'm not really happy I kind of want to get this issue fix this possible \n"
     ]
    }
   ],
   "source": [
    "# Transcribe customer channel of call_3\n",
    "call_3_channel_2_text = transcribe_long_audio(file_channel2, language='en-US')\n",
    "print(call_3_channel_2_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.078, 'neu': 0.899, 'pos': 0.023, 'compound': -0.8024}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sentiment analysis on customer channel of call_3\n",
    "sid.polarity_scores(call_3_channel_2_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add punctuation to the text (English only)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some text.\n"
     ]
    }
   ],
   "source": [
    "# Trying with puntuator module\n",
    "p = Punctuator(PUNCTUATOR_MODULE)\n",
    "print(p.punctuate('some text'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey, Daniel, this is John I've recently, bought a small fire from you last 3 weeks ago and I'm already having issues with it just one second and grab my serial number. It is full 175 7, I'm, very displeased. How long do you reckon this is going to take Abby on hold for about an hour. Now, we're, just really really really really just ways of this talk time, I've been trying to contact the pool at Cintas pause, three four days now and I've been coronavirus in the morning and then Aaron Haas I'm, not really happy I kind of want to get this issue. Fix this possible.\n"
     ]
    }
   ],
   "source": [
    "p = Punctuator(PUNCTUATOR_MODULE)\n",
    "call_3_channel_2_text_with_punctuation = p.punctuate(call_3_channel_2_text)\n",
    "print(call_3_channel_2_text_with_punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sentiment analysis Sentence by sentence**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey, Daniel, this is John I've recently, bought a small fire from you last 3 weeks ago and I'm already having issues with it just one second and grab my serial number.\n",
      "{'neg': 0.076, 'neu': 0.883, 'pos': 0.041, 'compound': -0.2732}\n",
      "It is full 175 7, I'm, very displeased.\n",
      "{'neg': 0.313, 'neu': 0.687, 'pos': 0.0, 'compound': -0.4927}\n",
      "How long do you reckon this is going to take Abby on hold for about an hour.\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "Now, we're, just really really really really just ways of this talk time, I've been trying to contact the pool at Cintas pause, three four days now and I've been coronavirus in the morning and then Aaron Haas I'm, not really happy I kind of want to get this issue.\n",
      "{'neg': 0.062, 'neu': 0.912, 'pos': 0.025, 'compound': -0.4432}\n",
      "Fix this possible.\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n"
     ]
    }
   ],
   "source": [
    "# Create sentiment analysis instance\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Find sentiment on each sentence\n",
    "for sentence in sent_tokenize(call_3_channel_2_text_with_punctuation):\n",
    "    print(sentence)\n",
    "    print(sid.polarity_scores(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04.07 Analyzing sentiment of a phone call\n",
    "\n",
    "Once you've transcribed the text from an audio file, it's possible to perform natural language processing on the text.\n",
    "\n",
    "In this exercise, we'll use __NLTK__'s VADER (Valence Aware Dictionary and sEntiment Reasoner) to analyze the sentiment of the transcribed text of __call_2.wav__ ().\n",
    "\n",
    "To transcribe the text, we'll use the __transcribe_audio()__ function we created earlier.\n",
    "\n",
    "Once we have the text, we'll use __NLTK__'s __SentimentIntensityAnalyzer()__ class to obtain a sentiment polarity score.\n",
    "\n",
    "__.polarity_scores(text)__ returns a value for pos (positive), neu (neutral), neg (negative) and compound. Compound is a mixture of the other three values. The higher it is, the more positive the text. Lower means more negative.\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "1. Instantiate an instance of SentimentIntensityAnalyzer() and save it to the variable sid.\n",
    "2. Transcribe the target call and save it to call_2_text.\n",
    "3. Print the polarity_scores() of call_2_text.\n",
    "\n",
    "**Results:**<br>\n",
    "<font color=darkgreen>Consider it analyzed! Reading back the transcribed text and listening to the phone call, a compound score of close to 1 (more positive) makes sense since the customer states they're very happy and enjoying their device. Let's keep going!</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking its stats...\n",
      "Channels: 1\n",
      "Sample width: 2\n",
      "Frame rate (sample rate): 32000\n",
      "Frame width: 2\n",
      "Length (ms): 52756\n",
      "Frame count: 1688192.0\n",
      "\n",
      "Playing the audio file...\n",
      "\n",
      "Transcribing the audio...\n",
      "Error: \n",
      "Error: \n",
      "hello my name is Daniel thank you for calling Acme Studios how can I best help you hi Daniel my name is belly smartfind from you guys and extremely happy with it I'll just go to East nobody street but I'm just what someone a little bit more about the message prank I have but I'm finding it had I thought you on the corner of Edward and Elizabeth according to Google according to the maps but some would you be able to help me in some way because I think actually walk straight past your shop yeah sure thing well thank you Sally that's good to hear you're enjoying it let me let me find out where the nearest stories for you \n"
     ]
    }
   ],
   "source": [
    "file = \"acme_studios_audio/ex4_call_2_stereo_native.wav\"\n",
    "\n",
    "\n",
    "# Check the stats of new file\n",
    "print('Checking its stats...')\n",
    "audio = show_pydub_stats(file)\n",
    "\n",
    "\n",
    "# Play audio file\n",
    "print('\\nPlaying the audio file...')\n",
    "play(audio)\n",
    "\n",
    "\n",
    "# Transcribe the audio\n",
    "print('\\nTranscribing the audio...')\n",
    "file_text = transcribe_long_audio(file, language='en-US')\n",
    "print(file_text)\n",
    "\n",
    "\n",
    "# Create SentimentIntensityAnalyzer instance\n",
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.0, 'neu': 0.753, 'pos': 0.247, 'compound': 0.9858}\n"
     ]
    }
   ],
   "source": [
    "# Display sentiment polarity scores at once\n",
    "print(sid.polarity_scores(file_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, my name is Daniel. Thank you for calling, Acme Studios. How can I best help you? Hi Daniel. My name is belly smartfind from you guys and extremely happy with it I'll just go to East, nobody street, but I'm, just what someone a little bit more about the message prank I have but I'm finding it had I thought you on the corner of Edward and Elizabeth, according to Google, according to the maps, but some would you be able to help me in some way because I think actually walk straight past your shop. Yeah, sure thing. Well, thank you Sally that's, good to hear you're, enjoying it. Let me let me find out where the nearest stories for you.\n"
     ]
    }
   ],
   "source": [
    "# Add punctuation to the text\n",
    "p = Punctuator(PUNCTUATOR_MODULE)\n",
    "file_text_with_punctuation = p.punctuate(file_text)\n",
    "print(file_text_with_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, my name is Daniel.\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "Thank you for calling, Acme Studios.\n",
      "{'neg': 0.0, 'neu': 0.667, 'pos': 0.333, 'compound': 0.3612}\n",
      "How can I best help you?\n",
      "{'neg': 0.0, 'neu': 0.303, 'pos': 0.697, 'compound': 0.7845}\n",
      "Hi Daniel.\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "My name is belly smartfind from you guys and extremely happy with it I'll just go to East, nobody street, but I'm, just what someone a little bit more about the message prank I have but I'm finding it had I thought you on the corner of Edward and Elizabeth, according to Google, according to the maps, but some would you be able to help me in some way because I think actually walk straight past your shop.\n",
      "{'neg': 0.0, 'neu': 0.894, 'pos': 0.106, 'compound': 0.8124}\n",
      "Yeah, sure thing.\n",
      "{'neg': 0.0, 'neu': 0.182, 'pos': 0.818, 'compound': 0.5423}\n",
      "Well, thank you Sally that's, good to hear you're, enjoying it.\n",
      "{'neg': 0.0, 'neu': 0.391, 'pos': 0.609, 'compound': 0.872}\n",
      "Let me let me find out where the nearest stories for you.\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n"
     ]
    }
   ],
   "source": [
    "# Sentiment analysis Sentence by sentence\n",
    "# Find sentiment on each sentence\n",
    "for sentence in sent_tokenize(file_text_with_punctuation):\n",
    "    print(sentence)\n",
    "    print(sid.polarity_scores(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04.08 Sentiment analysis on formatted text\n",
    "\n",
    "In this exercise, you'll calculate the sentiment on the customer channel of __call_2.wav__.\n",
    "\n",
    "You've split the customer channel and saved it to __call_2_channel_2.wav__.\n",
    "\n",
    "But from your experience with sentiment analysis, you know it can change sentence to sentence.\n",
    "\n",
    "To calculate it sentence to sentence, you split the split using __NLTK__'s __sent_tokenize()__ module.\n",
    "\n",
    "But __transcribe_audio()__ doesn't return sentences. To try sentiment anaylsis with sentences, you've tried a paid API service to get __call_2_channel_2_paid_api_text__ which has sentences.\n",
    "\n",
    "**Instructions**\n",
    "1. Transcribe the audio of call_2_channel_2.wav and find the sentiment scores.\n",
    "2. Split call_2_channel_2_text into sentences and find the sentiment score of each sentence.\n",
    "3. Split call_2_channel_2_paid_api_text into sentences and score the sentiment of each.\n",
    "\n",
    "**Results:**<br>\n",
    "<font color=darkgreen>That's pretty cool, you can see how the sentiment differs from sentence to sentence in the call 2 channel 2 paid API text. An extension could be to dig deeper into each of the sentences which have the lowest scores. Let's push on!</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_to_mono(filename, sel_channel):\n",
    "    'Split audio and return specified channel'\n",
    "    # Create AudioSegment instance\n",
    "    audio_segment = AudioSegment.from_file(filename)\n",
    "    # Verify the number of channels\n",
    "    number_of_channels = audio_segment.channels\n",
    "    if sel_channel < number_of_channels:\n",
    "        # Split call_1 to mono\n",
    "        audio_channels = audio_segment.split_to_mono()\n",
    "        # Export channel 2 (the customer channel)\n",
    "        file_sel_channel = filename.split('.')[0] + '_channel_2.wav'\n",
    "        audio_channels[sel_channel].export(file_sel_channel, format='wav')\n",
    "    else:\n",
    "        print(f'Error: unmatched audio file, selected channel: {sel_channel+1}°, ' + \\\n",
    "              f'number of channels in the audio file: {number_of_channels}.')\n",
    "        file_sel_channel = None\n",
    "    return file_sel_channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Getting the client audio (channnel 2)...\n",
      "Error: unmatched audio file, selected channel: 2°, number of channels in the audio file: 1.\n"
     ]
    }
   ],
   "source": [
    "# Split call to mono\n",
    "print('\\nGetting the client audio (channnel 2)...')\n",
    "wav_file = r\"acme_studios_audio\\ex4_call_2_stereo_native.wav\"\n",
    "file_one_channel = split_to_mono(wav_file, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_one_channel = r\"acme_studios_audio\\ex4_call_2_stereo_native_client.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi Daniel my name is belly recently purchased a smartphone from you guys and extremely happy with it I'm just going to issue nobody street but I'll just go someone a little bit more about the message prank I have Google location but I'm finding it I thought you on the corner of Edward and Elizabeth according to Google according to the maps but some would you be able to help me in some why because I think actually walk straight past your shop \n"
     ]
    }
   ],
   "source": [
    "# Transcribe customer channel of call 2\n",
    "file_one_channel_text = transcribe_long_audio(file_one_channel, language='en-US')\n",
    "print(file_one_channel_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.0, 'neu': 0.901, 'pos': 0.099, 'compound': 0.8124}\n"
     ]
    }
   ],
   "source": [
    "# Create SentimentIntensityAnalyzer instance\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Display text and sentiment polarity scores\n",
    "print(sid.polarity_scores(file_one_channel_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi Daniel, my name is belly recently purchased a smartphone from you guys and extremely happy with it I'm just going to issue, nobody street. But I'll just go someone a little bit more about the message. Prank I have Google location, but I'm finding it I thought you on the corner of Edward and Elizabeth, according to Google, according to the maps, but some would you be able to help me in some why? Because I think actually walk straight past your shop.\n"
     ]
    }
   ],
   "source": [
    "# Add punctuation marks\n",
    "p = Punctuator(PUNCTUATOR_MODULE)\n",
    "file_one_channel_text_with_punctuation = p.punctuate(file_one_channel_text)\n",
    "print(file_one_channel_text_with_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi Daniel, my name is belly recently purchased a smartphone from you guys and extremely happy with it I'm just going to issue, nobody street.\n",
      "{'neg': 0.0, 'neu': 0.852, 'pos': 0.148, 'compound': 0.6115}\n",
      "But I'll just go someone a little bit more about the message.\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "Prank I have Google location, but I'm finding it I thought you on the corner of Edward and Elizabeth, according to Google, according to the maps, but some would you be able to help me in some why?\n",
      "{'neg': 0.0, 'neu': 0.908, 'pos': 0.092, 'compound': 0.5499}\n",
      "Because I think actually walk straight past your shop.\n",
      "{'neg': 0.0, 'neu': 0.787, 'pos': 0.213, 'compound': 0.2263}\n"
     ]
    }
   ],
   "source": [
    "# Find sentiment on each sentence\n",
    "for sentence in sent_tokenize(file_one_channel_text_with_punctuation):\n",
    "    print(sentence)\n",
    "    print(sid.polarity_scores(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04.09 Named entity recognition on transcribed text\n",
    "\n",
    "See the video.\n",
    "\n",
    "**Examples from the video - Using spaCy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load spaCy language model\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I 0\n",
      "'d 1\n",
      "like 4\n",
      "to 9\n",
      "talk 12\n",
      "about 17\n",
      "a 23\n",
      "smartphone 25\n",
      "I 36\n",
      "ordered 38\n",
      "on 46\n",
      "July 49\n",
      "31st 54\n",
      "from 59\n",
      "your 64\n",
      "Sydney 69\n",
      "store 76\n",
      ", 81\n",
      "my 83\n",
      "order 86\n",
      "number 92\n",
      "is 99\n",
      "40939440 102\n",
      ". 110\n",
      "I 112\n",
      "spoke 114\n",
      "to 120\n",
      "Georgia 123\n",
      "about 131\n",
      "it 137\n",
      "last 140\n",
      "week 145\n",
      ". 149\n"
     ]
    }
   ],
   "source": [
    "# Create a spaCy doc\n",
    "doc = nlp(\"I'd like to talk about a smartphone I ordered on July 31st from your \" + \\\n",
    "          \"Sydney store, my order number is 40939440. I spoke to Georgia about it last week.\")\n",
    "          \n",
    "# Show different tokens and positions\n",
    "for token in doc:\n",
    "    print(token.text, token.idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'd like to talk about a smartphone I ordered on July 31st from your Sydney store, my order number is 40939440.\n",
      "I spoke to Georgia about it last week.\n"
     ]
    }
   ],
   "source": [
    "# Show sentences in doc\n",
    "for sentences in doc.sents:\n",
    "    print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "July 31st DATE\n",
      "Sydney GPE\n",
      "40939440 DATE\n",
      "Georgia GPE\n",
      "last week DATE\n"
     ]
    }
   ],
   "source": [
    "# Find named entities in doc\n",
    "for entity in doc.ents:\n",
    "    print(entity.text, entity.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Custom named entities**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('tagger', <spacy.pipeline.pipes.Tagger object at 0x000001A3005A1DC0>), ('parser', <spacy.pipeline.pipes.DependencyParser object at 0x000001A300545F40>), ('ner', <spacy.pipeline.pipes.EntityRecognizer object at 0x000001A30090FD60>)]\n"
     ]
    }
   ],
   "source": [
    "# Check spaCy pipeline\n",
    "print(nlp.pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tagger', <spacy.pipeline.pipes.Tagger at 0x1a3005a1dc0>),\n",
       " ('parser', <spacy.pipeline.pipes.DependencyParser at 0x1a300545f40>),\n",
       " ('entity_ruler', <spacy.pipeline.entityruler.EntityRuler at 0x1a30378d790>),\n",
       " ('ner', <spacy.pipeline.pipes.EntityRecognizer at 0x1a30090fd60>)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create EntityRuler instance\n",
    "ruler = EntityRuler(nlp)\n",
    "\n",
    "# Add token pattern to ruler\n",
    "ruler.add_patterns([{\"label\":\"PRODUCT\", \"pattern\": \"smartphone\"}])\n",
    "\n",
    "# Add new rule to pipeline before ner\n",
    "nlp.add_pipe(ruler, before=\"ner\")\n",
    "\n",
    "# Check updated pipeline\n",
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smartphone PRODUCT\n",
      "July 31st DATE\n",
      "Sydney GPE\n",
      "40939440 DATE\n",
      "Georgia GPE\n",
      "last week DATE\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"I'd like to talk about a smartphone I ordered on July 31st from your \" + \\\n",
    "          \"Sydney store, my order number is 40939440. I spoke to Georgia about it last week.\")\n",
    "          \n",
    "# Test new entity rule\n",
    "for entity in doc.ents:\n",
    "    print(entity.text, entity.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04.10 Named entity recognition in spaCy\n",
    "\n",
    "Named entities are real-world objects which have names, such as, cities, people, dates or times. We can use __spaCy__ to find named entities in our transcribed text.\n",
    "\n",
    "In this exercise, you'll transcribe __call_4_channel_2.wav__ (https://assets.datacamp.com/production/repositories/4637/datasets/2e039462d95117677db6ddfe24377d9cadcdf730/ex4_call_4_channel_2_formatted.wav) using __transcribe_audio()__ and then use __spaCy__'s language model, __en_core_web_sm__ to convert the transcribed text to a __spaCy__ doc.\n",
    "\n",
    "Transforming text to a __spaCy__ doc allows us to leverage __spaCy__'s built-in features for analyzing text, such as, __.text__ for tokens (single words), __.sents__ for sentences and __.ents__ for named entities.\n",
    "\n",
    "**Instructions**\n",
    "1. Create a spaCy doc by passing the transcribed call 4 channel 2 text to nlp() and then check its type.\n",
    "2. Create a spaCy doc with call_4_channel_2_text then print all the token text in it using the .text attribute.\n",
    "3. Load the \"en_core_web_sm\" language model and then print the sentences in the doc using the .sents attribute.\n",
    "4. Access the entities in the doc using .ents and then print the text of each.\n",
    "\n",
    "**Results:**<br>\n",
    "<font color=darkgreen>Well done! You've now seen some of spaCy's helpful functions for analyzing text. spaCy's built-in named entities are great to start with but sometimes you'll want to use your own. Let's see how!</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Transcribing the audio...\n",
      "hi Daniel my name is an and I've recently just purchased a smart front buying from you and I'm very happy with the product I'd like to order another one from my friends he lives in Sydney and have it delivered I'm pretty sure it's model 315 I can check that for you and I'll give you more details if you would like to take my details and I I will also give you the address thank you excellent \n"
     ]
    }
   ],
   "source": [
    "file = \"acme_studios_audio/ex4_call_4_channel_2_formatted.wav\"\n",
    "\n",
    "# Transcribe the audio\n",
    "print('\\nTranscribing the audio...')\n",
    "file_text = transcribe_long_audio(file, language='en-US')\n",
    "print(file_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: <class 'spacy.tokens.doc.Doc'>\n",
      "\n",
      "Tokens:\n",
      "hi 0\n",
      "Daniel 3\n",
      "my 10\n",
      "name 13\n",
      "is 18\n",
      "an 21\n",
      "and 24\n",
      "I 28\n",
      "'ve 29\n",
      "recently 33\n",
      "just 42\n",
      "purchased 47\n",
      "a 57\n",
      "smart 59\n",
      "front 65\n",
      "buying 71\n",
      "from 78\n",
      "you 83\n",
      "and 87\n",
      "I 91\n",
      "'m 92\n",
      "very 95\n",
      "happy 100\n",
      "with 106\n",
      "the 111\n",
      "product 115\n",
      "I 123\n",
      "'d 124\n",
      "like 127\n",
      "to 132\n",
      "order 135\n",
      "another 141\n",
      "one 149\n",
      "from 153\n",
      "my 158\n",
      "friends 161\n",
      "he 169\n",
      "lives 172\n",
      "in 178\n",
      "Sydney 181\n",
      "and 188\n",
      "have 192\n",
      "it 197\n",
      "delivered 200\n",
      "I 210\n",
      "'m 211\n",
      "pretty 214\n",
      "sure 221\n",
      "it 226\n",
      "'s 228\n",
      "model 231\n",
      "315 237\n",
      "I 241\n",
      "can 243\n",
      "check 247\n",
      "that 253\n",
      "for 258\n",
      "you 262\n",
      "and 266\n",
      "I 270\n",
      "'ll 271\n",
      "give 275\n",
      "you 280\n",
      "more 284\n",
      "details 289\n",
      "if 297\n",
      "you 300\n",
      "would 304\n",
      "like 310\n",
      "to 315\n",
      "take 318\n",
      "my 323\n",
      "details 326\n",
      "and 334\n",
      "I 338\n",
      "I 340\n",
      "will 342\n",
      "also 347\n",
      "give 352\n",
      "you 357\n",
      "the 361\n",
      "address 365\n",
      "thank 373\n",
      "you 379\n",
      "excellent 383\n",
      "\n",
      "Sentences:\n",
      "(1) hi Daniel my name is an\n",
      "(2) and I've recently just purchased a smart front buying from you\n",
      "(3) and I'm very happy with the product I'd like to order another one from my friends\n",
      "(4) he lives in Sydney and have it delivered\n",
      "(5) I'm pretty sure\n",
      "(6) it's model 315\n",
      "(7) I can check that for you\n",
      "(8) and I'll give you more details if you would like to take my details\n",
      "(9) and I I will also give you the address\n",
      "(10) thank you excellent\n",
      "\n",
      "Entities:\n",
      "Daniel PERSON\n",
      "Sydney GPE\n",
      "315 CARDINAL\n"
     ]
    }
   ],
   "source": [
    "# Create a spaCy language model instance\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Create a spaCy doc with call 4 channel 2 text\n",
    "doc = nlp(file_text)\n",
    "\n",
    "# Check the type of doc\n",
    "print('Type:', type(doc))\n",
    "\n",
    "# Show tokens in doc\n",
    "print('\\nTokens:')\n",
    "for token in doc:\n",
    "    print(token.text, token.idx)\n",
    "\n",
    "# Show sentences in doc\n",
    "print('\\nSentences:')\n",
    "for i, sentence in enumerate(doc.sents, start=1):\n",
    "    print(f'({i}) {sentence}')\n",
    "\n",
    "# Show named entities and their labels\n",
    "print('\\nEntities:')\n",
    "for entity in doc.ents:\n",
    "    print(entity.text, entity.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04.11 Creating a custom named entity in spaCy\n",
    "\n",
    "If __spaCy__'s built-in named entities aren't enough, you can make your own using __spaCy__'s __EntityRuler()__ class.\n",
    "\n",
    "__EntityRuler()__ allows you to create your own entities to add to a __spaCy__ pipeline.\n",
    "\n",
    "You start by creating an instance of __EntityRuler()__ and passing it the current pipeline, __nlp__.\n",
    "\n",
    "You can then call __add_patterns()__ on the instance and pass it a dictionary of the text ___pattern__ you'd like to label with an entity.\n",
    "\n",
    "Once you've setup a pattern you can add it the __nlp__ pipeline using __add_pipe()__.\n",
    "\n",
    "Since Acme is a technology company, you decide to tag the pattern __\"smartphone\"__ with the __\"PRODUCT\"__ entity tag.\n",
    "\n",
    "spaCy has been imported and a doc already exists containing the transcribed text from __call_4_channel_2.wav__.\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "1. Import EntityRuler from spacy.pipeline.\n",
    "2. Add \"smartphone\" as the value for the \"pattern\" key.\n",
    "3. Add the EntityRuler() instance, ruler, to the nlp pipeline.\n",
    "4. Print the entity attributes contained in doc.\n",
    "\n",
    "**Results:**<br>\n",
    "<font color=darkgreen>There we go! With custom entities like this, you can start to get even more information out of your transcribed text. Depending on the problem you're working with, you may want to combine a few different patterns together. Let's keep going.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new pipeline:\n",
      "[('tagger', <spacy.pipeline.pipes.Tagger object at 0x000001A303FCCDF0>), ('parser', <spacy.pipeline.pipes.DependencyParser object at 0x000001A30610E040>), ('entity_ruler', <spacy.pipeline.entityruler.EntityRuler object at 0x000001A3023FFE50>), ('ner', <spacy.pipeline.pipes.EntityRecognizer object at 0x000001A30610E9A0>)]\n",
      "\n",
      "Applying the new pipeline...\n",
      "Daniel PERSON\n",
      "smart PRODUCT\n",
      "Sydney GPE\n",
      "315 CARDINAL\n"
     ]
    }
   ],
   "source": [
    "# Create EntityRuler instance\n",
    "ruler = EntityRuler(nlp)\n",
    "\n",
    "# Add token pattern to ruler\n",
    "ruler.add_patterns([{\"label\":\"PRODUCT\", \"pattern\": \"smart\"}])\n",
    "\n",
    "# Add new rule to pipeline before ner\n",
    "nlp.add_pipe(ruler, before=\"ner\")\n",
    "print('The new pipeline:')\n",
    "print(nlp.pipeline)\n",
    "\n",
    "# Custom named entities\n",
    "print('\\nApplying the new pipeline...')\n",
    "doc = nlp(file_text)\n",
    "          \n",
    "# Test new entity rule\n",
    "for entity in doc.ents:\n",
    "    print(entity.text, entity.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04.12 Classifying transcribed speech with Sklearn\n",
    "\n",
    "See the video.\n",
    "\n",
    "**Examples from the video - Converting to wav**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspecting the data...\n",
      "['post_purchases_01.mp3', 'post_purchases_02.mp3', 'pre_purchases_03.mp3', 'pre_purchases_04.mp3']\n",
      "Converting to wav\n",
      "Converting purchases_audio/post_purchases_01.mp3 to purchases_audio/post_purchases_01.wav...\n",
      "Converting purchases_audio/post_purchases_02.mp3 to purchases_audio/post_purchases_02.wav...\n",
      "Converting purchases_audio/pre_purchases_03.mp3 to purchases_audio/pre_purchases_03.wav...\n",
      "Converting purchases_audio/pre_purchases_04.mp3 to purchases_audio/pre_purchases_04.wav...\n"
     ]
    }
   ],
   "source": [
    "# Inspect post purchase audio folder\n",
    "print('Inspecting the data...')\n",
    "folder = 'purchases_audio/'\n",
    "\n",
    "purchase_audio = os.listdir(folder)\n",
    "print(purchase_audio)\n",
    "\n",
    "\n",
    "# Loop through mp3 files\n",
    "print('Converting to wav')\n",
    "for file in purchase_audio:\n",
    "    if not file.endswith(\".wav\"):\n",
    "        # Use previously made function to convert to .wav\n",
    "        wav_file = convert_to_wav(folder + file)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transcribing all phone call excerpts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"How's it going Arthur I just placed an order with you guys and I accidentally sent it to the wrong address? Can you please help me change this.\", \"Yeah, hello. I'm just wondering if I can speak to someone about an order I received yesterday.\", 'Hi David, I just placed an order online and I was wondering if I could make an alteration to that order before you send it off.', \"Paypal just looking to place an order, but before I, receive I'm just wondering if this offer still stands.\"]\n"
     ]
    }
   ],
   "source": [
    "# Transcribe text from wav files\n",
    "def create_text_list(folder):\n",
    "    text_list = []\n",
    "    p = Punctuator(PUNCTUATOR_MODULE)\n",
    "    # Loop through folder\n",
    "    for file in os.listdir(folder):\n",
    "        # Check for .wav extension\n",
    "        if file.endswith(\".wav\"):\n",
    "            # Transcribe audio\n",
    "            text = transcribe_long_audio(folder + file, language='en-US')\n",
    "            # Add punctuation marks\n",
    "            text = p.punctuate(text)\n",
    "            # Add transcribed text to list\n",
    "            text_list.append(text)\n",
    "    return text_list\n",
    "\n",
    "purchase_text = create_text_list(folder)\n",
    "print(purchase_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Organizing transcribed text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             label                                               text\n",
      "0     pre_purchase  how's it going Arthur I just placed an order w...\n",
      "1    post_purchase  yeah hello I'm just wondering if I can speak t...\n",
      "2    post_purchase  hey I receive my order but it's the wrong size...\n",
      "3     pre_purchase  hi David I just placed an order online and I w...\n",
      "4    post_purchase  hey I bought something from your website the o...\n",
      "..             ...                                                ...\n",
      "97   post_purchase  yeah hello I'm just wondering if I can speak t...\n",
      "98    pre_purchase  hi I recently ordered a new phone and I'm just...\n",
      "99    pre_purchase  just looking to get some more information on t...\n",
      "100   pre_purchase  hi I just realised I ordered the wrong compute...\n",
      "101  post_purchase  hey mate how you doing I'm just calling in reg...\n",
      "\n",
      "[102 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create post purchase dataframe\n",
    "df = pd.read_csv('customer_call_transcriptions.csv')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Building a text classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is 96.77% accurate.\n"
     ]
    }
   ],
   "source": [
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[\"text\"], df[\"label\"], test_size=0.3, random_state=42)\n",
    "\n",
    "# Create text classifier pipeline\n",
    "text_classifier = Pipeline([(\"vectorizer\", CountVectorizer()),\n",
    "                            (\"tfidf\", TfidfTransformer()),\n",
    "                            (\"classifier\", MultinomialNB())\n",
    "                            ])\n",
    "\n",
    "# Fit the classifier pipeline on the training data\n",
    "text_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and compare them to test labels\n",
    "predictions = text_classifier.predict(X_test)\n",
    "accuracy = 100 * np.mean(predictions == y_test)\n",
    "print(f\"The model is {accuracy:.2f}% accurate.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04.13 Preparing audio files for text classification\n",
    "\n",
    "Acme are very impressed with your work so far. So they've sent over two more folders of audio files.\n",
    "\n",
    "One folder is called __pre_purchase__ and contains audio snippets from customers who are pre-purchase, like __pre_purchase_audio_25.mp3__.\n",
    "\n",
    "And the other is called __post_purchase__ and contains audio snippets from customers who have made a purchase (post-purchase), like __post_purchase_audio_27.mp3__.\n",
    "\n",
    "Upon inspecting the files you find there's about 50 in each and they're in the __.mp3__ format.\n",
    "\n",
    "Acme want to know if you can build a classifier to classify future calls. You tell them you sure can.\n",
    "\n",
    "So in this exercise, you'll go through each folder and convert the audio files to __.wav__ format using __convert_to_wav()__ so you can transcribe them.\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "1. Convert the files in pre_purchase to .wav using convert_to_wav().\n",
    "2. Convert the files in post_purchase to .wav using convert_to_wav().\n",
    "\n",
    "**Results:**<br>\n",
    "<font color=darkgreen>Excellent! Now all of the audio files are in .wav format, let's transcribe them.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "post-purchase-audio-27.wav\n",
      "post_purchases_01.wav\n",
      "post_purchases_02.wav\n",
      "pre-purchase-audio-25.wav\n",
      "pre_purchases_03.wav\n",
      "pre_purchases_04.wav\n"
     ]
    }
   ],
   "source": [
    "# All file are already converted before\n",
    "folder = 'purchases_audio/'\n",
    "post_purchase_audio = os.listdir(folder)\n",
    "\n",
    "for file in post_purchase_audio:\n",
    "    if file.endswith(\".wav\"):\n",
    "        print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04.14 Transcribing phone call excerpts\n",
    "\n",
    "In this exercise, we'll transcribe the audio files we converted to __.wav__ format to text using __transcribe_audio()__.\n",
    "\n",
    "Since there's lots of them and there could be more, we'll build a function __create_test_list()__ which takes a list of filenames of audio files as input and goes through each file transcribing the text.\n",
    "\n",
    "__create_test_list()__ uses our __transcribe_audio()__ function we created earlier and returns a list of strings containing the transcribed text from each audio file.\n",
    "\n",
    "__pre_purchase_wav_files__ and __post_purchase_wav_files__ are lists of audio snippet filenames.\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "1. Use transcribe_audio() to transcribe the current file to text and add it to the text list.\n",
    "2. Return the text list.\n",
    "3. Use create_text_list() to transcribe all post and pre purchase audio snippets.\n",
    "4. Check the first transcription of the post purchase text list.\n",
    "\n",
    "**Results:**<br>\n",
    "<font color=darkgreen>Nice job! We've now got two lists of transcribed audio snippets we can use to start building a text classifier. Let's organize our text data a little bit with a dataframe.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"How's it going Arthur I just placed an order with you guys and I \"\n",
      " 'accidentally sent it to the wrong address? Can you please help me change '\n",
      " 'this.',\n",
      " \"Yeah, hello. I'm just wondering if I can speak to someone about an order I \"\n",
      " 'received yesterday.',\n",
      " 'Hi David, I just placed an order online and I was wondering if I could make '\n",
      " 'an alteration to that order before you send it off.',\n",
      " \"Paypal just looking to place an order, but before I, receive I'm just \"\n",
      " 'wondering if this offer still stands.']\n"
     ]
    }
   ],
   "source": [
    "pprint(purchase_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04.15 Organizing transcribed phone call data\n",
    "\n",
    "We're almost ready to build a text classifier. But right now, all of our transcribed text data is in two lists, __pre_purchase_text__ and __post_purchase_text__.\n",
    "\n",
    "To organize it better for building a text classifier as well as for future use, we'll put it together into a pandas DataFrame.\n",
    "\n",
    "To start we'll import __pandas__ as __pd__ then we'll create a post purchase dataframe, __post_purchase_df__ using __pd.DataFrame()__.\n",
    "\n",
    "We'll pass __pd.DataFrame()__ a dictionary containing a __\"label\"__ key with a value of __\"post_purchase\"__ and a __\"text\"__ key with a value of our __post_purchase_text__ list.\n",
    "\n",
    "We'll do the same for __pre_purchase_df__ except with __pre_purchase_text__.\n",
    "\n",
    "To have all the data in one place, we'll use __pd.concat()__ and pass it the pre and post purchase DataFrames.\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "1. Create post_purchase_df using the post_purchase_text list.\n",
    "2. Create pre_purchase_df using the pre_purchase_text list.\n",
    "3. Combine the two DataFrames using pd.concat().\n",
    "\n",
    "**Results:**<br>\n",
    "<font color=darkgreen>Excellent! That was the final piece of the puzzle! Having your data in an organized format makes it easier to work with in the future. Let's go and build that text classifier.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             label                                               text\n",
      "0     pre_purchase  how's it going Arthur I just placed an order w...\n",
      "1    post_purchase  yeah hello I'm just wondering if I can speak t...\n",
      "2    post_purchase  hey I receive my order but it's the wrong size...\n",
      "3     pre_purchase  hi David I just placed an order online and I w...\n",
      "4    post_purchase  hey I bought something from your website the o...\n",
      "..             ...                                                ...\n",
      "97   post_purchase  yeah hello I'm just wondering if I can speak t...\n",
      "98    pre_purchase  hi I recently ordered a new phone and I'm just...\n",
      "99    pre_purchase  just looking to get some more information on t...\n",
      "100   pre_purchase  hi I just realised I ordered the wrong compute...\n",
      "101  post_purchase  hey mate how you doing I'm just calling in reg...\n",
      "\n",
      "[102 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04.16 Create a spoken language text classifier\n",
    "Now you've transcribed some customer call audio data, we'll build a model to classify whether the text from the customer call is __pre_purchase__ or __post_purchase__.\n",
    "\n",
    "We've got 45 examples of __pre_purchase__ calls and 57 examples of __post_purchase calls__.\n",
    "\n",
    "The data the model will train on is stored in __train_df__ and the data the model will predict on is stored in __test_df__.\n",
    "\n",
    "Try printing the __.head()__ of each of these to the console.\n",
    "\n",
    "We'll build an __sklearn pipeline__ using __CountVectorizer()__ and __TfidfTransformer()__ to convert our text samples to numbers and then use a __MultinomialNB()__ classifier to learn what category each sample belongs to.\n",
    "\n",
    "This model will work well on our small example here but for larger amounts of text, you may want to consider something more sophisticated.\n",
    "\n",
    "**Instructions**\n",
    "1. Create text_classifier using CountVectorizer(), TfidfTransformer(), and MultinomialNB().\n",
    "2. Fit text_classifier on train_df.text and train_df.label.\n",
    "3. Create predicted by calling predict() on text_classifier and passing it the text column of test_df.\n",
    "4. Evaluate the model by seeing how predicted compares to the test_df.label.\n",
    "\n",
    "**Results:**<br>\n",
    "<font color=darkgreen>Consider it classified! The model was able to classify our test examples with a high level of accuracy. For larger datasets, our pipeline is a good baseline but you might want to look into something like a language model. Now you can start capturing speech, converting it to text and classifying it into different categories. Massive effort!</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is 96.77% accurate.\n"
     ]
    }
   ],
   "source": [
    "# Make predictions and compare them to test labels\n",
    "predictions = text_classifier.predict(X_test)\n",
    "accuracy = 100 * np.mean(predictions == y_test)\n",
    "print(f\"The model is {accuracy:.2f}% accurate.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aditional material\n",
    "\n",
    "- **Online Voice Recorder & Audio Cutter**: https://voice-recorder-online.com/\n",
    "- **For more details on available language models in \"speech_recognition\" python module**: https://cloud.google.com/speech-to-text/docs/languages\n",
    "- **Datacamp course**: https://learn.datacamp.com/courses/spoken-language-processing-in-python\n",
    "- To work with file different from .wav: http://ffmpeg.org/, ex. (in the shell): <code>ffmpeg -i test.mp3 test.wav</code> \n",
    "- Problem with __ffmpeg__ solved: https://www.programmersought.com/article/76562906865/\n",
    "- Is Vader SentimentIntensityAnalyzer Multilingual? NO, https://stackoverflow.com/questions/45275166/is-vader-sentimentintensityanalyzer-multilingual\n",
    "- sentiment-analysis-spanish 0.0.25 https://pypi.org/project/sentiment-analysis-spanish/\n",
    "- Example of Google Cloud Speech API: https://stackoverflow.com/questions/62526560/python-speechrecognition-vs-google-cloud-speech-api\n",
    "- Adding punctuation: https://pypi.org/project/punctuator/ (For english only)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
