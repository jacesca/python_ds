{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Importing the requires libraries\n",
    "import ffmpeg\n",
    "from pydub import AudioSegment\n",
    "from pydub.effects import normalize\n",
    "from pydub.playback import play\n",
    "\n",
    "import speech_recognition as sr\n",
    "\n",
    "import os\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "# Own libraries\n",
    "from Transcribe_speech_to_text import get_transcription"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03. Manipulating Audio Files with PyDub\n",
    "\n",
    "Not all audio files come in the same shape, size or format. Luckily, the PyDub library by James Robert provides tools which you can use to programmatically alter and change different audio file attributes such as frame rate, number of channels, file format and more. In this chapter, you'll learn how to use this helpful library to ensure all of your audio files are in the right shape for transcription."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03.01 Introduction to PyDub\n",
    "\n",
    "See the video.\n",
    "\n",
    "**Examples from the video - PyDub's main class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pydub.audio_segment.AudioSegment"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import an audio file\n",
    "wav_file = AudioSegment.from_file(file=\"good_morning.wav\", format=\"wav\")\n",
    "\n",
    "type(wav_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play audio file\n",
    "play(wav_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show you the number of channels, 1 for mono, 2 for stereo audio\n",
    "wav_file.channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the sample of our AudioSegment in Hertz\n",
    "wav_file.frame_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the number of bytes per sample, 1 means 8-bit, 2 means 16-bit\n",
    "wav_file.sample_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14257"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the max amplitude of your audio file, which can be considered loudness and is useful for normalizing sound levels\n",
    "wav_file.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2604 ms\n",
      "2.604 s\n"
     ]
    }
   ],
   "source": [
    "# Duration of audio file in milliseconds\n",
    "print(len(wav_file), 'ms')\n",
    "print(len(wav_file)*0.001, 's')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Changing audio parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(wav_file.sample_width)\n",
    "\n",
    "# Change sample width to 1\n",
    "wav_file_width_1 = wav_file.set_sample_width(1)\n",
    "print(wav_file_width_1.sample_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000\n",
      "16000\n"
     ]
    }
   ],
   "source": [
    "print(wav_file.frame_rate)\n",
    "\n",
    "# Change sample rate\n",
    "wav_file_16k = wav_file.set_frame_rate(16000)\n",
    "print(wav_file_16k.frame_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(wav_file.channels)\n",
    "\n",
    "# Change number of channels\n",
    "wav_file_1_channel = wav_file.set_channels(1)\n",
    "print(wav_file_1_channel.channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> A rule of thumb is the higher the values, excluding channels, the better. You should aim for a minimum of 16,000 Hertz as the frame rate and to have your audio files in wav format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03.02 Import an audio file with PyDub\n",
    "\n",
    "<code>PyDub</code>'s <code>AudioSegment</code> class makes it easy to import and manipulate audio files with Python.\n",
    "\n",
    "In this exercise, we'll import an audio file of interest by creating an instance of <code>AudioSegment</code>.\n",
    "\n",
    "To import an audio file, you can use the <code>from_file()</code> function on <code>AudioSegment</code> and pass it your target audio file's pathname as a string. The <code>format</code> parameter gives you an option to specify the format of your audio file, however, this is optional as <code>PyDub</code> will automatically infer it.\n",
    "\n",
    "<code>PyDub</code> works with <code>.wav</code> files without any extra dependencies but for other file types like <code>.mp3</code>, you'll need to install ffmpeg (http://www.ffmpeg.org/).\n",
    "\n",
    "A sample audio file has been setup as __wav_file.wav__, you can listen to it here: https://assets.datacamp.com/production/repositories/4637/datasets/6238f8088db33efb5d103dfac1e42eb9fe3e6f2b/wav_file.wav.\n",
    "\n",
    "**Instructions**<br>\n",
    "1. Import AudioSegment from pydub.\n",
    "2. Call the from_file method and pass it the audio file pathname.\n",
    "\n",
    "**Results**<br>\n",
    "<font color=darkgreen>Woohoo! You've just imported your first audio file using PyDub. Over the next few lessons, you'll start to see how many helpful functions PyDub has built-in for working with audio.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pydub.audio_segment.AudioSegment'>\n"
     ]
    }
   ],
   "source": [
    "# Create an AudioSegment instance\n",
    "wav_file = AudioSegment.from_file(file='wav_file.wav', \n",
    "                                  format=\"wav\")\n",
    "\n",
    "# Check the type\n",
    "print(type(wav_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03.03 Play an audio file with PyDub\n",
    "\n",
    "If you're working with audio files, chances are you want to listen to them.\n",
    "\n",
    "<code>PyDub</code>'s <code>playback</code> module provides a function called <code>play()</code> which can be passed an AudioSegment. Running the <code>play()</code> function with an AudioSegment passed in will play the AudioSegment out loud.\n",
    "\n",
    "This can be helpful to check the quality of your audio files and assess any changes you need to make.\n",
    "\n",
    "In this exercise you'll see how simple it is to use the play() function.\n",
    "\n",
    "Remember: to use the <code>play()</code> function, you'll need <code>simpleaudio</code> or <code>pyaudio</code> installed for <code>.wav</code> files and <code>ffmpeg</code> for other kinds of files.\n",
    "\n",
    "**Instructions**<br>\n",
    "1. Import play from the pydub.playback module.\n",
    "2. Call play() whilst passing it the wav_file AudioSegment.\n",
    "\n",
    "**Results**<br>\n",
    "<font color=darkgreen>Wow, did you hear that? Or was your volume turned down? Don't worry, no sound was played because audio functionality isn't yet available at DataCamp. But you can try this code locally and see how play() works!</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play the audio file\n",
    "play(wav_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03.04 Audio parameters with PyDub\n",
    "\n",
    "Every audio file you work with will have a number of characteristics associated with them, such as, channels, frame rate (or sample rate), sample width and more.\n",
    "\n",
    "Knowing these parameters is useful to ensure your audio files are compatible with various API requirements for speech transcription.\n",
    "\n",
    "For example, many APIs recommend a minimum frame rate (<code>wav_file.frame_rate</code>) of 16,000 Hz.\n",
    "\n",
    "When you create an instance of <code>AudioSegment</code>, <code>PyDub</code> automatically infers these parameters from your audio files and saves them as attributes.\n",
    "\n",
    "In this exercise, we'll explore these attributes.\n",
    "\n",
    "**Instructions**<br>\n",
    "1. Find the frame_rate of wav_file.\n",
    "2. Find the number of channels of wav_file.\n",
    "3. Find the max amplitude of wav_file.\n",
    "4. Find the length of wav_file in milliseconds.\n",
    "\n",
    "**Results**<br>\n",
    "<font color=darkgreen>Massive effort! There are many more characteristics you can find out about your audio files once you've imported them as an AudioSegment. Try find some more by adding a dot after your audio file (wav_file.) and pressing tab.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000\n",
      "2\n",
      "8484\n",
      "3284 ms\n",
      "3.2840000000000003 s\n"
     ]
    }
   ],
   "source": [
    "# Find the frame rate\n",
    "print(wav_file.frame_rate)\n",
    "\n",
    "# Find the number of channels\n",
    "print(wav_file.channels)\n",
    "\n",
    "# Find the max amplitude\n",
    "print(wav_file.max)\n",
    "\n",
    "# Find the length\n",
    "# Duration of audio file in milliseconds\n",
    "print(len(wav_file), 'ms')\n",
    "print(len(wav_file)*0.001, 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DEFAULT_CODECS',\n",
       " '__add__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__mul__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__radd__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__sub__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_data',\n",
       " '_from_safe_wav',\n",
       " '_parse_position',\n",
       " '_repr_html_',\n",
       " '_spawn',\n",
       " '_sync',\n",
       " 'append',\n",
       " 'apply_gain',\n",
       " 'apply_gain_stereo',\n",
       " 'apply_mono_filter_to_each_channel',\n",
       " 'array_type',\n",
       " 'channels',\n",
       " 'compress_dynamic_range',\n",
       " 'converter',\n",
       " 'dBFS',\n",
       " 'duration_seconds',\n",
       " 'empty',\n",
       " 'export',\n",
       " 'fade',\n",
       " 'fade_in',\n",
       " 'fade_out',\n",
       " 'ffmpeg',\n",
       " 'frame_count',\n",
       " 'frame_rate',\n",
       " 'frame_width',\n",
       " 'from_file',\n",
       " 'from_file_using_temporary_files',\n",
       " 'from_flv',\n",
       " 'from_mono_audiosegments',\n",
       " 'from_mp3',\n",
       " 'from_ogg',\n",
       " 'from_raw',\n",
       " 'from_wav',\n",
       " 'get_array_of_samples',\n",
       " 'get_dc_offset',\n",
       " 'get_frame',\n",
       " 'get_sample_slice',\n",
       " 'high_pass_filter',\n",
       " 'invert_phase',\n",
       " 'low_pass_filter',\n",
       " 'max',\n",
       " 'max_dBFS',\n",
       " 'max_possible_amplitude',\n",
       " 'normalize',\n",
       " 'overlay',\n",
       " 'pan',\n",
       " 'raw_data',\n",
       " 'remove_dc_offset',\n",
       " 'reverse',\n",
       " 'rms',\n",
       " 'sample_width',\n",
       " 'set_channels',\n",
       " 'set_frame_rate',\n",
       " 'set_sample_width',\n",
       " 'silent',\n",
       " 'speedup',\n",
       " 'split_to_mono',\n",
       " 'strip_silence']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding properties and methods in the wav_file\n",
    "dir(wav_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03.05 Adjusting audio parameters\n",
    "During your __exploratory data analysis__, you may find some of the parameters of your audio files differ or are incompatible with speech recognition APIs.\n",
    "\n",
    "Don't worry, <code>PyDub</code> has built-in functionality which allows you to change various attributes.\n",
    "\n",
    "For example, you can set the frame rate of your audio file calling <code>set_frame_rate()</code> on your <code>AudioSegment</code> instance and passing it an integer of the desired frame rate measured in Hertz.\n",
    "\n",
    "In this exercise, we'll practice altering some audio attributes.\n",
    "\n",
    "**Instructions**<br>\n",
    "1. Create a new wav_file with a frame rate of 16,000 Hz and then check its frame rate.\n",
    "2. Set the wav_file number of channels to 1 and then check the number of channels.\n",
    "3. Print the sample width of wav_file and then set it to 1 and print it again.\n",
    "\n",
    "**Results**<br>\n",
    "<font color=darkgreen>Nice one! Once again, there are other methods you can call on your AudioSegment instances to adjust their attributes as further practice, you should try and find some more. But remember, lowering the values generally leads to lower audio qaulity and worse transcriptions but increasing them may increase the file size and but not the quality of the transcription. Best to explore with different values and find out the ideal tradeoff.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old frame rate:  48000\n",
      "New frame rate:  16000\n",
      "Old number of channels:  2\n",
      "New number of channels:  1\n",
      "Old sample width: 2\n",
      "New sample width: 1\n"
     ]
    }
   ],
   "source": [
    "# Adjusted frame rate\n",
    "print(\"Old frame rate: \", wav_file.frame_rate)\n",
    "wav_file_16k = wav_file.set_frame_rate(16000)\n",
    "print(\"New frame rate: \", wav_file_16k.frame_rate)\n",
    "\n",
    "# Set number of channels to 1\n",
    "print(\"Old number of channels: \", wav_file.channels)\n",
    "wav_file_1_ch = wav_file.set_channels(1)\n",
    "print(\"New number of channels: \", wav_file_1_ch.channels)\n",
    "\n",
    "# Set sample_width to 1\n",
    "print(f\"Old sample width: {wav_file.sample_width}\")\n",
    "wav_file_sw_1 = wav_file.set_sample_width(1)\n",
    "print(f\"New sample width: {wav_file_sw_1.sample_width}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03.06 Manipulating audio files with PyDub\n",
    "\n",
    "See the video.\n",
    "\n",
    "**Examples from the video - Turning it down to 11**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alternative': [{'confidence': 0.83799374,\n",
      "                  'transcript': 'this is a word file'},\n",
      "                 {'transcript': 'this is a web file'},\n",
      "                 {'transcript': 'this is why file'},\n",
      "                 {'transcript': 'this is a wife file'},\n",
      "                 {'transcript': \"this is a wife I'll\"}],\n",
      " 'final': True}\n"
     ]
    }
   ],
   "source": [
    "# Create an AudioSegment instance\n",
    "file, lang = 'wav_file.wav', 'en-US'\n",
    "wav_file = AudioSegment.from_file(file=file, format=\"wav\")\n",
    "            \n",
    "# Listening to the unchanged audio file.\n",
    "play(wav_file)\n",
    "#_ = wav_file.export(file, format='wav')\n",
    "\n",
    "# Converting to text\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "with sr.AudioFile(file) as source:\n",
    "    # Record the audio\n",
    "    audio = recognizer.listen(source)\n",
    "pprint(recognizer.recognize_google(audio, language=lang, show_all=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alternative': [{'confidence': 0.89323336, 'transcript': 'this is why file'},\n",
      "                 {'transcript': 'this is a waffle'},\n",
      "                 {'transcript': 'this is a wife file'},\n",
      "                 {'transcript': 'this is a word file'},\n",
      "                 {'transcript': \"this is a wife I'll\"}],\n",
      " 'final': True}\n"
     ]
    }
   ],
   "source": [
    "# Using the own created function\n",
    "pprint(get_transcription(file, lang, show_all=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alternative': [{'confidence': 0.80881679, 'transcript': 'this is a Wi-Fi'},\n",
      "                 {'transcript': 'this is why file'},\n",
      "                 {'transcript': 'this is a web file'},\n",
      "                 {'transcript': \"this is a wife I'll\"},\n",
      "                 {'transcript': \"this isn't why file\"}],\n",
      " 'final': True}\n"
     ]
    }
   ],
   "source": [
    "# Minus 60 dB\n",
    "quiet_wav_file = wav_file - 60\n",
    "\n",
    "# Listening the changes\n",
    "play(quiet_wav_file)\n",
    "\n",
    "# Try to recognize quiet audio\n",
    "file, lang = 'quiet_wav_file.wav', 'en-US'\n",
    "_ = quiet_wav_file.export(file, format='wav')\n",
    "\n",
    "pprint(get_transcription(file, lang, show_all=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Examples from the video - Increasing the volume**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alternative': [{'confidence': 0.8931073, 'transcript': 'this is why file'},\n",
      "                 {'transcript': 'this is a waffle'},\n",
      "                 {'transcript': 'this is a word file'},\n",
      "                 {'transcript': 'this is a web file'},\n",
      "                 {'transcript': 'this is a wife file'}],\n",
      " 'final': True}\n"
     ]
    }
   ],
   "source": [
    "# Increase the volume by 10 dB\n",
    "louder_wav_file = wav_file + 10\n",
    "\n",
    "# Listening the changes\n",
    "play(louder_wav_file)\n",
    "\n",
    "# Try to recognize quiet audio\n",
    "file, lang = 'louder_wav_file.wav', 'en-US'\n",
    "_ = louder_wav_file.export(file, format='wav')\n",
    "\n",
    "pprint(get_transcription(file, lang, show_all=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Reading the file\n",
    "file, lang = 'speaker_0_original.wav', 'en-US'\n",
    "quite_file = AudioSegment.from_file(file=file, format=\"wav\")\n",
    "            \n",
    "# Listening the file\n",
    "play(quite_file)\n",
    "\n",
    "pprint(get_transcription(file, lang, noise=0.75, show_all=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alternative': [{'confidence': 0.65736002,\n",
      "                  'transcript': 'the limitations of the speech recognition '\n",
      "                                'Lottery'},\n",
      "                 {'transcript': 'limitations of the speech recognition '\n",
      "                                'Lottery'},\n",
      "                 {'transcript': 'are the limitations of the speech recognition '\n",
      "                                'Lottery'},\n",
      "                 {'transcript': 'on the limitations of the speech recognition '\n",
      "                                'Lottery'}],\n",
      " 'final': True}\n"
     ]
    }
   ],
   "source": [
    "# Increase the volume by 10 dB\n",
    "louder_wav_file = quite_file + 10\n",
    "\n",
    "# Listening the changes\n",
    "play(louder_wav_file)\n",
    "\n",
    "# Try to recognize quiet audio\n",
    "file, lang = 'louder_speaker_0_original.wav', 'en-US'\n",
    "_ = louder_wav_file.export(file, format='wav')\n",
    "\n",
    "pprint(get_transcription(file, lang, noise=0.75, show_all=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Examples from the video - This all sounds the same**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import uneven sound audio file\n",
    "loud_quiet = AudioSegment.from_file(\"ex3_datacamp_loud_then_quiet.wav\")\n",
    "\n",
    "# Listening to the original audio file.\n",
    "play(loud_quiet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the sound levels\n",
    "normalized_loud_quiet = normalize(loud_quiet)\n",
    "\n",
    "# Listening the changes\n",
    "play(normalized_loud_quiet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Examples from the video - No static**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import audio with static at start\n",
    "static_at_start = AudioSegment.from_file(\"static-out-of-warranty.wav\")\n",
    "\n",
    "# Listening the file\n",
    "play(static_at_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the static via slicing\n",
    "no_static_at_start = static_at_start[3000:]\n",
    "\n",
    "# Listening the new file\n",
    "play(no_static_at_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Examples from the video - Remixing your audio**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import two audio files\n",
    "wav_file_1 = AudioSegment.from_file(\"speaker_1.wav\")\n",
    "wav_file_2 = AudioSegment.from_file(\"speaker_2.wav\")\n",
    "\n",
    "# Combine the two audio files\n",
    "wav_file_3 = wav_file_1 + wav_file_2\n",
    "\n",
    "# Check the sound\n",
    "play(wav_file_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine two wav files and make the combination louder\n",
    "louder_wav_file_3 = wav_file_1 + wav_file_2 + 10\n",
    "\n",
    "# Check the sound\n",
    "play(wav_file_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Examples from the video - Splitting your audio**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import phone call audio\n",
    "phone_call = AudioSegment.from_file(\"ex3_stereo_call.wav\")\n",
    "\n",
    "# Find number of channels\n",
    "phone_call.channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<pydub.audio_segment.AudioSegment at 0x2572e9b9b20>,\n",
       " <pydub.audio_segment.AudioSegment at 0x2572e9b9880>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split stereo to mono\n",
    "phone_call_channels = phone_call.split_to_mono()\n",
    "phone_call_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "('hello this is Daniel from Acme Studios how can I best help you yeah sure '\n",
      " \"thing what's your name and what's wrong with the device okay nice to meet \"\n",
      " \"you Josh what's a CR number of your device so I can track it down\")\n"
     ]
    }
   ],
   "source": [
    "# Find number of channels of first list item\n",
    "print(phone_call_channels[0].channels)\n",
    "\n",
    "# Listening the file\n",
    "play(phone_call_channels[0])\n",
    "\n",
    "# Try to recognize the audio\n",
    "file, lang = 'ex3_stereo_call_c0.wav', 'en-US'\n",
    "_ = phone_call_channels[0].export(file, format='wav')\n",
    "\n",
    "pprint(get_transcription(file, lang))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "('I was just wondering if I could get some support my name is Josh and my '\n",
      " 'device seems to not want to learn some of my my my phone number is 176-4588')\n"
     ]
    }
   ],
   "source": [
    "# Find number of channels of first list item\n",
    "print(phone_call_channels[1].channels)\n",
    "\n",
    "# Listening the file\n",
    "play(phone_call_channels[1])\n",
    "\n",
    "# Try to recognize the audio\n",
    "file, lang = 'ex3_stereo_call_c1.wav', 'en-US'\n",
    "_ = phone_call_channels[1].export(file, format='wav')\n",
    "\n",
    "pprint(get_transcription(file, lang))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03.07 Turning it down... then up\n",
    "\n",
    "Speech recognition works best on clean, audible speech. If your audio files are too quiet or too loud, it can hinder transcription.\n",
    "\n",
    "In this exercise, you'll see how to make an <code>AudioSegment</code> quieter or louder.\n",
    "\n",
    "Since the <code>play()</code> function won't play your changes in the DataCamp classroom.\n",
    "\n",
    "The baseline audio file, volume_adjusted.wav can be heard here: https://assets.datacamp.com/production/repositories/4637/datasets/520b312f96433535f93656d9e6d61fdb10f5c517/volume_adjusted.wav.\n",
    "\n",
    "**Instructions**<br>\n",
    "1. Import volume_adjusted.wav and lower its volume by 60 dB and save it to a new variable quiet_volume_adjusted.\n",
    "2. Import the target audio file, increase its volume by 15 dB and save it to the variable louder_volume_adjusted.\n",
    "\n",
    "**Results**<br>\n",
    "<font color=darkgreen>That sounds like progress! Here's the louder audio file you created and the quieter one (no sound). Nice work! Adjusting the volume with operators can be useful but doesn't help when you only want to increase the loudness of only quiet sections. Let's take a look at a function which can help!</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import audio file\n",
    "volume_adjusted = AudioSegment.from_file('volume_adjusted.wav')\n",
    "play(volume_adjusted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lower the volume by 60 dB\n",
    "quiet_volume_adjusted = volume_adjusted - 60\n",
    "play(quiet_volume_adjusted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase the volume by 15 dB\n",
    "louder_volume_adjusted = volume_adjusted + 15\n",
    "play(louder_volume_adjusted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03.08 Normalizing an audio file with PyDub\n",
    "\n",
    "Sometimes you'll have audio files where the speech is loud in some portions and quiet in others. Having this variance in volume can hinder transcription.\n",
    "\n",
    "Luckily, <code>PyDub</code>'s effects module has a function called <code>normalize()</code> which finds the maximum volume of an <code>AudioSegment</code>, then adjusts the rest of the <code>AudioSegment</code> to be in proportion. This means the quiet parts will get a volume boost.\n",
    "\n",
    "You can listen to an example of an audio file which starts as loud then goes quiet, <code>loud_then_quiet.wav</code>, here: https://assets.datacamp.com/production/repositories/4637/datasets/9251c751d3efccf781f3e189d68b37c8d22be9ca/ex3_datacamp_loud_then_quiet.wav.\n",
    "\n",
    "In this exercise, you'll use <code>normalize()</code> to normalize the volume of our file, making it sound more like this: https://assets.datacamp.com/production/repositories/4637/datasets/f0c1ba35ff99f07df8cfeee810c7b12118d9cd0f/ex3_datamcamp_normalized_loud_quiet.wav.\n",
    "\n",
    "**Instructions**<br>\n",
    "1. Import AudioSegment from PyDub and normalize from the PyDub's effects module.\n",
    "2. Import the target audio file, loud_then_quiet.wav and save it to loud_then_quiet.\n",
    "3. Normalize the imported audio file using the normalize() function and save it to normalized_loud_then_quiet.\n",
    "\n",
    "**Results**<br>\n",
    "<font color=darkgreen>That sounds much better! Remember, speech recognition works best on clear speech files, so the more you can do to improve the quality of your audio files, including their volume, the better.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import target audio file\n",
    "loud_then_quiet = AudioSegment.from_file('ex3_datacamp_loud_then_quiet.wav')\n",
    "play(loud_then_quiet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize target audio file\n",
    "normalized_loud_then_quiet = normalize(loud_then_quiet)\n",
    "play(normalized_loud_then_quiet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03.09 Chopping and changing audio files\n",
    "\n",
    "Some of your audio files may have sections of redundancy. For example, you might find at the beginning of each file, there's a few seconds of static.\n",
    "\n",
    "Instead of wasting compute trying to transcribe static, you can remove it.\n",
    "\n",
    "Since an <code>AudioSegment</code> is iterable, and measured in milliseconds, you can use slicing to alter the length.\n",
    "\n",
    "To get the first 3-seconds of <code>wav_file</code>, you'd use <code>wav_file[:3000]</code>.\n",
    "\n",
    "You can also add two <code>AudioSegment</code>'s together using the addition operator. This is helpful if you need to combine several audio files.\n",
    "\n",
    "To practice both of these, we're going to remove the first four seconds of __part1.wav__ (https://assets.datacamp.com/production/repositories/4637/datasets/6ef2e43497070fd23c6ce4c0fe1d9d0e46469750/ex3_slicing_part_1.wav), and add the remainder to __part2.wav__ (https://assets.datacamp.com/production/repositories/4637/datasets/6ef2e43497070fd23c6ce4c0fe1d9d0e46469750/ex3_slicing_part_1.wav). Leaving the end result sounding like __part_3.wav__ (https://assets.datacamp.com/production/repositories/4637/datasets/3803042506ed07d707fe264d0bc6ec6ffa891e63/ex3_slicing_part_3.wav).\n",
    "\n",
    "**Instructions**<br>\n",
    "1. Import part_1.wav and part_2.wav and save them to part_1 and part_2 respectively.\n",
    "2. Remove the first 4-seconds of part_1 using slicing and save the new audio to part_1_removed.\n",
    "3. Add part_1_removed to part_2 and save it to part_3.\n",
    "\n",
    "**Results**<br>\n",
    "<font color=darkgreen>Well done! You're becoming an audio manipulation master! But we're not done yet, there's still a few more tricks in the PyDub library you should know about.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import part 1 and part 2 audio files\n",
    "part_1 = AudioSegment.from_wav('ex3_slicing_part_1.wav')\n",
    "part_2 = AudioSegment.from_file('ex3_slicing_part_2.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the first four seconds of part 1\n",
    "part_1_removed = part_1[4000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the remainder of part 1 and part 2 together\n",
    "part_3 = part_1_removed + part_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03.10 Splitting stereo audio to mono with PyDub\n",
    "\n",
    "If you're trying to transcribe phone calls, there's a chance they've been recorded in stereo format, with one speaker on each channel.\n",
    "\n",
    "As you've seen, it's hard to transcribe an audio file with more than one speaker. One solution is to split the audio file with multiple speakers into single files with individual speakers.\n",
    "\n",
    "<code>PyDub</code>'s <code>split_to_mono()</code> function can help with this. When called on an <code>AudioSegment</code> recorded in stereo, it returns a list of two separate <code>AudioSegment</code>'s in mono format, one for each channel.\n",
    "\n",
    "In this exercise, you'll practice this by splitting this __stereo phone call__ (<code>stereo_phone_call.wav</code> https://assets.datacamp.com/production/repositories/4637/datasets/810bb65e2e681e086e90bc2c6c2372bc4bd2cb52/ex3_stereo_call.wav) recording into __channel 1__ (https://assets.datacamp.com/production/repositories/4637/datasets/0aa876f5cb924035481d7b786a3701624e86d1e7/ex3_stereo_call_channel_1.wav) and __channel 2__ (https://assets.datacamp.com/production/repositories/4637/datasets/2a16db969efc35186fe25ca45a4dbd506318a1cd/ex3_stereo_call_channel_2.wav). This separates the two speakers, allowing for easier transcription.\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "1. Import AudioSegment from pydub.\n",
    "2. Create an AudioSegment instance stereo_phone_call with stereo_phone_call.wav.\n",
    "3. Split stereo_phone_call into channels using split_to_mono() and check the channels of the resulting output.\n",
    "4. Save each channel to new variables, phone_call_channel_1 and phone_call_channel_2.\n",
    "\n",
    "**Results**<br>\n",
    "<font color=darkgreen>Nice one! Having audio files with only one speaker usually results in better quality transcriptions. Now you've done all this audio processing, how do save your altered audio files to use later? Let's find out.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stereo number channels: 2\n",
      "Split number channels: 1, 1\n"
     ]
    }
   ],
   "source": [
    "# Import stereo audio file and check channels\n",
    "stereo_phone_call = AudioSegment.from_file('ex3_stereo_call.wav')\n",
    "print(f\"Stereo number channels: {stereo_phone_call.channels}\")\n",
    "\n",
    "# Split stereo phone call and check channels\n",
    "channels = stereo_phone_call.split_to_mono()\n",
    "print(f\"Split number channels: {channels[0].channels}, {channels[1].channels}\")\n",
    "\n",
    "# Save new channels separately\n",
    "phone_call_channel_1 = channels[0]\n",
    "phone_call_channel_2 = channels[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03.11 Converting and saving audio files with PyDub\n",
    "\n",
    "See the video.\n",
    "\n",
    "**Examples from the video - Reformatting and exporting multiple audio **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_wav(wrong_folder_path, right_folder_path):\n",
    "    print(\"Let's begin!\")\n",
    "    # Loop through wrongly formatted files\n",
    "    for file in os.scandir(wrong_folder_path):\n",
    "        \n",
    "        # Only work with files with audio extensions we're fixing\n",
    "        if file.path.endswith(\".mp3\") or file.path.endswith(\".flac\"):\n",
    "        \n",
    "            # Create the new .wav filename\n",
    "            out_file = right_folder_path + os.path.splitext(os.path.basename(file.path))[0] + \".wav\"\n",
    "\n",
    "            # Read in the audio file and export it in wav format\n",
    "            AudioSegment.from_file(file.path).export(out_file, format=\"wav\")\n",
    "            print(f\"Creating {out_file}\")\n",
    "    print('End.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's begin!\n",
      "Creating audio_mp3_to_wav/AUD-20180918-WA0000.wav\n",
      "Creating audio_mp3_to_wav/CocaCola.wav\n",
      "Creating audio_mp3_to_wav/ex3-static-help-with-account.wav\n",
      "Creating audio_mp3_to_wav/mp3_file.wav\n",
      "End.\n"
     ]
    }
   ],
   "source": [
    "# Call our new function\n",
    "make_wav(\".\", \"audio_mp3_to_wav/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03.12 Exporting and reformatting audio files\n",
    "\n",
    "If you've made some changes to your audio files, or if they've got the wrong file extension, you can use **PyDub** to export and save them as new audio files.\n",
    "\n",
    "You can do this by using the **.export()** function on any instance of an **AudioSegment** you've created. The **export()** function takes two parameters, **out_f**, or the destination file path of your audio file and **format**, the format you'd like your new audio file to be. Both of these are strings. **format** is **\"mp3\"** by default so be sure to change it if you need.\n",
    "\n",
    "In this exercise, you'll import this **.mp3** file (**mp3_file.mp3** https://assets.datacamp.com/production/repositories/4637/datasets/b035eadbae1544450868436a7179fa70158eb5de/mp3_file.mp3) and then export it with the **.wav** extension using **.export()**.\n",
    "\n",
    "Remember, to work with files other than **.wav**, you'll need **ffmpeg**.\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "1. Import mp3_file.mp3 and save it to mp3_file.\n",
    "2. Export mp3_file with the file name mp3_file.wav with \"wav\" format.\n",
    "\n",
    "**Results**<br>\n",
    "<font color=darkgreen>There we go! Now our .mp3 file is in the .wav format, it'll definitely be compatible with all kinds of speech transcription APIs. Let's see this at scale.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the .mp3 file\n",
    "mp3_file = AudioSegment.from_file('mp3_file.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BufferedRandom name='audio_mp3_to_wav/mp3_file.wav'>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Export the .mp3 file as wav\n",
    "mp3_file.export(out_f='audio_mp3_to_wav/mp3_file.wav', format='wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03.13 Manipulating multiple audio files with PyDub\n",
    "\n",
    "You've seen how to convert a single file using **PyDub** but what if you had a folder with multiple different file types?\n",
    "\n",
    "For this exercise, we've setup a **folder** which has **.mp3**, **.m4a** and **.aac** versions of the **good-afternoon** audio file.\n",
    "\n",
    "We'll use **PyDub** to open each of the files and export them as **.wav** format so they're compatible with speech recognition APIs.\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "1. Pass audio_file to the from_file() function.\n",
    "2. Use export() to export wav_filename with the format \".wav\".\n",
    "\n",
    "**Results**<br>\n",
    "<font color=darkgreen>Woohoo! You've successfully converted the folder of audio files from being non-compatiable with speech_recognition to being compatible!</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating audio_mp3_to_wav/AUD-20180918-WA0000.wav...\n",
      "Creating audio_mp3_to_wav/mp3_file.wav...\n",
      "Creating audio_mp3_to_wav/CocaCola.wav...\n",
      "Creating audio_mp3_to_wav/AUD-20190504-WA0000.wav...\n"
     ]
    }
   ],
   "source": [
    "folder = ['AUD-20180918-WA0000.mp3', 'mp3_file.mp3', 'CocaCola.mp3', 'AUD-20190504-WA0000.m4a']\n",
    "\n",
    "# Loop through the files in the folder\n",
    "for audio_file in folder:\n",
    "    # Create the new .wav filename\n",
    "    wav_filename = \"audio_mp3_to_wav/\" + os.path.splitext(os.path.basename(audio_file))[0] + \".wav\"\n",
    "        \n",
    "    # Read audio_file and export it in wav format\n",
    "    AudioSegment.from_file(audio_file).export(out_f=wav_filename, format='wav')\n",
    "        \n",
    "    print(f\"Creating {wav_filename}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03.14 An audio processing workflow\n",
    "\n",
    "You've seen how to import and manipulate a single audio file using **PyDub**. But what if you had a folder with multiple audio files you needed to convert?\n",
    "\n",
    "In this exercise we'll use **PyDub** to format a folder of files to be ready to use with **speech_recognition**.\n",
    "\n",
    "You've found your customer call files all have 3-seconds of static at the start and are quieter than they could be.\n",
    "\n",
    "To fix this, we'll use **PyDub** to cut the static, increase the sound level and convert them to the **.wav** extension.\n",
    "\n",
    "You can listen to an unformatted example **here** (https://assets.datacamp.com/production/repositories/4637/datasets/c53557fea60087064aec7e9d99e889b9be79e75a/ex3-static-help-with-account.mp3).\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "1. Let's start with one file. Import account_help.mp3 and cut off the first 3-seconds (3000 milliseconds) of static.\n",
    "2. Now the static has been removed, increase the volume by 10dB.\n",
    "3. Now for multiple files. Use from_file() to import each audio_file and export the louder files without static with the \"wav\" format.\n",
    "\n",
    "**Results**<br>\n",
    "<font color=darkgreen>Woohoo! You've successfully processed and converted the folder of audio files from being non-compatiable with speech_recognition to being compatible! Here's what your files sound like without static, and here's without the static and 10 decibels louder. Let's start putting all you've learned about audio processing to work in the next chapter.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_with_static = AudioSegment.from_file('ex3-static-help-with-account.mp3')\n",
    "\n",
    "# Cut the first 3-seconds of static off\n",
    "file_without_static = file_with_static[3000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase the volume by 10dB\n",
    "louder_file_without_static = file_without_static + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating audio_mp3_to_wav/ex3-static-help-with-account.wav...\n"
     ]
    }
   ],
   "source": [
    "# Multiple files\n",
    "folder = ['ex3-static-help-with-account.mp3']\n",
    "\n",
    "for audio_file in folder:\n",
    "    file_with_static = AudioSegment.from_file(audio_file)\n",
    "\n",
    "    # Cut the 3-seconds of static off\n",
    "    file_without_static = file_with_static[3000:]\n",
    "\n",
    "    # Increase the volume by 10dB\n",
    "    louder_file_without_static = file_without_static + 10\n",
    "    \n",
    "    # Create the .wav filename for export\n",
    "    wav_filename = \"audio_mp3_to_wav/\" + os.path.splitext(os.path.basename(audio_file))[0] + \".wav\"\n",
    "    \n",
    "    # Export the louder file without static as .wav\n",
    "    louder_file_without_static.export(wav_filename, format='wav')\n",
    "    print(f\"Creating {wav_filename}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aditional material\n",
    "\n",
    "- **Online Voice Recorder & Audio Cutter**: https://voice-recorder-online.com/\n",
    "- **For more details on available language models in \"speech_recognition\" python module**: https://cloud.google.com/speech-to-text/docs/languages\n",
    "- **Datacamp course**: https://learn.datacamp.com/courses/spoken-language-processing-in-python\n",
    "- To work with file different from .wav: http://ffmpeg.org/, ex. (in the shell): <code>ffmpeg -i test.mp3 test.wav</code> \n",
    "- Problem with __ffmpeg__ solved: https://www.programmersought.com/article/76562906865/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
